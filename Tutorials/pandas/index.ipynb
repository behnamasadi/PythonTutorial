{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac66229",
   "metadata": {},
   "source": [
    "### What is a DataFrame?\n",
    "\n",
    "A `DataFrame` is a two-dimensional, size-mutable, and heterogeneous tabular data structure with labeled axes (rows and columns) in `pandas`. You can think of it like an in-memory spreadsheet or SQL table, or even a dict of Series objects.\n",
    "\n",
    "Here's a breakdown of its key features:\n",
    "\n",
    "1. **Two-Dimensional Structure**: Like a table in a spreadsheet, a DataFrame consists of rows and columns. This makes it ideal for representing real-world data like financial records, sports statistics, etc.\n",
    "\n",
    "2. **Labeled Axes**: Each row and column in a DataFrame has a label. By default, the row labels are known as the Index, and the column labels are simply the names of each column.\n",
    "\n",
    "3. **Heterogeneous Data Types**: A DataFrame can contain different types of data â€” integers, strings, floating-point numbers, Python objects, and more. Each column typically holds data of the same type.\n",
    "\n",
    "4. **Size Mutable**: You can add or remove rows and columns from a DataFrame after it has been created.\n",
    "\n",
    "5. **Functionality**: Pandas provides a vast array of functions to manipulate, transform, and analyze data in a DataFrame. This includes operations like filtering, sorting, groupby, merging, concatenation, and more.\n",
    "\n",
    "6. **Data Alignment**: One of the key features of Pandas is data alignment. It automatically aligns data in operations involving multiple DataFrames or Series (a one-dimensional array in Pandas).\n",
    "\n",
    "7. **Handling Missing Data**: Pandas is equipped to handle missing data using methods like `isna()`, `fillna()`, `dropna()`, etc.\n",
    "\n",
    "8. **Efficient Storage and Processing**: Under the hood, Pandas DataFrames are built on top of NumPy arrays, making them efficient for numerical computations.\n",
    "\n",
    "### Creating a DataFrame:\n",
    "\n",
    "There are many ways to create a DataFrame. Here's one of the simplest ways using a dictionary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b050c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age      City\n",
      "0    Alice   25  New York\n",
      "1      Bob   30     Paris\n",
      "2  Charlie   35    London\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'Paris', 'London']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407779a",
   "metadata": {},
   "source": [
    "or you can simply create an empty DataFram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cd219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"Name\", \"Article\", \"Quantity\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18058f",
   "metadata": {},
   "source": [
    "### append columns to an empty DataFrame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a33605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'] = ['Tv', 'PC', 'Desk']\n",
    "df['Article'] = [97, 600, 200]\n",
    "df['Quantity'] = [2200, 75, 100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83182510",
   "metadata": {},
   "source": [
    "#### iterate rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82164802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tv\n",
      "1 PC\n",
      "2 Desk\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(index, row['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f6411",
   "metadata": {},
   "source": [
    "### append rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb7fc759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Article  Quantity\n",
      "0      Tv       97      2200\n",
      "1      PC      600        75\n",
      "2    Desk      200       100\n",
      "0  Fridge       97      2200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_new_row = pd.DataFrame(\n",
    "    {'Name': ['Fridge'], 'Article': [97], 'Quantity': [2200]})\n",
    "df = pd.concat([df, df_new_row])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fde393",
   "metadata": {},
   "source": [
    "### printing headers (columns names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2947582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns are:  ['Name', 'Article', 'Quantity']\n",
      "head:       Name  Article  Quantity\n",
      "0      Tv       97      2200\n",
      "1      PC      600        75\n",
      "2    Desk      200       100\n",
      "0  Fridge       97      2200\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns.tolist()\n",
    "print(\"columns are: \", cols)\n",
    "print(\"head: \", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734581e2",
   "metadata": {},
   "source": [
    "\n",
    "### Basic Operations:\n",
    "\n",
    "You can do a variety of operations on DataFrames:\n",
    "\n",
    "\n",
    "### selecting columns\n",
    "\n",
    "```\n",
    "df['Name']\n",
    "```\n",
    "or\n",
    "\n",
    "```\n",
    "df[['Name', 'Article']]\n",
    "```\n",
    "\n",
    "### filtering rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c099e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Article  Quantity\n",
      "1    PC      600        75\n",
      "2  Desk      200       100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df[df['Article'] > 100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9f298",
   "metadata": {},
   "source": [
    "### merging/ joining data\n",
    "```\n",
    "pd.merge(df1, df2, on='key_column')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a317e118",
   "metadata": {},
   "source": [
    "### accessing rows by index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb0b8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value of column Name at row index 2: Name    Desk\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"the value of column Name at row index 2:\", df.loc[2, ['Name']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb47e0",
   "metadata": {},
   "source": [
    "### updating rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12553a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value of column Name at row index 1 after update is: Name    new value\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df.at[1, 'Name'] = 'new value'\n",
    "print(\"the value of column Name at row index 1 after update is:\",\n",
    "      df.loc[1, ['Name']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4b573",
   "metadata": {},
   "source": [
    "### updating rows in loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72c607f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name    ***Desk***\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index in df.index:\n",
    "    df.loc[index, ['Name']] = \"*\" + df.loc[index, ['Name']] + \"*\"\n",
    "print(df.loc[2,['Name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131e45c",
   "metadata": {},
   "source": [
    "### delete columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb5584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column exists\n",
      "removing the Quantity column\n",
      "     Name  Article\n",
      "0      Tv       97\n",
      "1      PC      600\n",
      "2    Desk      200\n",
      "0  Fridge       97\n"
     ]
    }
   ],
   "source": [
    "# or df.pop(\"temp\") or del df[\"temp\"]\n",
    "\n",
    "column_data=df.get('Quantity')\n",
    "if column_data is not None:\n",
    "    print(\"Column exists\")\n",
    "    df.drop('Quantity', inplace=True, axis=1)\n",
    "    print('removing the Quantity column')\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Column does not exist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0767bd",
   "metadata": {},
   "source": [
    "### rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48fc7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.rename(columns={'Article': 'New-Article'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42458d99",
   "metadata": {},
   "source": [
    "\n",
    "### reset index column\n",
    "```\n",
    "df = df.reset_index(drop=True)\n",
    "df.set_index('Name', inplace=True)\n",
    "print(df)\n",
    "```\n",
    "### remove index when writhing to csv\n",
    "```\n",
    "df.to_csv('data/tmp.csv', index=False)\n",
    "```\n",
    "### read csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd7beaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   New-Article\n",
      "0           97\n",
      "1          600\n",
      "2          200\n",
      "3           97\n"
     ]
    }
   ],
   "source": [
    "# index_col=False  not use the first column as the index\n",
    "df = pd.read_csv(\"../data/tmp.csv\", index_col=False)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0b028",
   "metadata": {},
   "source": [
    "### processing data without iterating\n",
    "\n",
    "In Pandas, it's often recommended to avoid explicit iteration (e.g., with `for` loops) over DataFrame rows or Series elements. Iterating over DataFrame rows using methods like `iterrows()` or `itertuples()` can be quite slow. Instead, one should leverage Pandas' built-in vectorized operations, which are optimized for performance.\n",
    "\n",
    "Here are some common ways to process data in Pandas without iterating:\n",
    "\n",
    "### 1. **Vectorized Operations**\n",
    "\n",
    "For arithmetic operations, you can apply them directly to the whole DataFrame or Series.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4419ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "df['A'] = df['A'] * 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4859952",
   "metadata": {},
   "source": [
    "### 2. **Using `apply()`**\n",
    "\n",
    "You can apply a function along the axis of a DataFrame.\n",
    "\n",
    "```python\n",
    "def some_function(x):\n",
    "    return x * x\n",
    "\n",
    "df['A'] = df['A'].apply(some_function)\n",
    "```\n",
    "or some lambda function:\n",
    "\n",
    "```python\n",
    "df[\"age\"]=df[\"age\"].apply(lambda x:x*2)\n",
    "```\n",
    "\n",
    "### 3. **Using `map()` for Series**\n",
    "\n",
    "The `map()` function is used to map each value in a Series to some other value.\n",
    "```python\n",
    "s = pd.Series(['cat', 'dog', 'mouse'])\n",
    "s = s.map(str.upper)\n",
    "```\n",
    "\n",
    "\n",
    "### 4. **Boolean Indexing**\n",
    "\n",
    "You can filter rows based on some condition without iterating.\n",
    "\n",
    "```python\n",
    "df_filtered = df[df['A'] > 2]\n",
    "```\n",
    "\n",
    "### 5. **Using `where()`**\n",
    "\n",
    "The `where()` function is used to replace values in rows or columns based on some condition.\n",
    "\n",
    "```python\n",
    "df['A'] = df['A'].where(df['A'] > 2, 0)\n",
    "```\n",
    "\n",
    "### 6. **Using `assign()` for Creating New Columns**\n",
    "\n",
    "```python\n",
    "df = df.assign(C = df['A'] + df['B'])\n",
    "```\n",
    "\n",
    "### 7. **String Operations with `str` Accessor**\n",
    "\n",
    "You can apply string operations directly on a Series without iterating.\n",
    "\n",
    "```python\n",
    "df['text_column'] = df['text_column'].str.lower()\n",
    "```\n",
    "\n",
    "### 8. **Datetime Operations with `dt` Accessor**\n",
    "\n",
    "If you have a datetime column, you can extract components without iterating.\n",
    "\n",
    "```python\n",
    "df['year'] = df['date_column'].dt.year\n",
    "```\n",
    "\n",
    "### 9. **Aggregation Functions**\n",
    "\n",
    "Aggregation functions like `sum()`, `mean()`, `max()`, etc., are inherently vectorized.\n",
    "\n",
    "```python\n",
    "total = df['A'].sum()\n",
    "```\n",
    "\n",
    "### 10. **Using `eval()` for Computation**\n",
    "`eval()` apply an string operation on the variable. For large DataFrames, `eval()` can be faster than standard operations.\n",
    "\n",
    "```python\n",
    "df.eval('age=age+quantity', inplace=True)\n",
    "```\n",
    "\n",
    "The key takeaway is that Pandas provides numerous built-in functionalities that allow you to perform operations on entire columns or DataFrames at once. By leveraging these capabilities, you can make your code cleaner, more concise, and often much faster.\n",
    "\n",
    "\n",
    "\n",
    "### iloc\n",
    " `iloc` stands for \"integer-location\" and is used primarily for selecting rows and columns in a DataFrame by their integer index positions. \n",
    "\n",
    "Here's a basic overview:\n",
    "\n",
    "1. **Single Selection**\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({\n",
    "        'A': [1, 2, 3],\n",
    "        'B': [4, 5, 6],\n",
    "        'C': [7, 8, 9]\n",
    "    })\n",
    "\n",
    "    # Select the value in the first row and first column\n",
    "    value = df.iloc[0, 0]  # returns 1\n",
    "    ```\n",
    "\n",
    "2. **Selecting Rows**\n",
    "    ```python\n",
    "    # Select the first row\n",
    "    first_row = df.iloc[0]\n",
    "\n",
    "    # Select the first and second rows\n",
    "    first_two_rows = df.iloc[0:2]\n",
    "    ```\n",
    "\n",
    "3. **Selecting Columns**\n",
    "    ```python\n",
    "    # Select the first column\n",
    "    first_column = df.iloc[:, 0]\n",
    "\n",
    "    # Select the first and second columns\n",
    "    first_two_columns = df.iloc[:, 0:2]\n",
    "    ```\n",
    "\n",
    "4. **Selecting Multiple Rows and Columns**\n",
    "    ```python\n",
    "    # Select the first two rows and the first two columns\n",
    "    subset = df.iloc[0:2, 0:2]\n",
    "    ```\n",
    "\n",
    "5. **Using Lists**\n",
    "    ```python\n",
    "    # Select the first and third rows and the first and third columns\n",
    "    subset = df.iloc[[0, 2], [0, 2]]\n",
    "    ```\n",
    "\n",
    "6. **Conditional Selection (using boolean indexing)**\n",
    "    While `iloc` doesn't support boolean indexing directly, we can achieve this by combining it with boolean indexing on the dataframe:\n",
    "    ```python\n",
    "    mask = df['A'] > 1  # Boolean mask where column 'A' is greater than 1\n",
    "    filtered_rows = df[mask]\n",
    "\n",
    "    # Using iloc on the filtered dataframe\n",
    "    subset = filtered_rows.iloc[:, 0:2]\n",
    "    ```\n",
    "\n",
    "Remember, `iloc` uses integer-based indexing, so it doesn't consider named indices (row labels) or column labels, unlike `loc` which is label-based indexing. If you try to access an index or column that doesn't exist, you will get an `IndexError`. Ensure that the indices you're using are valid for the DataFrame you're working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798bff1",
   "metadata": {},
   "source": [
    "# Practical Advice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a7d760",
   "metadata": {},
   "source": [
    "Working with Pandas DataFrames is a fundamental aspect of data analysis and manipulation in Python. Here are some practical pieces of advice for using Pandas DataFrames effectively:\n",
    "\n",
    "1. **Understand Data Types**: Be aware of the data types in your DataFrame. Using the appropriate data type (like `int`, `float`, `datetime`, etc.) can save memory and improve performance.\n",
    "\n",
    "2. **Use Vectorized Operations**: Leverage Pandas' vectorized operations instead of applying functions using loops. Vectorized operations are more efficient and concise.\n",
    "\n",
    "3. **Handling Missing Data**: Learn how to handle missing data effectively. Methods like `dropna()`, `fillna()`, and boolean indexing are crucial for cleaning and preparing your data.\n",
    "\n",
    "4. **Efficient Data Loading**: When reading large datasets, use parameters in `read_csv` (or similar functions) like `dtype`, `usecols`, and `chunksize` to control memory usage and only load necessary data.\n",
    "\n",
    "5. **Indexing and Selecting Data**: Master the use of `loc[]` and `iloc[]` for label-based and integer-based indexing. Understand how to slice and dice the data efficiently.\n",
    "\n",
    "6. **Avoid Chained Assignment**: Chained assignment (like `df[a][b] = value`) can lead to unexpected results due to Pandas' copying behavior. Prefer using `loc[]` or `iloc[]`.\n",
    "\n",
    "7. **Use `groupby` Wisely**: Grouping data using `groupby` is a powerful feature. Combine it with aggregate functions (`sum`, `mean`, `count`, etc.) to summarize data.\n",
    "\n",
    "8. **Datetime Handling**: If dealing with time series data, make use of Pandas' `datetime` capabilities for parsing, formatting, and manipulating dates and times.\n",
    "\n",
    "9. **Memory Management**: For large datasets, consider using categories with `pd.Categorical` for object-type columns with few unique values to save memory.\n",
    "\n",
    "10. **Leverage `apply` and `map`**: These functions are useful for applying a function across columns or elements but be mindful of their performance implications.\n",
    "\n",
    "11. **Use MultiIndex for Complex Data**: MultiIndex (hierarchical indices) can be very helpful for complex data analysis and can make data aggregation tasks easier.\n",
    "\n",
    "12. **Regularly Check Data**: Use methods like `head()`, `tail()`, `info()`, and `describe()` to regularly inspect your data throughout your analysis for sanity checks.\n",
    "\n",
    "13. **Opt for In-built Functions**: Whenever possible, use Pandas' built-in functions which are optimized for performance over custom implementations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1775655",
   "metadata": {},
   "source": [
    "# iloc, loc, and at\n",
    "`iloc`, `loc`, and `at` are three methods provided by Pandas for accessing data in a DataFrame or Series. They each have different use cases:\n",
    "\n",
    "1. **`iloc`**:\n",
    "   - **Purpose**: `iloc` is used for selecting data based on integer-location based indexing. It means that you use integers to indicate the position of the rows and columns you want to access.\n",
    "   - **Syntax**: `df.iloc[<row selection>, <column selection>]`.\n",
    "   - **Use Case**: You use `iloc` when you want to access elements by their integer index (like in an array). It is purely position based and not label based.\n",
    "   - **Example**: `df.iloc[0, 1]` would access the element at the first row and second column.\n",
    "\n",
    "2. **`loc`**:\n",
    "   - **Purpose**: `loc` is used for selecting data based on label-based indexing. It means that you use the names or labels of the rows and columns to access the data.\n",
    "   - **Syntax**: `df.loc[<row selection>, <column selection>]`.\n",
    "   - **Use Case**: You use `loc` when you want to access elements using their index labels or boolean arrays.\n",
    "   - **Example**: `df.loc['row_label', 'column_label']` would access the element at the specified row and column labels.\n",
    "\n",
    "3. **`at`**:\n",
    "   - **Purpose**: `at` is used for accessing a single value for a row/column label pair. It is similar to `loc` but is optimized for accessing a single element.\n",
    "   - **Syntax**: `df.at[<row label>, <column label>]`.\n",
    "   - **Use Case**: You use `at` when you know the exact location (row and column labels) of the element you want to access and you need to access it quickly. It's faster than `loc` for accessing single values.\n",
    "   - **Example**: `df.at['row_label', 'column_label']` would access the single element at the specified row and column labels.\n",
    "\n",
    "Here's a quick comparison:\n",
    "\n",
    "- **Speed**: `at` > `iloc` > `loc` (for accessing single values).\n",
    "- **Selection by**: `iloc` uses integer index, `loc` uses labels, and `at` is for single value access by labels.\n",
    "- **Use for multiple elements**: `iloc` and `loc` can be used to access multiple elements (slices, lists of index/labels), while `at` is strictly for single elements.\n",
    "\n",
    "Choosing between these depends on your specific needs: whether your data selection is based on index position or labels, and whether you're retrieving single values or subsets of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf18737",
   "metadata": {},
   "source": [
    "# check if a column exists\n",
    "To check if a column exists in a DataFrame in Pandas, you can use one of the following methods:\n",
    "\n",
    "### 1. Using the `in` Keyword\n",
    "You can simply use the `in` keyword to check if a column label is present in the DataFrame's columns.\n",
    "\n",
    "```python\n",
    "if 'column_name' in df.columns:\n",
    "    print(\"Column exists\")\n",
    "else:\n",
    "    print(\"Column does not exist\")\n",
    "```\n",
    "\n",
    "### 2. Using the `.columns` Attribute with `any()`\n",
    "You can use the `.columns` attribute and check if any of the column names matches the desired name.\n",
    "\n",
    "```python\n",
    "if any(df.columns == 'column_name'):\n",
    "    print(\"Column exists\")\n",
    "else:\n",
    "    print(\"Column does not exist\")\n",
    "```\n",
    "\n",
    "### 3. Try-Except Block\n",
    "Although less common for this purpose, you can use a try-except block. This is particularly useful if you want to perform an operation on the column and handle the case where the column doesn't exist.\n",
    "\n",
    "```python\n",
    "try:\n",
    "    # Attempt to access or perform operations on the column\n",
    "    df['column_name']\n",
    "    print(\"Column exists\")\n",
    "except KeyError:\n",
    "    print(\"Column does not exist\")\n",
    "```\n",
    "\n",
    "### 4. Using the `.get()` Method\n",
    "This method is more about safely accessing a column rather than just checking its existence. It returns `None` or a specified default value if the column does not exist.\n",
    "\n",
    "```python\n",
    "column_data = df.get('column_name')\n",
    "if column_data is not None:\n",
    "    print(\"Column exists\")\n",
    "else:\n",
    "    print(\"Column does not exist\")\n",
    "```\n",
    "\n",
    "The first method using the `in` keyword is the most straightforward and commonly used approach for this purpose."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
