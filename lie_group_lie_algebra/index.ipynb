{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b007b7",
   "metadata": {},
   "source": [
    "## Group\n",
    "In mathematics, a **group** is a set, equipped with an operation that combines any two of its elements to form a third element, satisfying four fundamental axioms. Here's the formal definition and its properties:\n",
    "\n",
    "Let $ G $ be a set and $ \\cdot $ be a binary operation on $ G $ (i.e., a function $ \\cdot: G \\times G \\rightarrow G $). Then $ (G, \\cdot) $ is called a group if the following axioms are satisfied:\n",
    "\n",
    "1. **Closure**: For every pair of elements $ a, b $ in $ G $, the result of the operation $ a \\cdot b $ is also in $ G $.\n",
    "   $ \\forall a, b \\in G, \\quad a \\cdot b \\in G $\n",
    "\n",
    "2. **Associativity**: For all elements $ a, b, $ and $ c $ in $ G $, the equation $ (a \\cdot b) \\cdot c = a \\cdot (b \\cdot c) $ holds.\n",
    "   $ \\forall a, b, c \\in G, \\quad (a \\cdot b) \\cdot c = a \\cdot (b \\cdot c) $\n",
    "\n",
    "3. **Identity Element**: There exists an element $ e $ in $ G $ such that for every element $ a $ in $ G $, the equation $ e \\cdot a = a \\cdot e = a $ holds.\n",
    "   $ \\exists e \\in G \\quad \\forall a \\in G, \\quad e \\cdot a = a \\cdot e = a $\n",
    "\n",
    "4. **Inverse Element**: For each element $ a $ in $ G $, there exists an element $ b $ in $ G $ such that $ a \\cdot b = b \\cdot a = e $, where $ e $ is the identity element of $ G $.\n",
    "   $ \\forall a \\in G, \\quad \\exists b \\in G \\quad \\text{such that} \\quad a \\cdot b = b \\cdot a = e $\n",
    "\n",
    "If a group also satisfies the **commutative** property:\n",
    "$ \\forall a, b \\in G, \\quad a \\cdot b = b \\cdot a $\n",
    "then the group is called an **abelian group** (or commutative group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfde82c-977b-4c7b-9174-95e92db9630e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d7fd84",
   "metadata": {},
   "source": [
    "### Examples of Groups:\n",
    "1. $ (\\mathbb{Z},+ )$: The set of integers $ \\mathbb{Z} $ with the operation of addition is a group. The identity element is 0, and the inverse of any integer $ n $ is $ -n $.\n",
    "2. $ (\\mathbb{R}^* ,\\times )$: The set of non-zero real numbers $ \\mathbb{R}^* $ with the operation of multiplication is a group. The identity element is 1, and the inverse of any real number $ r $ is $ 1/r $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b49d0",
   "metadata": {},
   "source": [
    "## Matrix Groups\n",
    "\n",
    "Matrix groups, often referred to as linear groups, are sets of matrices that form a group under matrix multiplication. These groups are subsets of the general linear group $ GL(n, F) $, where $ n $ is the size of the matrix and $ F $ is the field over which the matrices are defined (commonly $ F = \\mathbb{R} $ or $ F = \\mathbb{C} $).\n",
    "\n",
    "For a set of matrices to form a matrix group, they must satisfy the group axioms:\n",
    "\n",
    "1. **Closure**: The product of any two matrices in the set is also in the set.\n",
    "2. **Associativity**: Matrix multiplication is associative.\n",
    "3. **Identity Element**: The set contains the identity matrix (of appropriate size).\n",
    "4. **Inverse Element**: For every matrix in the set, its inverse is also in the set.\n",
    "\n",
    "\n",
    "Because each group is represented by a specific subclass of non-singular $n \\times n$ matrices, there are fewer than $n^2$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5181348-ccbc-4d5d-a502-56453ce360e7",
   "metadata": {},
   "source": [
    "### Field\n",
    "In mathematics, a **field** $F$ is a set on which addition, subtraction, multiplication, and division are defined and behave as expected from our familiar arithmetic operations. More formally, a field is a set equipped with two operations, usually called addition and multiplication, and these operations satisfy the following conditions (called field axioms):\n",
    "\n",
    "1. **Closure under Addition and Multiplication**: For any two elements $a$ and $b$ in the field $F$, both $a + b$ and $a \\cdot b$ are also in $F$.\n",
    "2. **Associativity of Addition and Multiplication**: For any $a, b, c \\in F$, one has $a + (b + c) = (a + b) + c$ and $a \\cdot (b \\cdot c) = (a \\cdot b) \\cdot c$.\n",
    "3. **Commutativity of Addition and Multiplication**: For any $a, b \\in F$, $a + b = b + a$ and $a \\cdot b = b \\cdot a$.\n",
    "4. **Existence of Additive and Multiplicative Identity Elements**: There exist two distinct elements $0$ and $1$ in $F$ such that for any element $a \\in F$, $a + 0 = a$ and $a \\cdot 1 = a$.\n",
    "5. **Existence of Additive Inverses and Multiplicative Inverses (except for 0)**: For every $a \\in F$, there exists an element $-a$ in $F$ such that $a + (-a) = 0$. Similarly, for every $a \\in F$ except $0$, there exists an element $a^{-1}$ in $F$ such that $a \\cdot a^{-1} = 1$.\n",
    "6. **Distributivity of Multiplication over Addition**: For any $a, b, c \\in F$, $a \\cdot (b + c) = (a \\cdot b) + (a \\cdot c)$.\n",
    "\n",
    "These axioms make fields a fundamental structure for many areas of mathematics, including algebra, number theory, and algebraic geometry. Common examples of fields include the set of rational numbers ($\\mathbb{Q}$), the set of real numbers ($\\mathbb{R}$), and the set of complex numbers ($\\mathbb{C}$). There are also finite fields, consisting of a finite number of elements, which are of great interest in areas such as coding theory and cryptography.\n",
    "\n",
    "In the context of Lie algebras, the field $F$ typically serves as the \"scalar\" coefficients for the vector space operations within the algebra. The operations of the Lie algebra, such as the Lie bracket (commutator), must satisfy certain properties that are consistent with the structure of the field $F$, ensuring that the algebra is closed under these operations and that they interact predictably with scalar multiplication from $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160dbb02",
   "metadata": {},
   "source": [
    "### Examples of Matrix Groups:\n",
    "\n",
    "1. **General Linear Group $ GL(n, \\mathbb{R}) $**:\n",
    "   - This is the set of all invertible $ n \\times n $ matrices with real entries.\n",
    "   - The operation is matrix multiplication.\n",
    "   - The identity element is the $ n \\times n $ identity matrix.\n",
    "   - Every matrix in the set has an inverse in the set since they are all invertible.\n",
    "   - This group consists of all invertible $ n \\times n $ matrices with real entries.\n",
    "   - Example for $ GL(2, \\mathbb{R}) $ (2x2 invertible matrices):\n",
    "      \n",
    "     $\\begin{bmatrix} \n",
    "     2 & 1 \\\\\n",
    "     1 & 1 \\\\\n",
    "     \\end{bmatrix}$\n",
    "   - This matrix is invertible, and its determinant is:  $ 2(1) - 1(1) = 1 $, which is non-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a57614",
   "metadata": {},
   "source": [
    "2. **Special Linear Group $ SL(n, \\mathbb{R}) $**:\n",
    "   - This is the set of all $ n \\times n $ matrices with real entries and determinant equal to 1.\n",
    "   - Like $ GL(n, \\mathbb{R}) $, the operation is matrix multiplication.\n",
    "   - The identity element is the $ n \\times n $ identity matrix.\n",
    "   - Every matrix in the set has an inverse in the set, and the determinant of the inverse is also 1.\n",
    "   - This group consists of all $ n \\times n $ matrices with real entries and determinant equal to 1.\n",
    "   - Example for $ SL(2, \\mathbb{R}) $:\n",
    "   \n",
    "     $\n",
    "     \\begin{bmatrix}\n",
    "     2 & 1 \\\\\n",
    "     -1 & 1 \\\\\n",
    "     \\end{bmatrix}\n",
    "     $\n",
    "     \n",
    "     The determinant of this matrix is $ 2(1) - 1(-1) = 3 - 1 = 2 $, so it's not in $ SL(2, \\mathbb{R}) $. A valid example would be:\n",
    "     \n",
    "     $\n",
    "     \\begin{bmatrix}\n",
    "     2 & 1 \\\\\n",
    "     -2 & 1 \\\\\n",
    "     \\end{bmatrix}\n",
    "     $\n",
    "     \n",
    "     The determinant of this matrix is $ 2(1) - 1(-2) = 2 + 2 = 4 $, so this also isn't in $ SL(2, \\mathbb{R}) $. Finding matrices in $ SL(2, \\mathbb{R}) $ requires a bit more effort to ensure the determinant is 1.\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c32f1",
   "metadata": {},
   "source": [
    "3.**n-dimentional Affine group** over $\\mathbb{R}$ is:\n",
    "\n",
    "\n",
    "$Aff_n(\\mathbb{R})= \\begin{Bmatrix} \\begin{bmatrix} A & t\\\\  0 & 1 \\end{bmatrix}: A \\in GL_n( \\mathbb{R} ), t\\in  \\mathbb{R}^n \\end{Bmatrix}$\n",
    "\n",
    "If $x \\in \\mathbb{R}^n $ with $\\begin{bmatrix} x \\\\  1 \\end{bmatrix}  \\in \\mathbb{R}^ {n+1}$ then the **action of** $Aff_n(\\mathbb{R})$ on $\\mathbb{R}^n$ is :\n",
    "\n",
    "\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "A & t\\\\ \n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x\n",
    "\\\\ \n",
    "1\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "Ax+t\\\\ \n",
    "1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "The Affine group includes: scaling, rotation, translation, distortion, and sheer.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Formally, the **affine group** $ \\text{Aff}(V) $ on a vector space $ V $ over a field $ F $ is the group of all invertible affine transformations from $ V $ to itself. An affine transformation can be thought of as the composition of a linear transformation and a translation.\n",
    "\n",
    "Mathematically, an affine transformation $ T: V \\rightarrow V $ is defined as:\n",
    "\n",
    "$ T(\\mathbf{v}) = A\\mathbf{v} + \\mathbf{b} $\n",
    "\n",
    "Where:\n",
    "- $ A $ is an invertible linear transformation (an element of the general linear group $ GL(V) $).\n",
    "- $ \\mathbf{b} $ is a vector in $ V $.\n",
    "\n",
    "The set of all such transformations, equipped with the operation of composition, forms the affine group $ \\text{Aff}(V) $.\n",
    "\n",
    "For example, when $ V = \\mathbb{R}^2 $, the affine group $ \\text{Aff}(\\mathbb{R}^2) $ consists of all transformations of the plane that can be obtained by taking any combination of rotations, translations, dilations, and shears.\n",
    "\n",
    "It's worth noting that while linear transformations fix the origin, affine transformations do not necessarily do so. The addition of the translation vector $ \\mathbf{b} $ allows the \"movement\" of the origin under the transformation.\n",
    "\n",
    "\n",
    "the affine group **can be represented using matrices**, but with a slight modification to the usual matrix representation of linear transformations. This representation is often called the **homogeneous coordinates** representation.\n",
    "\n",
    "Given an affine transformation on $ \\mathbb{R}^n $ defined by $ T(\\mathbf{v}) = A\\mathbf{v} + \\mathbf{b} $, where $ A $ is an $ n \\times n $ matrix representing a linear transformation and $ \\mathbf{b} $ is a translation vector in $ \\mathbb{R}^n $, this transformation can be represented using an $ (n+1) \\times (n+1) $ matrix in the following way:\n",
    "\n",
    "$ \n",
    "T = \n",
    "\\begin{bmatrix}\n",
    "A & \\mathbf{b} \\\\\n",
    "\\mathbf{0}^T & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ A $ is the $ n \\times n $ matrix of the linear transformation.\n",
    "- $ \\mathbf{b} $ is the translation vector, placed in the last column.\n",
    "- $ \\mathbf{0}^T $ is a row vector of zeros.\n",
    "- The bottom-right entry is 1.\n",
    "\n",
    "Using this representation, the composition of affine transformations corresponds to matrix multiplication in this augmented space.\n",
    "\n",
    "For example, in $ \\mathbb{R}^2 $, an affine transformation can be represented by a $ 3 \\times 3 $ matrix:\n",
    "\n",
    "$ \n",
    "\\begin{bmatrix}\n",
    "a & b & t_x \\\\\n",
    "c & d & t_y \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Where $ a, b, c, $ and $ d $ represent the linear transformation part, and $ t_x $ and $ t_y $ represent the translation in the x and y directions, respectively.\n",
    "\n",
    "So, while the affine group isn't a subset of the matrix groups we typically discuss (like $ GL(n, \\mathbb{R}) $), it can be represented using an extended matrix group in the space of one higher dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a019115",
   "metadata": {},
   "source": [
    "4. **Orthogonal Group $ O(n) $**:\n",
    "   - This is the set of all $ n \\times n $ real matrices $ A $ such that $ A^T A = AA^T = I $, where $ A^T $ is the transpose of $ A $ and $ I $ is the identity matrix.\n",
    "   - These matrices represent rotations (and reflections) in $ n $-dimensional space.\n",
    "   - The operation is matrix multiplication.\n",
    "   - The identity element is the $ n \\times n $ identity matrix.\n",
    "   - If $ A $ is in $ O(n) $, then $ A^T $ (which is also $ A^{-1} $) is in $ O(n) $ as well.\n",
    "   - This group consists of all $ n \\times n $ real matrices $ A $ such that $ A^T A = AA^T = I $.\n",
    "   - Example for $ O(2) $ (rotation matrix):\n",
    "   \n",
    "     $\n",
    "     \\begin{bmatrix}\n",
    "     \\cos(\\theta) & -\\sin(\\theta) \\\\\n",
    "     \\sin(\\theta) & \\cos(\\theta) \\\\\n",
    "     \\end{bmatrix}\n",
    "     $\n",
    "     \n",
    "     For $ \\theta = \\pi/4 $ (45 degrees), this becomes:\n",
    "     \n",
    "     $\n",
    "     \\begin{bmatrix}\n",
    "     \\sqrt{2}/2 & -\\sqrt{2}/2 \\\\\n",
    "     \\sqrt{2}/2 & \\sqrt{2}/2 \\\\\n",
    "     \\end{bmatrix}\n",
    "     $\n",
    "   \n",
    "   \n",
    "Looking closer into orthogonal group and knwoing the determinant of the product of two matrices is equal to the product of their determinants, $ \\text{det}(AB) = \\text{det}(A) \\times \\text{det}(B) $, we have:\n",
    "\n",
    "$det(AA^T)=det(A)^2=det(I_n)=1$\n",
    "\n",
    "\n",
    "\n",
    "Therefore $det(A)=\\pm 1$, thus we have:\n",
    "\n",
    "$O(n)=O(n)^{+}  \\cup O(n)^{-}$ where:\n",
    "\n",
    "$O(n)^{+}={A \\in O(n): det(A)=+1}$ which is the rotation\n",
    "\n",
    "$O(n)^{-}={A \\in O(n): det(A)=-1}$ which is the reflection\n",
    "\n",
    "$O(n)^{+} \\cap O(n)^{-}=\\emptyset$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d9c8cc",
   "metadata": {},
   "source": [
    "5. **Special Orthogonal Group $ SO(n) $**:\n",
    "   - This is a subgroup of $ O(n) $ consisting of matrices with determinant 1.\n",
    "   - These matrices represent rotations in $ n $-dimensional space without reflections.\n",
    "   - The operation and identity are the same as in $ O(n) $.\n",
    "   - The rotation matrix example from $ O(2) $ above is also in $ SO(2) $ since its determinant is 1.\n",
    "\n",
    "The examples provided are for the case $ n = 2 $ for simplicity. The groups themselves exist for all positive integers $ n $.\n",
    "\n",
    "**isometric**: distance-preserving bijection\n",
    "$\\parallel f(x)-f(y) \\parallel= \\parallel x-y\\parallel   x,y\\in \\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b5b3ea",
   "metadata": {},
   "source": [
    "6.**special Euclidean group** is the isometry group that:\n",
    "\n",
    "\n",
    "$SE(n)= \\begin{Bmatrix} \\begin{bmatrix} A & t\\\\  0 & 1 \\end{bmatrix}: A \\in SO(n), t\\in  \\mathbb{R}^n \\end{Bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420359e5",
   "metadata": {},
   "source": [
    "## Manifold \n",
    "A manifold is a topological space where every point has a neighborhood that is homeomorphic (topologically equivalent) to an open subset of Euclidean space. \n",
    "\n",
    "\n",
    "\n",
    "**Manifold (Simplified Definition)**: In simpler terms, even if the global structure of the data or space is complex (the manifold shape might be curvy and twisted overall), locally (around each point) it looks like a flat Euclidean space (like a piece of paper).  \n",
    "\n",
    "**Examples**:\n",
    "\n",
    "1. **Surface of a Ball (Sphere)**: Imagine the surface of a basketball. If you're an ant walking on it, the surface seems flat. But from a distance, we see it's curved. So, the surface of the ball is a 2-dimensional manifold. Even though it's curved, every small patch on it feels flat.\n",
    "\n",
    "2. **Twisted Paper (Möbius Strip)**: Take a strip of paper, give it a half-twist, and then tape the two ends together. You've made a Möbius strip. It's a simple example of a manifold with a twist! If you're an ant walking on the strip, it feels flat, but there's a twist in the global structure.\n",
    "\n",
    "3. **Swiss Roll**: Imagine a flat sheet of paper rolled up like a cinnamon roll. The surface of this roll is a manifold. Each point on the roll is on a flat piece, but the overall shape is curved.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f6450",
   "metadata": {},
   "source": [
    "## Tangent  Space and Tangent Vector\n",
    "To study the geometry of a manifold, we need the notion of tangent space, let $\\gamma$ be some curve in some manifold $M$, then its derivative $\\dot {\\gamma} $  is a tangent vector. The space of all these vectors at a particular point $x\\in M $ is called **tangent space** andis denotd by $T_xM$ and\n",
    "$\\text{ dim } T_xM=\\text{ dim }M$.\n",
    "\n",
    "In the below example, we could have infinite vectors like $\\nu$, and the dimention of the tangent space is 2\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/Tangentialvektor.svg\" height=\"50%\" width=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711b906",
   "metadata": {},
   "source": [
    "##  Lie Group\n",
    "A Lie group,is a mathematical structure that combines the properties of both a continuous group and a differentiable manifold. \n",
    "\n",
    "\n",
    "\n",
    "**Group**:  a group is a set equipped with an operation (like addition or multiplication) that combines any two elements to form a third element, subject to certain conditions (closure, associativity, identity element, and inverse elements). Groups serve as a fundamental concept in abstract algebra and are used to study symmetry.\n",
    "\n",
    "\n",
    "**Topological Space**: A set of points, along with a set of neighborhoods for each point, satisfying a set of axioms relating points and neighborhoods. Topology studies properties that are preserved under continuous transformations, such as stretching or bending, but not tearing or gluing.\n",
    "\n",
    "\n",
    "**Continuous Group**: A continuous group, or a topological group, is a group that is also a topological space, meaning it has a notion of nearness or continuity. The group operations (multiplication and taking inverses) are continuous functions with respect to the topology of the space.\n",
    "\n",
    "\n",
    "**Differentiable Manifold**: A differentiable manifold is a space that locally resembles Euclidean space and where one can perform calculus. It's a geometric space that is a generalization of the notion of curves and surfaces.\n",
    "\n",
    "\n",
    "Combining these ideas, a Lie group is a group that is also a differentiable manifold, where the group operations of multiplication and inversion are smooth (infinitely differentiable) maps. This means we can apply calculus directly to the study of these groups. \n",
    "\n",
    "### Examples of Lie Group\n",
    "For example, the set of all rotations in 3D space forms a Lie group known as SO(3). \n",
    "\n",
    "\n",
    "Another example is the group of all real numbers under addition, $\\mathbb{R}$, which is a simple Lie group used extensively in analysis and mathematical physics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fb326a",
   "metadata": {},
   "source": [
    "A matrix group is an algebraic object, however is can be seen as a geometric object since it is a subset of Euclidean space:\n",
    "$\\mathcal{G} \\subset GL_n(\\mathbb{R}) \\subset M_n(\\mathbb{R})\\cong \\mathbb{R}^{n^2} $\n",
    "\n",
    "For instance if youhave $2\\times2$ matix :\n",
    "$\\begin{bmatrix}\n",
    "a & b\\\\ \n",
    "c & d\n",
    "\\end{bmatrix}$\n",
    "\n",
    "you can write it as :\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "a \\\\ b\\\\ \n",
    "c \\\\ d\n",
    "\\end{bmatrix} \\in \\mathbb{R^4}$  \n",
    "\n",
    "Looking at a matrix group as a subset of an Euclidean space, we can discuss its tangent space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc68498",
   "metadata": {},
   "source": [
    "##  Lie Algebra\n",
    "\n",
    "A Lie algebra is a mathematical structure that provides a formal framework for studying the concept of infinitesimal (infinite small) transformations and symmetries. \n",
    "\n",
    "A Lie algebra is a vector space $ \\mathfrak{g} $ over some field $ F $ (commonly the field of real or complex numbers) equipped with a binary operation called the Lie bracket (denoted as $[ \\cdot , \\cdot ]$), which maps any two elements $ x, y $ in $ \\mathfrak{g} $ to another element $ [x, y] $ in $ \\mathfrak{g} $. This Lie bracket operation is subject to the following axioms:\n",
    "\n",
    "1. **Bilinearity**: The Lie bracket is linear in both arguments, meaning for any elements $ x, y, z $ in $ \\mathfrak{g} $ and any scalars $ a, b $ in $ F $,\n",
    "$ [ax + by, z] = a[x, z] + b[y, z] \\quad \\text{and} \\quad [z, ax + by] = a[z, x] + b[z, y]. $\n",
    "\n",
    "2. **Alternativity**: The Lie bracket of any element with itself is zero, i.e.,\n",
    "$ [x, x] = 0 \\quad \\text{for all } x \\in \\mathfrak{g}. $\n",
    "This condition implies that the Lie bracket is anticommutative for distinct elements, since\n",
    "$ [x, y] = -[y, x] \\quad \\text{for all } x, y \\in \\mathfrak{g}. $\n",
    "\n",
    "3. **Jacobi Identity**: The Lie bracket satisfies the Jacobi identity, which is a specific condition of associativity. For any elements $ x, y, z $ in $ \\mathfrak{g} $,\n",
    "$ [x, [y, z]] + [y, [z, x]] + [z, [x, y]] = 0. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25cb83",
   "metadata": {},
   "source": [
    "## Lie Algebra of a Matrix Group \n",
    "\n",
    "The Lie Algebra of a Matrix Group  $ \\mathcal{G} \\subset GL_n(\\mathbb{R})$ is the tangent space to $ \\mathcal{G}$ atthe identity $e$. It is denoted $\\mathfrak{g}=\\mathfrak{g}(\\mathcal{G})=T_e\\mathcal{G}$.\n",
    "\n",
    "\n",
    "Note: the choice of identity is since all groups have identity elements.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b717c",
   "metadata": {},
   "source": [
    "## Lie Algebra and Lie Group\n",
    "\n",
    "\n",
    "Consider a Lie group $G$ represented in $\\mathbb{R} ^ {n \\times n}$ , with $k$ degrees of freedom. The Lie algebra $\\mathfrak {g}$ is the space of differential transformations - the tangent space - around the identity of $G$. This tangent space is a $k$-dimensional vector space with basis elements $\\{ G_1 , . . . , G_k \\}$: the generators. Elements of $g$ are represented as matrices in$\\mathbb{R} ^ {n \\times n}$ , but under addition and scalar multiplication, rather than matrix multiplication.\n",
    "\n",
    "\n",
    "For such a Lie algebra $g$, we write the linear combination of generators $\\{ G_i \\}$ specified by a vector\n",
    "of coefficients $c$ as $alg (c)$.\n",
    "\n",
    "\n",
    "$alg: \\mathbb{R}^k  \\to \\mathfrak {g} \\subset \\mathbb{R}^{n \\times n}$\n",
    "\n",
    "$alg(c) \\equiv \\sum_{i=1}^kc_iG_i$\n",
    "\n",
    "\n",
    "It might seem confusing that a tangent vector is in fact an $n \\times n$ matrix, but it can always be thought of (and represented) as the vector of coefficients of the generators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b83cc3",
   "metadata": {},
   "source": [
    "This definition elaborates on the relationship between a Lie group and its associated Lie algebra by focusing on the representation of the group and the algebraic structure of its tangent space at the identity. Let's break down the key points for clarity:\n",
    "\n",
    "1. **Lie Group Representation in $ \\mathbb{R}^{n \\times n} $**: The statement refers to a Lie group $ G $ that is represented by matrices of size $ n \\times n $, i.e., each element of $ G $ is an $ n \\times n $ matrix. This representation allows us to study the group's properties using the tools of linear algebra and matrix calculus.\n",
    "\n",
    "2. **Degrees of Freedom**: The mention of $ k $ degrees of freedom implies that the group $ G $ can be parameterized by $ k $ independent parameters. This reflects the dimensionality of the manifold underlying $ G $; in other words, locally around any point (and in particular around the identity), you can describe the group's elements using $ k $ independent coordinates or parameters.\n",
    "\n",
    "3. **Lie Algebra $ \\mathfrak{g} $**: The Lie algebra associated with $ G $, denoted here as $ \\mathfrak{g} $, is described as the space of differential transformations, essentially highlighting its role as the tangent space at the identity element of $ G $. This means $ \\mathfrak{g} $ consists of all possible \"directions\" in which one can infinitesimally move away from the identity, encapsulating the local structure of $ G $.\n",
    "\n",
    "4. **Tangent Space and Generators**: The tangent space $ \\mathfrak{g} $ is a $ k $-dimensional vector space. This is consistent with $ G $ having $ k $ degrees of freedom, as each degree of freedom corresponds to a direction in the tangent space. The basis elements $ \\{G_1, \\ldots, G_k\\} $ are referred to as generators. These generators are crucial because any element in $ \\mathfrak{g} $ can be expressed as a linear combination of these basis elements. They are the \"smallest\" infinitesimal transformations that generate the group's structure around the identity.\n",
    "\n",
    "5. **Matrix Representation and Operations**: Elements of $ \\mathfrak{g} $ are represented as matrices in $ \\mathbb{R}^{n \\times n} $, but it's important to distinguish the operations within $ \\mathfrak{g} $ from regular matrix operations. Within $ \\mathfrak{g} $, we consider addition and scalar multiplication (the vector space operations) rather than matrix multiplication. The Lie bracket (e.g., the commutator $[A, B] = AB - BA$ for matrices $A, B$) defines the algebraic structure beyond the vector space, capturing the notion of infinitesimal commutation.\n",
    "\n",
    "The essence of this definition is that it links the abstract algebraic concept of a Lie algebra to the more concrete notion of matrices and transformations, making it easier to visualize and understand the infinitesimal structure of Lie groups. The generators play a key role as the fundamental building blocks of the group's algebraic structure, highlighting how movements in the group can be decomposed into movements along these basic directions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee2560",
   "metadata": {},
   "source": [
    "## Exponential Map and Logarithm\n",
    "\n",
    "The exponential map takes elements in the **algebra** $\\mathfrak {g}$ to elements in the **group** $G$. Intuitively speaking,\n",
    "it walks along the group manifold in the differential direction specified by the tangent vector in the\n",
    "algebra. For matrix groups the exponential map is simply matrix exponentiation\n",
    "\n",
    "\n",
    "$exp:  \\mathfrak {g} \\to G$\n",
    "\n",
    "$exp(x) =I +x+ \\frac{1}{2!}x^2  + \\frac{1}{3!}x^3+ ...+ \\frac{1}{i!}x^i + ...   $\n",
    "\n",
    "For some groups, the exponential map has a closed form. It is always a continuous map.\n",
    "\n",
    "The inverse of the exponential map is the logarithm:\n",
    "\n",
    "\n",
    "$\\text{exp (log ( X ))} =X $\n",
    "\n",
    "\n",
    "The logarithm is usually not continuous everywhere, but is always continuous near the identity.\n",
    "Note that for most groups, including all groups with compact subgroups such as rotations, neither\n",
    "exp nor log is injective.\n",
    "\n",
    "\n",
    "### Adjoint Representation\n",
    "Consider tangent vectors $a, b \\in   \\mathfrak {g}$ and a group element $X \\in G$. How can we choose b such that the following relation holds: \n",
    "\n",
    "$ exp (b) · X = X · exp ( a)  $ are \n",
    "\n",
    "\n",
    "For instnce, $a \\in \\mathfrak {se(3)}$ which is a twist vector, expressed at the point identity, we have a group element $X \\in G=SE(3)$ which a transformation matrix, we want to find the correspondong twist in that transformation matrix.\n",
    "\n",
    "\n",
    "Right multiplying both sides by $X^{-1}$\n",
    "\n",
    "$exp (b) = X · exp ( a) · X^{-1}$\n",
    "\n",
    "\n",
    "$b = log( X · exp ( a) · X^{-1})$\n",
    "\n",
    "The identical result can be obtained by using the adjoint representation. A group $G \\subset R^{n \\times n}$ with $k$ degrees of freedom has an isomorphic representation as the group of linear ransformations on $\\mathfrak {g} $, called the adjoint:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$X \\in G$ \n",
    "\n",
    "$a \\in g$\n",
    "\n",
    "\n",
    "$\\text{Adj}_X: \\mathfrak {g} \\rightarrow \\mathfrak {g}$ \n",
    "\n",
    "$  \\text{Adj}_X(a) = X \\cdot a \\cdot X^{-1} \\in \\mathfrak {g} $\n",
    "\n",
    "<img src=\"images/adjoint_matrix.png\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618bf6c-5f16-42fe-9932-bbe351e11f3e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Elements of the adjoint representation are usually written as $k \\times k$ matrices acting on the coefficient vectors of elements in $\\mathfrak {g}$ by multiplication. The adjoint representation preserves the group structure of $G$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{If } X, Y \\in G, \\text{ then } \\text{Adj}_{X \\cdot Y} = \\text{Adj}_X \\cdot \\text{Adj}_Y\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\text{Adj}_{X^{-1}} = \\text{Adj}_{X}^{-1}\n",
    "\\end{equation}\n",
    "\n",
    "Defining $b$ using the adjoint representation:\n",
    "\\begin{equation}\n",
    "    b \\equiv \\text{Adj}_X(a)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\Rightarrow \\exp(b) = X \\cdot \\exp(a) \\cdot X^{-1}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\Rightarrow \\exp(b) \\cdot X = X \\cdot \\exp(a)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08771f9e",
   "metadata": {},
   "source": [
    "### Example of Adjoint representaion  Twist\n",
    "twist is full representation of linear and angular velocity:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\nu=\\begin{bmatrix}\\omega&space;\\\\&space;v\\end{bmatrix}_{6\\times1}=s\\dot\\theta\" title=\"https://latex.codecogs.com/svg.image?\\nu=\\begin{bmatrix}\\omega \\\\ v\\end{bmatrix}_{6\\times1}=s\\dot\\theta\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "The $6\\times 6$ adjoint representation of a transformation matrix $T=\\begin{bmatrix}R & p \\\\0 & 1 \\\\\\end{bmatrix}$ is:\n",
    "\n",
    "\n",
    "$\\begin{bmatrix}Ad_T\\end{bmatrix}=\\begin{bmatrix}R & 0 \\\\ [p]R & R \\\\\\end{bmatrix}\\in \\mathbb{R}^{6\\times6}$\n",
    "\n",
    "which enable us the subscribe cancaltion for chaining the frame of reference\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\nu_a=[Ad_T_{ab}]\\nu_{b}\" title=\"https://latex.codecogs.com/svg.image?\\nu_a=[Ad_T_{ab}]\\nu_{b}\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For angular velocity we had:\n",
    "<br/>\n",
    "<br/>\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\dot{R_{sb}}&space;=[\\omega_s]R_{sb}\" title=\"https://latex.codecogs.com/svg.image?\\dot{R_{sb}} =[\\omega_s]R_{sb}\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\dot{R_{sb}}R_{sb}^{-1}&space;=[\\omega_s]\\in&space;so(3)\" title=\"https://latex.codecogs.com/svg.image?\\dot{R_{sb}}R_{sb}^{-1} =[\\omega_s]\\in so(3)\" />\n",
    "<br/>\n",
    "<br/>\n",
    "similarly for twist we have:\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\dot{T_{sb}}T_{sb}^{-1}=\\begin{bmatrix}&space;[\\omega_s]&space;&&space;v_s&space;\\\\&space;0&&space;&space;0\\\\\\end{bmatrix}&space;=[\\nu_s]\\in&space;se(3)\" title=\"https://latex.codecogs.com/svg.image?\\dot{T_{sb}}T_{sb}^{-1}=\\begin{bmatrix} [\\omega_s] & v_s \\\\ 0& 0\\\\\\end{bmatrix} =[\\nu_s]\\in se(3)\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f5ff9",
   "metadata": {},
   "source": [
    "## Examples of Lie algebra\n",
    "### SO(2)\n",
    "\n",
    "SO(2) is the group of rotations in the 2D plane. It has **one degree of freedom**: angle of rotation. The group is commutative. The inverse is given by the transpose:\n",
    "\n",
    "\n",
    "$X \\in  SO(2) \\subset  \\mathbb{R}^{2\\times2} $\n",
    "\n",
    "\n",
    "$X^{-1} =X^T $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Lie Group\n",
    "\n",
    "A Lie group is a group that is also a differentiable manifold, with the property that the group operations (multiplication and inversion) are smooth. The special orthogonal group $SO(2)$ represents rotations in 2D space and is a Lie group. Each element of $SO(2)$ can be represented as a rotation matrix:\n",
    "\n",
    "$\n",
    "R(\\theta) = \\begin{pmatrix}\n",
    "\\cos(\\theta) & -\\sin(\\theta) \\\\\n",
    "\\sin(\\theta) & \\cos(\\theta)\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "where $\\theta$ is the rotation angle.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Lie Algebra\n",
    "\n",
    "\n",
    "The Lie algebra of a Lie group is the tangent space at the identity element of the group. The Lie algebra $\\mathfrak{so}(2)$ is generated by one antisymmetric element:\n",
    "\\begin{equation}\n",
    "    G_1 = \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Exponential Map\n",
    "\n",
    "The exponential map is a map from the Lie algebra $\\mathfrak{so}(2)$  to the Lie group $SO(2)$, providing a way to \"exponentiate\" algebra elements to get group elements. For $SO(2)$, the exponential map takes a matrix in $\\mathfrak{so}(2)$ and maps it to a matrix in $SO(2)$. Using the matrix exponential, we have:\n",
    "\n",
    "$\n",
    "\\exp(A(\\phi)) = \\exp\\left( \\begin{pmatrix}\n",
    "0 & -\\phi \\\\\n",
    "\\phi & 0\n",
    "\\end{pmatrix} \\right) = \\begin{pmatrix}\n",
    "\\cos(\\phi) & -\\sin(\\phi) \\\\\n",
    "\\sin(\\phi) & \\cos(\\phi)\n",
    "\\end{pmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce7e8a",
   "metadata": {},
   "source": [
    "###  SE(2) \n",
    "- **Definition**: $ SE(2) $ is the group of rigid transformations in the 2D plane, which can be seen as the semi-direct product of $ SO(2) $ and $ \\mathbb{R}^2 $. It represents transformations that include both rotation and translation.\n",
    "- **Degrees of Freedom**: It has three degrees of freedom, corresponding to two for translation along the x and y axes, and one for rotation.\n",
    "- **Mathematical Representation**: A transformation in $ SE(2) $ can be represented by a 3x3 matrix, combining rotation ($ R $ in $ SO(2) $) and translation ($ t $ in $ \\mathbb{R}^2 $) components.\n",
    "- **Inverse Transformation**: The document also provides the formula for the inverse transformation in $ SE(2) $.\n",
    "\n",
    "### Lie Algebra\n",
    "- **Generators (liner algebra basis)**: The Lie algebra $\\mathfrak{so}(2)$ associated with $ SE(2) $ has three generators, which are matrices that essentially encode the infinitesimal transformations corresponding to rotations and translations in the plane.\n",
    "\n",
    "$\n",
    "G_1 = \\begin{pmatrix}\n",
    "0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}, \\quad\n",
    "G_2 = \\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}, \\quad\n",
    "G_3 = \\begin{pmatrix}\n",
    "0 & -1 & 0 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "###  Exponential Map\n",
    "- **Function**: The exponential map is a crucial concept in Lie theory, connecting the Lie algebra $\\mathfrak{se}(2)$ to the Lie group $ SE(2) $ through an exponential operation.\n",
    "- **Closed Form**: The document details the closed-form of the exponential map for $\\mathfrak{se}(2)$, which is used to compute finite transformations from infinitesimal ones. This involves the use of the rotation matrix $ R $ and a matrix $ V $ derived from $ \\theta $ (rotation angle) and the translation vector.\n",
    "\n",
    "\n",
    "$v = \\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "\\theta\n",
    "\\end{pmatrix} \\in \\mathbb{R}^3, \\quad R \\equiv \\begin{pmatrix}\n",
    "\\cos\\theta & \\sin\\theta \\\\\n",
    "-\\sin\\theta & \\cos\\theta\n",
    "\\end{pmatrix}, \\quad V = \\begin{pmatrix}\n",
    "\\frac{\\sin\\theta}{\\theta} & \\frac{1-\\cos\\theta}{\\theta} \\\\\n",
    "\\frac{-1+\\cos\\theta}{\\theta} & \\frac{\\sin\\theta}{\\theta}\n",
    "\\end{pmatrix}. $\n",
    "\n",
    "$ \\exp(\\text{alg}(v)) = \\exp \\begin{pmatrix}\n",
    "\\theta & -\\theta & x \\\\\n",
    "\\theta & \\theta & y \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "R & \\frac{V}{\\theta} \\cdot \\begin{pmatrix} x \\\\ y \\end{pmatrix} \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix} $\n",
    "\n",
    "\n",
    "\n",
    "### Adjoint Representation\n",
    "- **Representation**: It discusses the adjoint representation of $ SE(2) $, which is a way to describe how the group transformations affect its own Lie algebra. This concept is essential in understanding how different transformations in $ SE(2) $ relate to each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf270be8",
   "metadata": {},
   "source": [
    "## Continuous integration over the 3D rotation group SO(3)\n",
    "### Mathematical Representation\n",
    "\n",
    "The rotation group $SO(3)$ can be mathematically represented in several ways, including rotation matrices, Euler angles, and quaternions:\n",
    "\n",
    "- **Rotation Matrices**: A 3x3 matrix that rotates vectors in 3D space. Every matrix in $SO(3)$ is orthogonal ($R^{-1} = R^T$) with a determinant of 1.\n",
    "- **Euler Angles**: A representation of a 3D rotation through three angles, often denoted as $\\phi$, $\\theta$, and $\\psi$. While intuitive, they suffer from gimbal lock.\n",
    "- **Quaternions**: An extension of complex numbers used to represent rotations that avoid singularities and discontinuities common with Euler angles.\n",
    "\n",
    "### Integration Techniques\n",
    "\n",
    "Integrating over $SO(3)$ usually requires numerical methods, especially for complex functions or applications. Techniques may include:\n",
    "\n",
    "- **Monte Carlo Integration**: A probabilistic method that samples points over the rotation space to approximate the integral. Useful for high-dimensional spaces or complex integrands.\n",
    "- **Quadrature Rules**: Deterministic methods that approximate the integral using weighted sums of function evaluations at specific points. For $SO(3)$, specialized quadrature rules can be applied.\n",
    "- **Symmetry Exploitation**: Taking advantage of the symmetries in $SO(3)$ to reduce the complexity of the integration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e2a63",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "\n",
    "Consider a function $f(R)$ defined on $SO(3)$ that returns the square of the $z$-component of the unit vector along the body's $x$-axis after rotation $R$. We want to integrate this function over all possible rotations in $SO(3)$.\n",
    "\n",
    "Mathematically, the function can be expressed as:\n",
    "\n",
    "$f(R) = (R \\cdot \\mathbf{e}_x)_z^2$\n",
    "\n",
    "where $R$ is a rotation matrix in $SO(3)$, $\\mathbf{e}_x = [1, 0, 0]^T$ is the unit vector along the $x$-axis, and $(R \\cdot \\mathbf{e}_x)_z$ is the $z$-component of the rotated vector.\n",
    "\n",
    "The goal is to compute the integral:\n",
    "\n",
    "$I = \\int_{SO(3)} f(R) \\, dR$\n",
    "\n",
    "### Solution Approach\n",
    "\n",
    "A direct analytic solution of this integral over $SO(3)$ is challenging. However, for this particular function, symmetry and properties of $SO(3)$ allow for a simplified approach. Since the integration is over all possible orientations, and the function depends only on the square of the $z$-component of a rotated vector, which is symmetric with respect to the orientation, we can infer that the integral should be uniformly distributed over all directions.\n",
    "\n",
    "Given that any rotation can be thought of as rotating into any possible orientation with equal probability, the average value of the square of any component (x, y, or z) of a vector after a random rotation should be $\\frac{1}{3}$, considering the vector's length is 1.\n",
    "\n",
    "Therefore, without performing a detailed calculation, we can argue that the integral $I$ over $SO(3)$ for our function $f(R)$ will be:\n",
    "\n",
    "$I = \\frac{1}{3}$\n",
    "\n",
    "This is because, after integration over all possible orientations, each component $x$, $y$, and $z$ of the rotated vector contributes equally to the squared sum, due to isotropy of space and the integral covering all possible orientations uniformly.\n",
    "\n",
    "This solution leverages symmetry and probabilistic reasoning rather than explicit computation. For more complex functions, numerical integration techniques specific to $SO(3)$ would be required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3638a4",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "Imagine a robotic arm that can rotate freely around its base in all three dimensions. The arm's orientation at any moment is described by a rotation matrix $R$ in $SO(3)$. The robot is tasked with positioning a sensor to map environmental features. The sensor's effectiveness, $E(R)$, at any orientation depends on how well it aligns with a particular environmental feature of interest. Let's simplify and say $E(R)$ is maximized when the arm points directly at the feature and decreases as the cosine of the angle away from that feature. \n",
    "\n",
    "Our goal is to calculate the average effectiveness of the sensor over all possible orientations of the robotic arm to understand its average performance in an isotropic environment. Mathematically, this could be represented as an integral of $E(R)$ over $SO(3)$.\n",
    "\n",
    "### Simplified Model for Example\n",
    "For simplicity, assume the environmental feature is located along the global $z$-axis, and the sensor's effectiveness is proportional to the dot product between the arm's orientation (pointing vector) and the $z$-axis vector $\\mathbf{e}_z = [0, 0, 1]^T$. This gives us:\n",
    "\n",
    "$E(R) = \\cos(\\theta) = R \\cdot \\mathbf{e}_z \\cdot \\mathbf{e}_s$\n",
    "\n",
    "where $\\mathbf{e}_s$ is the sensor's pointing direction in the robot's frame (let's assume it points along the robot's $x$-axis, so $\\mathbf{e}_s = [1, 0, 0]^T$ when not rotated). The cosine of the angle $\\theta$ between the sensor direction and the $z$-axis is given by the dot product between the rotated sensor direction and $\\mathbf{e}_z$.\n",
    "\n",
    "The average effectiveness, $\\bar{E}$, over all orientations is then given by:\n",
    "\n",
    "$\\bar{E} = \\frac{1}{|SO(3)|} \\int_{SO(3)} E(R) \\, dR$\n",
    "\n",
    "where $|SO(3)|$ is the \"size\" of $SO(3)$, or the total measure of the space.\n",
    "\n",
    "### Solution Approach\n",
    "\n",
    "Given that the sensor effectiveness depends on the cosine of the angle between the sensor's pointing direction and the $z$-axis, and considering the integration over the entire rotation group, the problem simplifies to evaluating how the sensor's orientation uniformly distributes over all directions. \n",
    "\n",
    "Because the space is isotropic and $SO(3)$ integrates over all possible orientations, the average dot product between any fixed vector and a uniformly distributed vector over the sphere is zero. This is due to the symmetry of the sphere, where for every vector there is an opposite vector, and their contributions to the integral cancel out.\n",
    "\n",
    "However, since $E(R)$ depends on the cosine of the angle, which is always non-negative when considering only the angle between 0 and $\\pi/2$ (and symmetric around the sphere), the problem slightly adjusts. The effective contribution over half the sphere would be positive, and considering the symmetry, this means the average over the whole sphere should account for the absolute value of the cosine function contributions, normalized over the half-sphere.\n",
    "\n",
    "In this simplified context and reasoning, without delving into complex calculus over $SO(3)$, the exact average value can be hard to derive intuitively. Normally, you'd need to perform the integral calculation explicitly, often through numerical methods, due to the complex nature of $SO(3)$. Yet, the conceptual takeaway is understanding that such integration averages out the orientation-based effects across all possible orientations, providing a holistic measure of performance or effectiveness in isotropic conditions.\n",
    "\n",
    "For a more concrete value or detailed analysis, one would likely turn to numerical simulation or specific integration techniques tailored to the problem at hand, which could involve sampling from $SO(3)$ or employing specialized algorithms designed to work with rotations and their representations (like quaternions or rotation matrices)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a677873",
   "metadata": {},
   "source": [
    "## Group Action vs Group Operation\n",
    "\n",
    "In the context of group theory within mathematics, it's important to distinguish between **group operations** and **group actions**. Let's clarify these two terms:\n",
    "\n",
    "### Group Operation\n",
    "\n",
    "A **group operation** is a binary function that combines two elements of a group to produce another element of the same group. This operation must satisfy four key properties (closure, associativity, identity, and invertibility) which define the mathematical structure of a group. \n",
    "\n",
    "**Examples of Group Operations:**\n",
    "- **Addition** in the group of integers $\\mathbb{Z}$ under addition. Here, the operation is $+$, combining any two integers to form another integer.\n",
    "- **Matrix Multiplication** in the group of all $n \\times n$ invertible matrices (the general linear group $GL(n, \\mathbb{R})$). The operation is matrix multiplication, where combining two invertible matrices by multiplication yields another invertible matrix.\n",
    "\n",
    "### Group Action\n",
    "\n",
    "A **group action** is a rule for how the elements of a group systematically transform elements in another set. This set does not necessarily have to be a group; it could be any set. The action must satisfy two main properties related to the group's identity and the operation's associativity.\n",
    "\n",
    "**Examples of Group Actions:**\n",
    "- **Matrix Acting on Vectors**: The group $GL(n, \\mathbb{R})$ can act on the vector space $\\mathbb{R}^n$ via matrix multiplication. For a matrix $A \\in GL(n, \\mathbb{R})$ and a vector $x \\in \\mathbb{R}^n$, the action is $A \\cdot x$, resulting in another vector in $\\mathbb{R}^n$.\n",
    "- **Rotation Groups**: The special orthogonal group $SO(n)$ acts on $\\mathbb{R}^n$ by rotating vectors. Each element of $SO(n)$ (each matrix) can be applied to vectors in $\\mathbb{R}^n$, rotating them while preserving their norms.\n",
    "\n",
    "### Distinguishing Operation and Action\n",
    "\n",
    "- **Operation** relates directly to the algebraic structure of the group itself and defines how its elements combine.\n",
    "- **Action** extends the influence of the group to an external set, describing how the group’s elements can be applied as operations (transformations) on the members of this set.\n",
    "\n",
    "### Application in Linear Algebra\n",
    "\n",
    "Considering $GL(n, \\mathbb{R})$ acting on $\\mathbb{R}^n$:\n",
    "- **Operation**: Matrix multiplication within $GL(n, \\mathbb{R})$.\n",
    "- **Action**: Matrix multiplication between an element of $GL(n, \\mathbb{R})$ and an element of $\\mathbb{R}^n$. \n",
    "\n",
    "This distinction is critical when applying group theory to problems in physics (like symmetry operations in quantum mechanics), computer graphics (like transformations in 3D modeling), and engineering (like robotic arm movements and control systems), where both the internal structure of the group and its external effects via action are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca87781",
   "metadata": {},
   "source": [
    "A group action on $\\mathbb{R}^n$, where $n$ is a positive integer, involves a group $G$ acting on the $n$-dimensional real vector space $\\mathbb{R}^n$. This kind of action can be visualized as the group elements being transformations that map vectors in $\\mathbb{R}^n$ to other vectors in $\\mathbb{R}^n$. Common groups that perform such actions include matrix groups, which use matrix multiplication to implement these transformations.\n",
    "\n",
    "### Examples of Group Actions on $\\mathbb{R}^n$\n",
    "\n",
    "#### 1. General Linear Group: $GL(n, \\mathbb{R})$\n",
    "\n",
    "- **Group Definition**: The general linear group $GL(n, \\mathbb{R})$ consists of all $n \\times n$ invertible matrices with real entries. The operation is matrix multiplication.\n",
    "- **Action**: A matrix $A$ in $GL(n, \\mathbb{R})$ acts on a vector $x \\in \\mathbb{R}^n$ by matrix multiplication, $A \\cdot x$. This action is transitive on $\\mathbb{R}^n \\setminus \\{0\\}$ (all non-zero vectors), meaning there is a matrix that transforms any non-zero vector to any other non-zero vector.\n",
    "\n",
    "#### 2. Special Orthogonal Group: $SO(n)$\n",
    "\n",
    "- **Group Definition**: The special orthogonal group $SO(n)$ includes all $n \\times n$ orthogonal matrices with determinant 1. These matrices represent rotations around the origin in $n$-dimensional space.\n",
    "- **Action**: An orthogonal matrix $Q$ in $SO(n)$ acts on $x \\in \\mathbb{R}^n$ as $Q \\cdot x$. This preserves the Euclidean norm ($\\|x\\|$) and is crucial in applications involving rotations, such as in physics and engineering for maintaining orientation and distance.\n",
    "\n",
    "#### 3. Orthogonal Group: $O(n)$\n",
    "\n",
    "- **Group Definition**: The orthogonal group $O(n)$ consists of all $n \\times n$ orthogonal matrices. This group includes both rotations and reflections, depending on the determinant being 1 or -1, respectively.\n",
    "- **Action**: For $Q \\in O(n)$, the action on $x \\in \\mathbb{R}^n$ is $Q \\cdot x$, preserving the norm of $x$ but possibly reversing orientation (if $\\det(Q) = -1$).\n",
    "\n",
    "### Properties of Group Actions\n",
    "\n",
    "1. **Preservation of Structure**:\n",
    "   - Actions by groups like $GL(n, \\mathbb{R})$, $SO(n)$, and $O(n)$ preserve certain algebraic or geometric structures. For $SO(n)$ and $O(n)$, the length of vectors (norms) and angles between vectors are invariant under the action.\n",
    "\n",
    "2. **Orbits**:\n",
    "   - The orbit of a vector $x$ under a group $G$ is the set of all vectors that can be reached from $x$ by the actions of elements in $G$. For $GL(n, \\mathbb{R})$, the orbit of any non-zero vector is all of $\\mathbb{R}^n \\setminus \\{0\\}$.\n",
    "\n",
    "3. **Stabilizers**:\n",
    "   - The stabilizer of a vector $x$ in $G$ (denoted $G_x$) consists of all elements in $G$ that leave $x$ unchanged (i.e., $g \\cdot x = x$). For example, in $SO(n)$, the stabilizer of a non-zero vector includes all rotations that rotate within the subspace orthogonal to $x$.\n",
    "\n",
    "4. **Transitivity**:\n",
    "   - A group action is transitive if there is only one orbit for the action, meaning any vector can be transformed into any other vector via some group element. $GL(n, \\mathbb{R})$ acts transitively on $\\mathbb{R}^n \\setminus \\{0\\}$.\n",
    "\n",
    "These properties and the structure of group actions are utilized extensively in many fields including physics (symmetry operations), engineering (transformations and controls), and computer graphics (manipulating shapes and objects). Group actions provide a powerful framework for understanding and exploiting symmetries in complex systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b8fb4",
   "metadata": {},
   "source": [
    "$w=\\begin{bmatrix}\n",
    "w_1\n",
    "\\\\ \n",
    "w_2\n",
    "\\\\ \n",
    "w_3\n",
    "\\end{bmatrix} \\in \\mathbb{R}^3$\n",
    "\n",
    "**wedge notation:**\n",
    "\n",
    "$w^\\wedge  = \\begin{bmatrix}\n",
    "0  && w_3 && -w_2\\\\ \n",
    "-w_3 && 0 && w_1\\\\ \n",
    "w_2 && -w_1 && 0\n",
    "\\end{bmatrix} \\in \\mathfrak{so(3)}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**vee notation:**\n",
    "\n",
    "$  S=w^\\wedge  = \\begin{bmatrix} 0  && w_3 && -w_2\\\\  -w_3 && 0 && w_1\\\\  w_2 && -w_1 && 0 \\end{bmatrix} \\in \\mathfrak{so(3)} $\n",
    "\n",
    "$ S^\\vee =(w^\\wedge)^\\vee =\\begin{bmatrix} w_1 \\\\ w_2 \\\\  w_3 \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726234b3",
   "metadata": {},
   "source": [
    "$G_1 = \\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "0 & -1 & 0\n",
    "\\end{pmatrix}, \\quad\n",
    "G_2 = \\begin{pmatrix}\n",
    "0 & 0 & -1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "1 & 0 & 0\n",
    "\\end{pmatrix}, \\quad\n",
    "G_3 = \\begin{pmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "-1 & 0 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}$\n",
    "\n",
    "\n",
    "$ e_1=\\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "$ e_2=\\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "$ e_3=\\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "$w^\\wedge = w_1G_1 +w_2G_2+w_3G_3$\n",
    "\n",
    "\n",
    "$w= w_1e_1 +w_2e_2+w_3e_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562c88d3",
   "metadata": {},
   "source": [
    "### Cross Product and Lie Bracket\n",
    "\n",
    "$e_1\\times e_2=e_3 $\n",
    "\n",
    "$e_2\\times e_1=-e_3 $\n",
    "\n",
    "$\\left [  G_1,G_2 \\right ]:=G_1G_2 -G_2G_1=G_3$\n",
    "\n",
    "$\\left [  G_2,G_1 \\right ]=-G_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cffb172",
   "metadata": {},
   "source": [
    "For any $R\\in SO(3)$ we know that: \n",
    "\n",
    "$R^TR=I$\n",
    "\n",
    "$RR^T=I$\n",
    "\n",
    "If we take derivative:\n",
    "\n",
    "$\\frac{d(R^TR)}{dt}=\\overset{.}R^TR + R^T\\overset{.}R  = 0$\n",
    "\n",
    "which gives us:\n",
    "\n",
    "$\\overset{.}R^TR =- R^T\\overset{.}R \\in \\mathfrak{so(3)}$\n",
    "\n",
    "This only true for skew symmetric matrices:\n",
    "\n",
    "$R^T\\dot{R}= \\begin{bmatrix}\n",
    "0 & -\\omega_z  & \\omega_y\\\\ \n",
    "\\omega_z & 0 & -\\omega_x\\\\ \n",
    "\\omega_y & \\omega_z &  \n",
    "\\end{bmatrix}$\n",
    "\n",
    "since Lie alegbra is ientity $R=I$:\n",
    "\n",
    "$\\dot{R}= \\begin{bmatrix}\n",
    "0 & -\\omega_z  & \\omega_y\\\\ \n",
    "\\omega_z & 0 & -\\omega_x\\\\ \n",
    "\\omega_y & \\omega_z &  \n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "also: \n",
    "$\\frac{d(RR^T)}{dt}=\\overset{.}R R^T  + R \\overset{.}R^T  =0 $\n",
    "\n",
    "which gives us:\n",
    "\n",
    "$\\overset{.}R R^T  =- R \\overset{.}R^T \\in \\mathfrak{so(3)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d5f03",
   "metadata": {},
   "source": [
    "Rotation properties: (As the triangle stays a triangle after rotation)\n",
    "\n",
    "Rotation is linear: \n",
    "$\\text{Rotate} (\\text{v+w})= \\text{Rotate} (\\text{v}) +\\text{Rotate} (\\text{w})$\n",
    "\n",
    "Rotation is linear: \n",
    "\n",
    "$\\text{Rotate} (\\lambda v)= \\lambda \\text{Rotate} (\\text{v}) $\n",
    "\n",
    "\n",
    "\n",
    "$\\text{Rotate} (\\text{v})=  \\text{R}\\text{v} $\n",
    "\n",
    "After rotation length and angle are preserved which hint that dot products are also preserved:\n",
    "\n",
    "\n",
    "$\\text{v.w} = (\\text{Rv}) . (\\text{Rw}) $\n",
    "\n",
    "In the case of real vectors, we can write the dot product as transpose multiplications:\n",
    "\n",
    "$\\text{v}.\\text{w}= \\text{v} ^T \\text{w}$\n",
    "\n",
    "\n",
    "$ \\text{v}^T\\text{w} = (\\text{Rv})^T . (\\text{Rw}) =\\text{v}^T \\text{R}^T \\text{R} \\text{w}  $\n",
    "\n",
    "which means\n",
    "\n",
    "$\\text{R}^T \\text{R}=I$\n",
    "\n",
    "For complex numbers, instead of transpose, we have conjugated transpose which displayed by simbol $\\dagger$:\n",
    "\n",
    "\n",
    "$\\text{v}.\\text{w}= \\text{v}^ \\dagger \\text{w}$\n",
    "\n",
    "$ \\text{v}^\\dagger \\text{w} = (\\text{Uv})^\\dagger . (\\text{Uw}) =\\text{v}^\\dagger \\text{U}^\\dagger \\text{U} \\text{w}  $\n",
    "\n",
    "$U(n)=\\{ \\text{U is } n\\times n, \\text{U}^\\dagger  \\text{U}=I \\}$\n",
    "\n",
    "\n",
    "$SU(n)=\\{ U \\in \\text{U(n)}, \\text{ det U}=1 \\}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f857d7d",
   "metadata": {},
   "source": [
    "Refs: [1](https://www.youtube.com/watch?v=2f0uWEWGr-E&list=PLdMorpQLjeXmbFaVku4JdjmQByHHqTd1F&index=9), [2](https://www.youtube.com/playlist?list=PLDcSwjT2BF_WDki-WvmJ__Q0nLIHuNPbP), [3](https://www.math.stonybrook.edu/~kirillov/mat552/liegroups.pdf), [4](https://ethaneade.com/lie_groups.pdf), [5](https://www.youtube.com/watch?v=csolG83gCV8), [6](https://www.youtube.com/playlist?list=PLRlVmXqzHjURZO0fviJuyikvKlGS6rXrb),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a8f29d",
   "metadata": {},
   "source": [
    "## Matrix Similarity\n",
    "Matrix similarity is a concept in linear algebra that describes a relationship where two square matrices represent the same linear transformation under different bases. Specifically, two matrices $ A $ and $ B $ are similar if there exists an invertible matrix $ P $ such that:\n",
    "\n",
    "$\n",
    "B = P^{-1}AP\n",
    "$\n",
    "\n",
    "This definition implies that similar matrices have the same eigenvalues, the same characteristic polynomial, and the same trace, among other properties. However, their actual entries might be different, reflecting the basis change encoded by $ P $.\n",
    "\n",
    "### Example of Matrix Similarity\n",
    "\n",
    "Let’s consider a practical example to illustrate matrix similarity:\n",
    "\n",
    "#### Matrices Definition\n",
    "\n",
    "Suppose we have matrix $ A $ and we want to find a matrix $ B $ that is similar to $ A $, given by:\n",
    "\n",
    "$\n",
    "A = \\begin{pmatrix} 4 & -5 \\\\ 2 & -3 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "We choose a matrix $ P $ for the transformation, say:\n",
    "\n",
    "$\n",
    "P = \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "#### Calculate $ P^{-1} $\n",
    "\n",
    "First, we need to calculate $ P^{-1} $:\n",
    "\n",
    "The inverse of a 2x2 matrix $ \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} $ is given by:\n",
    "\n",
    "$\n",
    "P^{-1} = \\frac{1}{ad - bc} \\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}\n",
    "$\n",
    "\n",
    "For matrix $ P $:\n",
    "\n",
    "$\n",
    "P^{-1} = \\frac{1}{(1)(0) - (1)(1)} \\begin{pmatrix} 0 & -1 \\\\ -1 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 1 & -1 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "#### Calculate $ B = P^{-1}AP $\n",
    "\n",
    "Now, calculate $ B $ using $ B = P^{-1}AP $:\n",
    "\n",
    "$\n",
    "AP = \\begin{pmatrix} 4 & -5 \\\\ 2 & -3 \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 4-5 & 4 \\\\ 2-3 & 2 \\end{pmatrix} = \\begin{pmatrix} -1 & 4 \\\\ -1 & 2 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "Then,\n",
    "\n",
    "$\n",
    "B = P^{-1}AP = \\begin{pmatrix} 0 & 1 \\\\ 1 & -1 \\end{pmatrix} \\begin{pmatrix} -1 & 4 \\\\ -1 & 2 \\end{pmatrix} = \\begin{pmatrix} -1 & 2 \\\\ 0 & 2 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Matrix $ B $ is:\n",
    "\n",
    "$\n",
    "B = \\begin{pmatrix} -1 & 2 \\\\ 0 & 2 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "And we find that $ B $ is similar to $ A $ because we derived it using $ B = P^{-1}AP $ with an invertible matrix $ P $. Thus, $ A $ and $ B $ represent the same linear transformation in different bases, confirming their similarity.\n",
    "\n",
    "This process illustrates how changing bases with matrix $ P $ and its inverse transforms matrix $ A $ into a new matrix $ B $ that, while possibly looking different, shares many fundamental properties with $ A $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144cfdb",
   "metadata": {},
   "source": [
    "\n",
    "### Example: Robotic Arm with Different Coordinate Frames\n",
    "\n",
    "Suppose we have a robotic arm with two major components:\n",
    "\n",
    "1. **Base Frame (B-frame)**: The origin of the coordinate system from which the position of the robotic arm is controlled.\n",
    "2. **End-Effector Frame (E-frame)**: The coordinate system at the gripper of the robotic arm, used for precise manipulation tasks.\n",
    "\n",
    "#### Task\n",
    "\n",
    "The task is to transform the representation of a linear transformation (matrix representing a rotation followed by a translation) from the B-frame to the E-frame. \n",
    "\n",
    "#### Definitions\n",
    "\n",
    "Let's assume the transformation matrix in the B-frame is:\n",
    "\n",
    "$\n",
    "A_{B} = \\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) & x \\\\ \\sin(\\theta) & \\cos(\\theta) & y \\\\ 0 & 0 & 1 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "where $ \\theta $ is the rotation angle, and $ (x, y) $ is the translation vector in the B-frame. \n",
    "\n",
    "To transform this matrix to the E-frame, we need the transformation matrix $ P $ that changes coordinates from the E-frame to the B-frame. Let's define $ P $ as a rotation matrix (assuming for simplicity, the origin of E-frame coincides with the B-frame, focusing only on rotation):\n",
    "\n",
    "$\n",
    "P = \\begin{pmatrix} \\cos(\\phi) & -\\sin(\\phi) & 0 \\\\ \\sin(\\phi) & \\cos(\\phi) & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "#### Calculate $ P^{-1} $\n",
    "\n",
    "The inverse of a rotation matrix $ P $ (which is an orthogonal matrix) is its transpose:\n",
    "\n",
    "$\n",
    "P^{-1} = P^T = \\begin{pmatrix} \\cos(\\phi) & \\sin(\\phi) & 0 \\\\ -\\sin(\\phi) & \\cos(\\phi) & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "#### Calculate $ A_{E} = P^{-1}A_{B}P $\n",
    "\n",
    "$\n",
    "A_{E} = P^T A_{B} P = \\begin{pmatrix} \\cos(\\phi) & \\sin(\\phi) & 0 \\\\ -\\sin(\\phi) & \\cos(\\phi) & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) & x \\\\ \\sin(\\theta) & \\cos(\\theta) & y \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\cos(\\phi) & -\\sin(\\phi) & 0 \\\\ \\sin(\\phi) & \\cos(\\phi) & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n",
    "$\n",
    "\n",
    "This matrix multiplication, though straightforward, involves combining rotations and translating the effect of these rotations through the translation vector. The resultant matrix $ A_{E} $ will still be a combination of a rotation and a translation, but centered in the E-frame's perspective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c5240-910c-4955-9a40-ec235b001102",
   "metadata": {},
   "source": [
    "## Taylor's theorem\n",
    "\n",
    "1. Taylor's theorem for single functions\n",
    "\n",
    "$f(x)=f(a)+f'(a)(x-a)+\\frac{1}{2}(x-a)^2f''(a) +\\frac{1}{3!}f'''(a)(x-a)^3+...=\\sum_{j=0} f^{(j)}(a)\\frac {(x-a)^j}{j!} \n",
    "\\nonumber$\n",
    "\n",
    "2. Taylor's theorem for multivariate functions\n",
    "\n",
    "\n",
    "$\\begin{align*}\n",
    "  f(\\textbf{x}) \\approx f(\\textbf{a}) + Df(\\textbf{a})_{1\\times n} (\\textbf{x}-\\textbf{a})_{n\\times1}+\n",
    "  \\frac{1}{2} (\\textbf{x}-\\textbf{a})_{1\\times n}^T Hf(\\textbf{a})_{n\\times n} (\\textbf{x}-\\textbf{a})_{n\\times1}.\n",
    "\\end{align*}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef2dc5-942a-46b4-b3b3-6f03a514bebe",
   "metadata": {},
   "source": [
    "##  Taylor series expansions for the sine and cosine\n",
    "The Taylor series expansions for $\\sin(x)$ and $\\cos(x)$ centered at $x = 0$.\n",
    "\n",
    "\n",
    "$sin(x)=sin(0)+sin'(0)(x)+\\frac{1}{2}(x)^2sin''(0) +\\frac{1}{3!}sin'''(0)(x)^3+...=\\sum_{j=0} sin^{(j)}(0)\\frac {(x-a)^j}{j!} \n",
    "\\nonumber$\n",
    "\n",
    "**For $\\sin(x)$**:\n",
    "\n",
    "- $sin'(0)=cos(0)=1$\n",
    "- $sin''(0)=-sin(0)=0$\n",
    "- $sin'''(0)=-cos(0)=-1$\n",
    "- $sin''''(0)=sin(0)=0$\n",
    "\n",
    "The derivatives at $x = 0$ cycle through  $1, 0, -1, 0$ and so on. Thus, the odd powers of $x$ appear in the series.\n",
    "\n",
    "$sin(x)=0+ x \\times 1 + \\frac{1}{2}x^2 \\times 0 +\\frac{1}{3!}\\times -1 \\times x^3+...=  x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots =\\sum_{n=0}^{\\infty} \\frac{(-1)^n}{(2n+1)!} x^{2n+1} $\n",
    "\n",
    "\n",
    "\n",
    "**For $\\cos(x)$**:\n",
    "\n",
    "\n",
    "\n",
    "The Taylor series expansion for $\\cos(x)$ around $x = 0$ is \n",
    "\n",
    "$ \\cos(x) = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\cdots = \\sum_{n=0}^{\\infty} \\frac{(-1)^n}{(2n)!} x^{2n} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89481582-6587-4cf4-a8d1-cb286042b328",
   "metadata": {},
   "source": [
    "##  Taylor series expansions for Exponential function\n",
    "\n",
    "\n",
    "\n",
    "$f(x)=f(a)+f'(a)(x-a)+\\frac{1}{2}(x-a)^2f''(a) +\\frac{1}{3!}f'''(a)(x-a)^3+...=\\sum_{j=0} f^{(j)}(a)\\frac {(x-a)^j}{j!} \n",
    "\\nonumber$\n",
    "\n",
    "\n",
    "$exp(0)=1$\n",
    "\n",
    "$exp(x)=exp(0)+exp(0)(x)+\\frac{1}{2}(x)^2exp(0) +\\frac{1}{3!}exp(0)(x)^3+...=1+ x+\\frac{1}{2}x^2 +\\frac{1}{3!}x^3+...$\n",
    "\n",
    "\n",
    "$exp(x)=e^x = \\sum_{k=0}^\\infty \\frac{1}{k!} x^k$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30496096-f735-478f-951d-564a5c294c93",
   "metadata": {},
   "source": [
    "## Matrix Exponential\n",
    "\n",
    "$e^\\mathbf{X} = \\sum_{k=0}^\\infty \\frac{1}{k!} \\mathbf{X}^k$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec44d22-a258-46be-9f50-fd54523b0566",
   "metadata": {},
   "source": [
    "## Euler's Formula\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20e%5E%7Bix%7D%3D%5Ccos%20x&plus;i%5Csin%20x%2C%7D\" alt=\"https://latex.codecogs.com/svg.latex?{\\displaystyle e^{ix}=\\cos x+i\\sin x,}\" />\n",
    "\n",
    "proof of Euler's formula using Taylor series:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20f%28a%29&plus;%7B%5Cfrac%20%7Bf%27%28a%29%7D%7B1%21%7D%7D%28x-a%29&plus;%7B%5Cfrac%20%7Bf%27%27%28a%29%7D%7B2%21%7D%7D%28x-a%29%5E%7B2%7D&plus;%7B%5Cfrac%20%7Bf%27%27%27%28a%29%7D%7B3%21%7D%7D%28x-a%29%5E%7B3%7D&plus;%5Ccdots%20%2C%7D\" alt=\"{\\displaystyle f(a)+{\\frac {f'(a)}{1!}}(x-a)+{\\frac {f''(a)}{2!}}(x-a)^{2}+{\\frac {f'''(a)}{3!}}(x-a)^{3}+\\cdots ,}\" />\n",
    "\n",
    "if we write it for around point zero (a=0):\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20%7B%5Cbegin%7Baligned%7De%5E%7Bix%7D%26%3D1&plus;ix&plus;%7B%5Cfrac%20%7B%28ix%29%5E%7B2%7D%7D%7B2%21%7D%7D&plus;%7B%5Cfrac%20%7B%28ix%29%5E%7B3%7D%7D%7B3%21%7D%7D&plus;%7B%5Cfrac%20%7B%28ix%29%5E%7B4%7D%7D%7B4%21%7D%7D&plus;%7B%5Cfrac%20%7B%28ix%29%5E%7B5%7D%7D%7B5%21%7D%7D&plus;%7B%5Cfrac%20%7B%28ix%29%5E%7B6%7D%7D%7B6%21%7D%7D&plus;%7B%5Cfrac%20%7B%28ix%29%5E%7B7%7D%7D%7B7%21%7D%7D&plus;%7B%5Cfrac%20%7B%28ix%29%5E%7B8%7D%7D%7B8%21%7D%7D&plus;%5Ccdots%20%5C%5C%5B8pt%5D%26%3D1&plus;ix-%7B%5Cfrac%20%7Bx%5E%7B2%7D%7D%7B2%21%7D%7D-%7B%5Cfrac%20%7Bix%5E%7B3%7D%7D%7B3%21%7D%7D&plus;%7B%5Cfrac%20%7Bx%5E%7B4%7D%7D%7B4%21%7D%7D&plus;%7B%5Cfrac%20%7Bix%5E%7B5%7D%7D%7B5%21%7D%7D-%7B%5Cfrac%20%7Bx%5E%7B6%7D%7D%7B6%21%7D%7D-%7B%5Cfrac%20%7Bix%5E%7B7%7D%7D%7B7%21%7D%7D&plus;%7B%5Cfrac%20%7Bx%5E%7B8%7D%7D%7B8%21%7D%7D&plus;%5Ccdots%20%5C%5C%5B8pt%5D%26%3D%5Cleft%281-%7B%5Cfrac%20%7Bx%5E%7B2%7D%7D%7B2%21%7D%7D&plus;%7B%5Cfrac%20%7Bx%5E%7B4%7D%7D%7B4%21%7D%7D-%7B%5Cfrac%20%7Bx%5E%7B6%7D%7D%7B6%21%7D%7D&plus;%7B%5Cfrac%20%7Bx%5E%7B8%7D%7D%7B8%21%7D%7D-%5Ccdots%20%5Cright%29&plus;i%5Cleft%28x-%7B%5Cfrac%20%7Bx%5E%7B3%7D%7D%7B3%21%7D%7D&plus;%7B%5Cfrac%20%7Bx%5E%7B5%7D%7D%7B5%21%7D%7D-%7B%5Cfrac%20%7Bx%5E%7B7%7D%7D%7B7%21%7D%7D&plus;%5Ccdots%20%5Cright%29%5C%5C%5B8pt%5D%26%3D%5Ccos%20x&plus;i%5Csin%20x%2C%5Cend%7Baligned%7D%7D%7D\" alt=\"https://latex.codecogs.com/svg.latex?{\\displaystyle {\\begin{aligned}e^{ix}&=1+ix+{\\frac {(ix)^{2}}{2!}}+{\\frac {(ix)^{3}}{3!}}+{\\frac {(ix)^{4}}{4!}}+{\\frac {(ix)^{5}}{5!}}+{\\frac {(ix)^{6}}{6!}}+{\\frac {(ix)^{7}}{7!}}+{\\frac {(ix)^{8}}{8!}}+\\cdots \\\\[8pt]&=1+ix-{\\frac {x^{2}}{2!}}-{\\frac {ix^{3}}{3!}}+{\\frac {x^{4}}{4!}}+{\\frac {ix^{5}}{5!}}-{\\frac {x^{6}}{6!}}-{\\frac {ix^{7}}{7!}}+{\\frac {x^{8}}{8!}}+\\cdots \\\\[8pt]&=\\left(1-{\\frac {x^{2}}{2!}}+{\\frac {x^{4}}{4!}}-{\\frac {x^{6}}{6!}}+{\\frac {x^{8}}{8!}}-\\cdots \\right)+i\\left(x-{\\frac {x^{3}}{3!}}+{\\frac {x^{5}}{5!}}-{\\frac {x^{7}}{7!}}+\\cdots \\right)\\\\[8pt]&=\\cos x+i\\sin x,\\end{aligned}}}\" />\n",
    "\n",
    "\n",
    "\n",
    "Letting <img src=\"https://latex.codecogs.com/svg.latex?%5Cmathbf%7Bv%7D%3D%5Cmathbf%7Bu%7D%5Ctheta\" alt=\"https://latex.codecogs.com/svg.latex?\\mathbf{v}=\\mathbf{u}\\theta\" />  be the rotation vector, representing a rotation of <img src=\"https://latex.codecogs.com/svg.latex?%5Ctheta\" alt=\"https://latex.codecogs.com/svg.latex?\\theta\" />\n",
    " radians around the unitary axis \n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cmathbf%7Bu%7D%3D%5Cbegin%7Bbmatrix%7Du_x%20%5C%5C%20u_y%20%5C%5C%20u_z%5Cend%7Bbmatrix%7D\" alt=\"https://latex.codecogs.com/svg.latex?\\mathbf{u}=\\begin{bmatrix}u_x \\\\ u_y \\\\ u_z\\end{bmatrix}\" />\n",
    " \n",
    "  \n",
    "we can get its exponential series as:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?e%5E%5Cmathbf%7Bv%7D%20%3D%20e%5E%7B%5Cmathbf%7Bu%7D%5Ctheta%7D%20%3D%20%5CBig%281%20-%20%5Cfrac%7B%5Ctheta%5E2%7D%7B2%21%7D%20&plus;%20%5Cfrac%7B%5Ctheta%5E4%7D%7B4%21%7D%20&plus;%20%5Ccdots%5CBig%29%20&plus;%20%5CBig%28%5Cmathbf%7Bu%7D%5Ctheta%20-%20%5Cfrac%7B%5Cmathbf%7Bu%7D%5Ctheta%5E3%7D%7B3%21%7D%20&plus;%20%5Cfrac%7B%5Cmathbf%7Bu%7D%5Ctheta%5E5%7D%7B5%21%7D%20&plus;%20%5Ccdots%5CBig%29\" alt=\"https://latex.codecogs.com/svg.latex?e^\\mathbf{v} = e^{\\mathbf{u}\\theta} = \\Big(1 - \\frac{\\theta^2}{2!} + \\frac{\\theta^4}{4!} + \\cdots\\Big) + \\Big(\\mathbf{u}\\theta - \\frac{\\mathbf{u}\\theta^3}{3!} + \\frac{\\mathbf{u}\\theta^5}{5!} + \\cdots\\Big)\" />\n",
    "\n",
    "\n",
    "This exponential map is formerly defined as:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cmathbf%7Bq%7D%20%3D%20e%5E%5Cmathbf%7Bv%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%5Ccos%5Cfrac%7B%5Ctheta%7D%7B2%7D%20%5C%5C%20%5Cmathbf%7Bu%7D%5Csin%5Cfrac%7B%5Ctheta%7D%7B2%7D%5Cend%7Bbmatrix%7D\" alt=\"https://latex.codecogs.com/svg.latex?\\mathbf{q} = e^\\mathbf{v} = \\begin{bmatrix}\\cos\\frac{\\theta}{2} \\\\ \\mathbf{u}\\sin\\frac{\\theta}{2}\\end{bmatrix}\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a4efe-387e-43b3-a02d-8f186dee63e0",
   "metadata": {},
   "source": [
    "$z.z^*=1$\n",
    "\n",
    "\n",
    "To take the derivative with respect to time of the expression $ z \\cdot z^* = 1 $, where $z$ is a complex-valued function of time $t$, we will use the product rule and the chain rule.\n",
    "\n",
    "Given:\n",
    "$ z(t) \\cdot z^*(t) = 1 $\n",
    "\n",
    "Differentiate both sides with respect to time $t$:\n",
    "$ \\frac{d}{dt} \\left( z(t) \\cdot z^*(t) \\right) = \\frac{d}{dt}(1) $\n",
    "\n",
    "Since the right-hand side is a constant:\n",
    "$ \\frac{d}{dt}(1) = 0 $\n",
    "\n",
    "Now apply the product rule to the left-hand side:\n",
    "$ \\frac{d}{dt} \\left( z(t) \\cdot z^*(t) \\right) = \\frac{dz(t)}{dt} \\cdot z^*(t) + z(t) \\cdot \\frac{dz^*(t)}{dt} $\n",
    "\n",
    "Recall that $z^*$ is the complex conjugate of $z$. When differentiating $z^*$ with respect to $t$, we use the fact that:\n",
    "$ \\frac{dz^*}{dt} = \\left( \\frac{dz}{dt} \\right)^* $\n",
    "\n",
    "Thus, we get:\n",
    "$ \\frac{dz(t)}{dt} \\cdot z^*(t) + z(t) \\cdot \\left( \\frac{dz(t)}{dt} \\right)^* = 0 $\n",
    "\n",
    "Let's denote $\\dot{z} = \\frac{dz}{dt}$. Then the equation becomes:\n",
    "$ \\dot{z} \\cdot z^* + z \\cdot \\dot{z}^* = 0 $\n",
    "\n",
    "This is the derivative of the given equation $ z \\cdot z^* = 1 $ with respect to time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99788c7-fc1b-4796-9bf2-e5c7ba121753",
   "metadata": {},
   "source": [
    "$ \\dot{z} \\cdot z^* =- z \\cdot \\dot{z}^*  $\n",
    "\n",
    "$ \\dot{z} \\cdot z^* =- (\\dot{z} \\cdot z ^*  ) ^*$\n",
    "\n",
    "\n",
    "$ a =- (a ) ^*$\n",
    "\n",
    "Only imaginary number are equal to the minus of their conjugate, so $ \\dot{z} \\cdot z^*$ is pure maginary,\n",
    "\n",
    "$ \\dot{z} \\cdot z^*=i \\omega$\n",
    "\n",
    "\n",
    "- Hat: $ \\hat{\\omega}$\n",
    "\n",
    "- Vee: $ \\wedge{\\omega}$\n",
    "\n",
    "\n",
    "$ \\vee{\\omega}$\n",
    "\n",
    "<img src=\"images/exp_log_s1.png\" />\n",
    "\n",
    "\n",
    "<img src=\"images/exp_log.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfdeded-73ec-45f6-8129-22c6290b3413",
   "metadata": {},
   "source": [
    "- $R=exp(\\theta_\\times)$\n",
    "\n",
    "- $R=Exp(\\theta)$\n",
    "\n",
    "\n",
    "<img src=\"images/exp_Exp.png\" height=\"50%\" width =\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c16bd1-b29b-438c-8f99-6d3f10bac007",
   "metadata": {},
   "source": [
    "## Plus and Minus Operator\n",
    "In $S^1$ if we multiply $x_2$ by $x_1$, $x_1.x_2$ we rotate $x_2$ by angle of $x_1$\n",
    "\n",
    "Any element of the group can be expressed as exponential of some vector in tangent space \n",
    "\n",
    "$ (\\oplus and \\ominus )$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$ X \\oplus \\omega $ is a proper rotation matrix.\n",
    "\n",
    "\n",
    "$x\\oplus \\omega \\triangleq x. exp(\\omega_\\times) \\triangleq  x.Exp(\\omega)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c75a99-b79e-424e-85ec-46d819fd18e1",
   "metadata": {},
   "source": [
    "\n",
    "Here you have two group elements (two matrices) and you want to find the difference between them in vector form.\n",
    "\n",
    "<img src=\"images/minus_op.png\" height=\"25%\" width=\"25%\" />\n",
    "\n",
    "Both $x,y$ are rotation matrices (two group elements) and you want to know what is the diference between them \n",
    "\n",
    "$y \\ominus x \\triangleq Log(x^{-1}.y) \\triangleq  $\n",
    "\n",
    "\n",
    "<img src=\"images/plus_and_minus_operator.png\" height=\"50%\" width=\"50%\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49abf3d8-2611-4495-8689-d5829b74b4c4",
   "metadata": {},
   "source": [
    "## Jacobians on Lie groups\n",
    "\n",
    "\n",
    "$\\mathbf{J}=\\frac{Df(x)}{D(x)}= \\lim\\limits_{\\tau\\to 0} \\frac{f(x\\oplus \\tau) \\ominus f(x)}{\\tau} \\in \\mathbb{R} ^{n\\times m}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b13099-8070-4307-a4ed-748a0a0ecc6d",
   "metadata": {},
   "source": [
    "$ f: SO(3)\\times\\mathbb{R}^3 \\rightarrow  \\mathbb{R}^3 ; \\rightarrow f(R,P)=R.P $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928f35e3-79d3-4704-b4cb-69f6b8c9f698",
   "metadata": {},
   "source": [
    "$\\lim\\limits_{\\tau\\to 0} \\frac{f(x\\oplus \\tau) \\ominus f(x)}{\\tau} \\in \\mathbb{R} ^{n\\times m}=\n",
    "\\lim\\limits_{\\tau\\to 0} \\frac{Log[f(x)^{-1} ]f(xExp(\\tau)) }{\\tau} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc70796-9f00-4315-991f-01f3a1bf8841",
   "metadata": {},
   "source": [
    "[Fonts for Lie Algebra](https://tex.stackexchange.com/questions/581447/curly-letters-used-by-john-lee-in-introduction-to-smooth-manifolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bff25c-baa9-47dc-a74a-9814860d90f6",
   "metadata": {},
   "source": [
    "$\\lim\\limits_{\\tau\\to 0} \\frac{\\mathbf{J\\tau}}{\\tau}  \\triangleq \\frac{\\mathbf{J\\tau}}{\\partial \\tau} =\\mathbf{J}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404e568-c39c-4d91-8dae-4f03935ed5e2",
   "metadata": {},
   "source": [
    "<img src=\"images/adjoint_matrix.png\" height=\"25%\" width=\"25%\" />\n",
    "\n",
    "$y=\\sigma \\oplus x=x\\oplus \\tau$\n",
    "\n",
    "$\\sigma^\\vee =x.\\tau ^\\vee .x^{-1}$\n",
    "\n",
    "$\\sigma=\\mathbf{ Ad_{x}}.\\tau$\n",
    "\n",
    "\n",
    "The $\\mathbf{ Ad_{x}}$ operator is linear and maps from $T_xM$ to $T_{\\epsilon}M$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5096bf7f-86a1-4193-8630-2743656c2231",
   "metadata": {},
   "source": [
    "## The unit complex numbers\n",
    "\n",
    "<img src=\"images/unit_complex_s1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a3517-33b3-4d37-bf84-88c46bb1d078",
   "metadata": {},
   "source": [
    "## SO(2) Rotation Matrices\n",
    "\n",
    "\n",
    "<img src=\"images/so(2)_rotation_matrices.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b998da-da26-4d15-9206-b82dfbc33fbd",
   "metadata": {},
   "source": [
    "Act on other\n",
    "Invert\n",
    "Compose\n",
    "Interpolate \n",
    "Integrate\n",
    "Differentiate\n",
    "Uncertainty\n",
    "\n",
    "\n",
    "- Examples\n",
    "- Lie group definition\n",
    "   - Group, Manifold, action\n",
    "- The tangent space\n",
    "    - Lie algebra\n",
    "- The exponential map\n",
    "- Plus Minus Operator\n",
    "- The adjoint matrix\n",
    "- Derivatives: Jacobins\n",
    "- Uncertainty: covariances\n",
    "- Integration: motion\n",
    "  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187df30b-050d-44b8-ab66-093cafb7c8ac",
   "metadata": {},
   "source": [
    "<img src=\"images/TYPICAL_LIE_GROUPS_USED_IN_2D_AND_3D_MOTION.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e467db42-e48f-44bc-9482-e5fd938e2998",
   "metadata": {},
   "source": [
    "Jacobian of  $ f:SO(3)\\times \\mathbb{R}^3 \\to \\mathbb{R}^3   $ with respect to R\n",
    "\n",
    "\n",
    "$\\mathfrak{s}$\n",
    "\n",
    "\n",
    "\n",
    "$ \\oplus$\n",
    "\n",
    "$\\ominus$\n",
    "\n",
    "\n",
    "$\\textbf{J}=\\lim_{\\tau \\to 0} \\frac{f (X\\oplus \\tau)  \\ominus f(X) }{\\tau} \\in \\mathbb{R}^{n \\times m}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65558671-f922-46ee-8020-faf1301159a8",
   "metadata": {},
   "source": [
    "$\\lim_{\\tau \\to 0} \\frac{f (X\\oplus \\tau)  \\ominus f(X) }{\\tau} = \\lim_{\\tau \\to 0} \\frac{\\textbf{J}\\tau }{\\tau}   $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2f737-6f96-4f4a-a0bc-600a8b43ff73",
   "metadata": {},
   "source": [
    "$\\lim_{\\tau \\to 0} \\frac{f (X\\oplus \\tau)  \\ominus f(X) }{\\tau} = \\lim_{\\tau \\to 0} \\frac{Log[f(X)^{-1}f(XExp(\\tau)   ] }{\\tau}   $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df1e9a4-34c6-4ee2-94dd-781d92216d1f",
   "metadata": {},
   "source": [
    "Consider an arbitrary rotation matrix $\\mathbf{R}$, we know that it satisfies:\n",
    "\\begin{equation}\n",
    "\\mathbf{R} \\mathbf{R}^T=\\mathbf{I}.\n",
    "\\end{equation}\n",
    "Now, we say that $\\mathbf{R}$ is the rotation of a camera that changes continuously over time, which is a function of time: $\\mathbf{R}(t)$. Since it is still a rotation matrix, we have\n",
    "\n",
    "$\\mathbf{R}(t) \\mathbf{R}(t) ^T = \\mathbf{I}.$\n",
    "\n",
    "\n",
    "Deriving time on both sides of the equation yields (we use $\\dot{\\mathbf{R}}$ to represent the derivative of $\\mathbf{R}$ on time $t$, ):\n",
    "$ \\dot{\\mathbf{R}} (t) \\mathbf{R} {(t)^T} + \\mathbf{R} (t) \\dot{\\mathbf{R}} {(t) ^T} = 0. $\n",
    "\n",
    "Move the second term to right and commute the matrices by using the transposed relation:\n",
    "\\begin{equation}\n",
    "\\dot{\\mathbf{R}} (t) \\mathbf{R} {(t)^T} = - \\left( \\dot{\\mathbf{R}} (t) \\mathbf{R} {(t)^T} \\right)^T .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f4f1b-306a-45ad-8e73-d5957cb28728",
   "metadata": {},
   "source": [
    "It can be seen that $\\dot{\\mathbf{R}} (t) \\mathbf{R} {(t)^T}$ is a $\\textit{skew-symmetric}$ matrix. Recall that we introduced the $^\\wedge$ symbol in the cross product formula, which turns a vector into a skew-symmetric matrix. Similarly, for any skew-symmetric matrix, we can also find a unique vector corresponding to it. Let this operation be represented by the symbol $^{\\vee}$:\n",
    "\\begin{equation}\n",
    "{\\mathbf{a}^ \\wedge } = \\mathbf{A} = \\left[ {\\begin{array}{*{20}{c}}\n",
    "    0&{ - {a_3}}&{{a_2}}\\\\\n",
    "    {{a_3}}&0&{ - {a_1}}\\\\\n",
    "    { - {a_2}}&{{a_1}}&0\n",
    "    \\end{array}} \\right], \\quad\n",
    "{ \\mathbf{A}^ \\vee } = \\mathbf{a}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40520063-8866-44f7-abd6-9f058dc66d0e",
   "metadata": {},
   "source": [
    "So, since $\\dot{\\mathbf{R}} (t) \\mathbf{R} {(t)^T}$ is a skew-symmetric matrix, we can find a three-dimensional vector $\\boldsymbol{\\phi} (t) \\in \\mathbb{R}^3$ corresponds to it:\n",
    "$ \\dot{\\mathbf{R}} (t) \\mathbf{R}(t)^T = \\boldsymbol{\\phi} (t) ^ {\\wedge}. $\n",
    "\n",
    "Right multiply with $\\mathbf{R}(t)$ on both sides. Since $\\mathbf{R}$ is an orthogonal matrix, we have:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f104e5fb-08fb-4c50-b92e-43d16063da55",
   "metadata": {},
   "source": [
    "$\\dot{\\mathbf{R}} (t) = \\boldsymbol{\\phi} (t)^{\\wedge} \\mathbf{R}(t) =\n",
    "\\left[ {\\begin{array}{*{20}{c}}\n",
    "    0&{ - {\\phi _3}}&{{\\phi _2}}\\\\\n",
    "    {{\\phi _3}}&0&{ - {\\phi _1}}\\\\\n",
    "    { - {\\phi _2}}&{{\\phi _1}}&0\n",
    "    \\end{array}} \\right] \\mathbf{R} (t).$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbe5f48-c7cc-405c-a059-2e40e520d275",
   "metadata": {},
   "source": [
    "## The Definition of Lie Algebra\n",
    "Now let's give the strict definition of Lie Algebra. Each Lie group has a Lie algebra corresponding to it. Lie algebra describes the local structure of the Lie group around its origin point, or in other words, is the tangent space. The general definition of Lie algebra is listed as follows:\n",
    "\n",
    "A Lie algebra consists of a set $\\mathbb{V}$, a scalar field $\\mathbb{F}$, and a binary operation $[,]$. If they satisfy the following properties, then $(\\mathbb{V}, \\mathbb{F}, [,])$ is a Lie algebra, denoted as $\\mathfrak{g}$.\n",
    "\n",
    "\n",
    "1. **Closure**: $\\forall \\mathbf{X}, \\mathbf{Y} \\in \\mathbb{V}; [\\mathbf{X}, \\mathbf{Y}] \\in \\mathbb{V}$.\n",
    "\n",
    "2. **Bilinear composition**: $\\forall \\mathbf{X},\\mathbf{Y},\\mathbf{Z} \\in \\mathbb{V}; a,b \\in \\mathbb{F }$, we have:\n",
    "   $$\n",
    "   [a\\mathbf{X}+b\\mathbf{Y}, \\mathbf{Z}] = a[\\mathbf{X}, \\mathbf{Z}] + b [ \\mathbf{Y}, \\mathbf{Z} ], \\quad [\\mathbf{Z}, a \\mathbf{X}+b\\mathbf{Y}] = a [\\mathbf{Z}, \\mathbf{X} ]+ b [\\mathbf{Z},\\mathbf{Y}].\n",
    "   $$\n",
    "\n",
    "3. **Reflexive**: $\\forall \\mathbf{X} \\in \\mathbb{V}; [\\mathbf{X},\\mathbf{X}] = \\mathbf{0}$.\n",
    "\n",
    "4. **Jacobi identity**: $\\forall \\mathbf{X},\\mathbf{Y},\\mathbf{Z} \\in \\mathbb{V}; [\\mathbf{X}, [ \\mathbf{Y},\\mathbf{Z}] ] + [\\mathbf{Z}, [\\mathbf{X},\\mathbf{Y}] ] + [\\mathbf{Y}, [\\mathbf{Z}, \\mathbf{X}]] =\\mathbf{0}$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The binary operations $[,]$ are called $\\textit{Lie brackets}$. At first glance, we require a lot of properties about the Lie bracket.  Compared to the simpler binary operations in the group, the Lie bracket expresses the difference between the two elements. It does not require a combination law but requires the element and itself to be zero after the brackets. For example, the cross product $\\times$ defined on the 3D vector $\\mathbb{R}^3$ is a kind of Lie bracket, so $\\mathfrak{g} = (\\mathbb{R}^3, \\mathbb{R}, \\times)$ constitutes a Lie algebra. Readers can try to substitute the cross product into the four properties to verify the above conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f786608e-030b-423c-825f-aedeec3e68f9",
   "metadata": {},
   "source": [
    "## Lie Algebra $\\mathfrak{so}(3)$\n",
    "The previously mentioned $\\boldsymbol{\\phi}$ is actually a kind of Lie algebra. The Lie algebra corresponding to $\\mathrm{SO}(3)$ is a vector defined on $\\mathbb{R}^3$, which we will denote as $\\boldsymbol{\\phi}$. According to the previous derivation, each $\\boldsymbol{\\phi}$ can generate a skew-symmetric matrix:\n",
    "\n",
    "\n",
    "$\\boldsymbol{\\varPhi} = \\boldsymbol{\\phi}^{\\wedge} = \\left[ {\\begin{array}{*{20}{c}}\n",
    "    0&{ - {\\phi _3}}&{{\\phi _2}}\\\\\n",
    "    {{\\phi _3}}&0&{ - {\\phi _1}}\\\\\n",
    "    { - {\\phi _2}}&{{\\phi _1}}&0\n",
    "    \\end{array}} \\right] \\in \\mathbb{R}^{3 \\times 3}.$\n",
    "\n",
    "Under this definition, the two vectors $\\boldsymbol{\\phi}_1, \\boldsymbol{\\phi}_2$'s Lie bracket is:\n",
    "\\begin{equation}\n",
    "[\\boldsymbol{\\phi}_1, \\boldsymbol{\\phi}_2] = \\left( \\mathbf{ \\varPhi }_1 \\mathbf{ \\varPhi }_2 - \\mathbf{ \\varPhi }_2 \\mathbf{ \\varPhi }_1 \\right)^\\vee.\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298b738-422e-443d-accc-70a32b3a2185",
   "metadata": {},
   "source": [
    "Some books also use the symbol $\\widehat{\\boldsymbol{\\phi}}$ to represent $\\boldsymbol{\\phi}^\\wedge$, but the meaning is the same.\n",
    "\n",
    "Contents of $\\mathfrak{so}(3)$: they are just a set of 3D vectors that can express the derivative of the rotation matrix. Its relationship to $\\mathrm{SO}(3)$ is given by the exponential map:\n",
    "\\begin{equation}\n",
    "\\mathbf{R} = \\exp ( \\boldsymbol{\\phi}^\\wedge ).\n",
    "\\end{equation}\n",
    "The exponential map will be introduced later. Since we have introduced $\\mathfrak{so}(3)$, we will first look at the corresponding Lie algebra on $\\mathrm{SE}(3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc59ae-fb60-464c-b255-f17887bb46d9",
   "metadata": {},
   "source": [
    "\n",
    "## Lie Algebra $\\mathfrak{se}(3)$\n",
    "For $\\mathrm{SE}(3)$, it also has a corresponding Lie algebra $\\mathfrak{se}(3)$. To save space, we won't start by taking time derivatives. Similar to $\\mathfrak{so}(3)$, $\\mathfrak{se}(3)$ is located in the $\\mathbb{R}^6$ space:\n",
    "\\begin{equation}\n",
    "\\mathfrak{se}(3) = \\left\\{ { \\boldsymbol{\\xi} = \\left[ \\begin{array}{l}\n",
    "    \\boldsymbol{\\rho} \\\\\n",
    "    \\boldsymbol{\\phi}\n",
    "    \\end{array} \\right]\n",
    "    \\in { \\mathbb{R}^6} ,\n",
    "    \\boldsymbol{\\rho} \\in { \\mathbb{R}^3}, \\boldsymbol{\\phi} \\in \\mathfrak{so} \\left( 3 \\right),{ \\boldsymbol{\\xi} ^ \\wedge } = \\left[ {\\begin{array}{*{20}{c}}\n",
    "        {{ \\boldsymbol{\\phi} ^ \\wedge }}& \\boldsymbol{\\rho} \\\\\n",
    "        {{\\mathbf{0}^T}}&0\n",
    "        \\end{array}} \\right] \\in { \\mathbb{R}^{4 \\times 4}}} \\right\\}.\n",
    "\\end{equation}\n",
    "We write each $\\mathfrak{se}(3)$ element as $\\boldsymbol{\\xi}$, which is a six-dimensional vector. The first three dimensions are \"translation part\" (but keep in mind that the meaning i\n",
    "s $\\textit{different}$ from the translation in the matrix), which is denoted as $\\boldsymbol{\\rho}$; the second part is a rotation part $\\boldsymbol{\\phi}$, which is essentially a $\\mathfrak{so}(3)$ element. At the same time, we extended the meaning of the $^\\wedge$ symbol. In $\\mathfrak{se}(3)$, a six-dimensional vector is converted to a four-dimensional matrix also using the $^\\wedge$ symbol, but no longer a skew-symmetric one:\n",
    "\\begin{equation}\n",
    "{ \\boldsymbol{\\xi} ^ \\wedge } = \\left[ {\\begin{array}{*{20}{c}}\n",
    "    {{ \\boldsymbol{\\phi} ^ \\wedge }}& \\boldsymbol{\\rho} \\\\\n",
    "    {{\\mathbf{0}^T}}&0\n",
    "    \\end{array}} \\right] \\in { \\mathbb{R}^{4 \\times 4}}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The Lie algebra $\\mathfrak{se}(3)$ also has a Lie bracket similar to $\\mathfrak{so}(3)$:\n",
    "\\begin{equation}\n",
    "[ \\boldsymbol{\\xi}_1, \\boldsymbol{\\xi}_2 ] = \\left( \\boldsymbol{\\xi}_1^\\wedge \\boldsymbol{\\xi}_2^\\wedge -\\boldsymbol{\\xi}_2^ \\wedge \\boldsymbol{\\xi}_1^\\wedge \\right) ^\\vee.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4f368-dcdd-47c2-b8b0-f0531b205398",
   "metadata": {},
   "source": [
    "## Exponential Map of $\\mathrm{SO}(3)$\n",
    "\n",
    "Now consider the second question: How to calculate $\\exp ( \\boldsymbol{\\phi}^{\\wedge} )$? In other words, it is an exponential map of a matrix. Again, we will first discuss the exponential mapping of $\\mathfrak{so}(3)$ and then the case of $\\mathfrak{se}(3)$.\n",
    "\n",
    "The exponential of an arbitrary matrix can be written as a Taylor expansion if it has converged, whose result is still a matrix:\n",
    "\\begin{equation}\n",
    "\\exp(\\mathbf{A}) = \\sum\\limits_{n = 0}^\\infty {\\frac{1}{{n!}}{ \\mathbf{A}^n}}.\n",
    "\\end{equation}\n",
    "\n",
    "Similarly, for any element in $\\boldsymbol{\\phi} \\in \\mathfrak{so}(3)$, we can also define its exponential map in this way:\n",
    "\\begin{equation}\n",
    "\\exp(\\boldsymbol{\\phi}^\\wedge) = \\sum\\limits_{n = 0}^\\infty {\\frac{1}{{n!}}{ (\\boldsymbol{\\phi}^{\\wedge })^n}}.\n",
    "\\end{equation}\n",
    "But this definition cannot be calculated directly because we don't want to calculate the infinite power of a matrix. Below we derive a convenient way to calculate the exponential mapping. Since $\\boldsymbol{\\phi}$ is a three-dimensional vector, we can define its length and direction,  denoted as $\\theta$ and $\\mathbf{n}$, respectively. So we have $\\boldsymbol{\\phi} = \\theta \\mathbf{n}$, where $\\mathbf{n}$ is a unit-length direction vector, i.e., $\\| \\mathbf{n} \\| =1$. First, for such a unit-length vector $\\mathbf{n}$, there are two properties:\n",
    "\\begin{equation}\n",
    " \\mathbf{n}^{\\wedge} \\mathbf{n}^{\\wedge} = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{ - n_2^2 - n_3^2}&{{n_1}{n_2}}&{{n_1}{n_3}}\\\\\n",
    "{{n_1}{n_2}}&{ - n_1^2 - n_3^2}&{{n_2}{n_3}}\\\\\n",
    "{{n_1}{n_3}}&{{n_2}{n_3}}&{ - n_1^2 - n_2^2}\n",
    "\\end{array}} \\right] = \\mathbf{n} \\mathbf{n}^T - \\mathbf{I},\n",
    "\\end{equation}\n",
    "as well as\n",
    "\\begin{equation}\n",
    "\\mathbf{n}^{\\wedge} \\mathbf{n}^{\\wedge} \\mathbf{n}^{\\wedge} = \\mathbf{n}^\\wedge (\\mathbf{n}\\mathbf{n} ^T-\\mathbf{I}) = \\underbrace{\\mathbf{n}^\\wedge \\mathbf{n}}_{\\text{zero}} \\mathbf{n}^T - \\mathbf{n}^{\\wedge} = - \\mathbf{n}^{\\wedge}.\n",
    "\\end{equation}\n",
    "These two formulas provide a way to handle the high-order $\\mathbf{n}^\\wedge$ items. Now we can write the exponential map as:\n",
    "\\begin{align*}\n",
    "\\exp \\left( {{\\boldsymbol{\\phi} ^ \\wedge }} \\right) &= \\exp \\left( {\\theta {\\mathbf{n}^ \\wedge }} \\right) = \\sum\\limits_ {n = 0}^\\infty {\\frac{1}{{n!}}{{\\left( {\\theta {\\mathbf{n}^ \\wedge }} \\right)}^n}} \\\\\n",
    "&= \\mathbf{I} + \\theta {\\mathbf{n}^ \\wedge } + \\frac{1}{{2!}}{\\theta ^2}{\\mathbf{n}^ \\wedge }{\\mathbf{n}^ \\wedge } + \\frac{1}{{3!}}{\\theta ^3}{\\mathbf{n}^ \\wedge }{\\mathbf{n}^ \\wedge }{\\mathbf{n}^ \\wedge } + \\frac{1}{{4!}}{\\theta ^4}{\\left( {{\\mathbf{n}^ \\wedge }} \\right)^4} + ... \\\\\n",
    "&= \\mathbf{n} {\\mathbf{n}^T} - {\\mathbf{n}^ \\wedge }{\\mathbf{n}^ \\wedge } + \\theta {\\mathbf{n} ^ \\wedge } + \\frac{1}{{2!}}\\theta^2 {\\mathbf{n}^ \\wedge }{\\mathbf{n}^ \\wedge } - \\frac{1}{{3! }}{\\theta ^3}{\\mathbf{n}^ \\wedge } - \\frac{1}{{4!}}{\\theta ^4}{\\left( {{\\mathbf{n}^ \\wedge }} \\right)^2} + ...\\\\\n",
    "&= \\mathbf{n}{\\mathbf{n}^T} + \\underbrace{\\left( {\\theta - \\frac{1}{{3!}}{\\theta ^3} + \\frac{1}{{5!}}{\\theta ^5} - ...} \\right)}_{\\sin \\theta} {\\mathbf{n}^ \\wedge } - \\underbrace{\\left( { 1 - \\frac{1}{{2!}}{\\theta ^2} + \\frac{1}{{4!}}{\\theta ^4} - ...} \\right)}_{\\cos \\theta}{\\mathbf{n}^ \\wedge }{\\mathbf{n}^ \\wedge }\\\\\n",
    "&= {\\mathbf{n}^ \\wedge }{\\mathbf{n}^ \\wedge } + \\mathbf{I} + \\sin \\theta {\\mathbf{n}^ \\wedge } - \\cos \\theta {\\mathbf{n}^ \\wedge }{\\mathbf{n}^ \\wedge }\\\\\n",
    "&= (1 - \\cos \\theta ){\\mathbf{n}^ \\wedge }{\\mathbf{n}^ \\wedge } + \\mathbf{I} + \\sin \\theta {\\mathbf{n}^ \\wedge }\\\\\n",
    "&= \\cos \\theta \\mathbf{I} + (1 - \\cos \\theta )\\mathbf{n}{\\mathbf{n}^T} + \\sin \\theta {\\mathbf{n}^ \\wedge }.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2067d5-bf9e-44ac-9e8e-3e624cd5094f",
   "metadata": {},
   "source": [
    "To show that\n",
    "\n",
    "$\\mathbf{n}^{\\wedge} \\mathbf{n}^{\\wedge} = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{ - n_2^2 - n_3^2}&{{n_1}{n_2}}&{{n_1}{n_3}}\\\\\n",
    "{{n_1}{n_2}}&{ - n_1^2 - n_3^2}&{{n_2}{n_3}}\\\\\n",
    "{{n_1}{n_3}}&{{n_2}{n_3}}&{ - n_1^2 - n_2^2}\n",
    "\\end{array}} \\right] = \\mathbf{n} \\mathbf{n}^T - \\mathbf{I},\n",
    "$\n",
    "\n",
    "where $\\mathbf{n} = \\begin{bmatrix} n_1 \\\\ n_2 \\\\ n_3 \\end{bmatrix}$ is a unit-length direction vector and $\\mathbf{n}^{\\wedge}$ is the skew-symmetric matrix representation of $\\mathbf{n}$.\n",
    "\n",
    "### Step 1: Skew-symmetric Matrix $\\mathbf{n}^{\\wedge}$\n",
    "\n",
    "The skew-symmetric matrix $\\mathbf{n}^{\\wedge}$ for a vector $\\mathbf{n}$ is defined as:\n",
    "$\n",
    "\\mathbf{n}^{\\wedge} = \\begin{bmatrix}\n",
    "0 & -n_3 & n_2 \\\\\n",
    "n_3 & 0 & -n_1 \\\\\n",
    "-n_2 & n_1 & 0\n",
    "\\end{bmatrix}.\n",
    "$\n",
    "\n",
    "### Step 2: Compute $\\mathbf{n}^{\\wedge} \\mathbf{n}^{\\wedge}$\n",
    "\n",
    "Now, we need to compute $\\mathbf{n}^{\\wedge} \\mathbf{n}^{\\wedge}$:\n",
    "\n",
    "\n",
    "$\n",
    "\\mathbf{n}^{\\wedge} \\mathbf{n}^{\\wedge} = \\begin{bmatrix}\n",
    "0 & -n_3 & n_2 \\\\\n",
    "n_3 & 0 & -n_1 \\\\\n",
    "-n_2 & n_1 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & -n_3 & n_2 \\\\\n",
    "n_3 & 0 & -n_1 \\\\\n",
    "-n_2 & n_1 & 0\n",
    "\\end{bmatrix}.\n",
    "$\n",
    "\n",
    "Expanding this product gives:\n",
    "\n",
    "$\\mathbf{n}^{\\wedge} \\mathbf{n}^{\\wedge} = \\begin{bmatrix}\n",
    "(-n_3^2 - n_2^2) & n_1 n_2 & n_1 n_3 \\\\\n",
    "n_1 n_2 & (-n_1^2 - n_3^2) & n_2 n_3 \\\\\n",
    "n_1 n_3 & n_2 n_3 & (-n_1^2 - n_2^2)\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "### Step 3: Express $\\mathbf{n} \\mathbf{n}^T - \\mathbf{I}$\n",
    "\n",
    "The outer product $\\mathbf{n} \\mathbf{n}^T$ is:\n",
    "$ \\mathbf{n} \\mathbf{n}^T = \\begin{bmatrix}\n",
    "n_1 \\\\\n",
    "n_2 \\\\\n",
    "n_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "n_1 & n_2 & n_3\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "n_1^2 & n_1 n_2 & n_1 n_3 \\\\\n",
    "n_1 n_2 & n_2^2 & n_2 n_3 \\\\\n",
    "n_1 n_3 & n_2 n_3 & n_3^2\n",
    "\\end{bmatrix}.$\n",
    "\n",
    "Subtract the identity matrix $\\mathbf{I}$ from $\\mathbf{n} \\mathbf{n}^T$:\n",
    "$ \\mathbf{n} \\mathbf{n}^T - \\mathbf{I} = \\begin{bmatrix}\n",
    "n_1^2 & n_1 n_2 & n_1 n_3 \\\\\n",
    "n_1 n_2 & n_2^2 & n_2 n_3 \\\\\n",
    "n_1 n_3 & n_2 n_3 & n_3^2\n",
    "\\end{bmatrix} - \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "n_1^2 - 1 & n_1 n_2 & n_1 n_3 \\\\\n",
    "n_1 n_2 & n_2^2 - 1 & n_2 n_3 \\\\\n",
    "n_1 n_3 & n_2 n_3 & n_3^2 - 1\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "### Step 4: Compare Both Results\n",
    "\n",
    "Notice that for a unit vector $\\mathbf{n}$, $n_1^2 + n_2^2 + n_3^2 = 1$. This makes:\n",
    "$ -n_2^2 - n_3^2 = n_1^2 - 1, \\quad -n_1^2 - n_3^2 = n_2^2 - 1, \\quad -n_1^2 - n_2^2 = n_3^2 - 1.$\n",
    "\n",
    "Thus:\n",
    "$ \\mathbf{n}^{\\wedge} \\mathbf{n}^{\\wedge} = \\mathbf{n} \\mathbf{n}^T - \\mathbf{I}.$\n",
    "\n",
    "This completes the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580116a-78a6-4b7d-80ac-9a22e85f1b3f",
   "metadata": {},
   "source": [
    "Finally, we get a very familiar equation:\n",
    "\\begin{equation}\n",
    "\\exp( \\theta \\mathbf{n}^\\wedge ) = \\cos \\theta \\mathbf{I} + (1 - \\cos \\theta )\\mathbf{n}{\\mathbf{n}^T } + \\sin \\theta {\\mathbf{n}^ \\wedge }.\n",
    "\\end{equation}\n",
    "\n",
    "This equation is exactly the same as Rodrigues' formula. This shows that $\\mathfrak{so}(3)$ is actually the \\textit{rotation vector}, and the exponential map is just Rodrigues' formula. Through them, we map any vector in $\\mathfrak{so}(3)$ to a rotation matrix in $\\mathrm{SO}(3)$. Conversely, if we define a logarithmic map, we can also map the elements in $\\mathrm{SO}(3)$ to $\\mathfrak{so}(3)$:\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\phi} = \\ln {\\left( \\mathbf{R} \\right)^ \\vee } = {\\left( {\\sum\\limits_{n = 0}^\\infty {\\frac{{{{ \\left( { - 1} \\right)}^n}}}{{n + 1}}{{\\left( { \\mathbf{R} - \\mathbf{I}} \\right)}^{n + 1 }}} } \\right)^ \\vee }.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeffc49-099f-4e89-867d-beb5c801dc6a",
   "metadata": {},
   "source": [
    "###  Rodrigues' formula\n",
    "a rotation can be described by a rotation axis and a rotation angle. Thus, we can use a vector whose direction is parallel with the axis of rotation, and the length is equal to the angle of rotation, which is called the $\\textit{rotation vector}$ (or angle-axis/axis-angle). Only a three-dimensional vector is needed here to describe the rotation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4736f2-471f-4374-a18d-7bbeed33a2c7",
   "metadata": {},
   "source": [
    "Consider a rotation represented by $ \\mathbf{R} $. If described by a rotation vector, assuming that the rotation axis is a unit-length vector $ \\mathbf{n} $ and the angle is $ \\theta $, then the vector $ \\theta \\mathbf{n} $ can also describe this rotation. So, we have to ask, what is the connection between the two expressions? In fact, it is not difficult to derive their conversion relationship. The conversion from the rotation vector to the rotation matrix is shown by the $\\textit{Rodrigues' formula}$.  result of the conversion is given:\n",
    "$ \\mathbf{R} = \\cos \\theta \\mathbf{I} + \\left({ 1 - \\cos \\theta } \\right) \\mathbf{n} { \\mathbf {n} ^T } + \\sin \\theta { \\mathbf{n}^ \\wedge }.$\n",
    "\n",
    "Conversely, we can also calculate the conversion from a rotation matrix to a rotation vector. For the corner $ \\theta $, taking the $\\textit{trace}$ of both sides ($\\textit{trace}$ on both sides to find the sum of the diagonal elements of the matrix.), we have:\n",
    "\n",
    "$\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\mathrm{tr} \\left( \\mathbf{R} \\right) &= \\cos \\theta \\mathop{}\\!\\mathrm{tr}\\left( \\mathbf{I} \\right) + \\left( {1 - \\cos \\theta } \\right) \\mathop{}\\!\\mathrm{tr} \\left( { \\mathbf{n} {\\mathbf{n}^T}} \\right) + \\sin \\theta \\mathop{}\\!\\mathrm{tr} ({\\mathbf{n}^ \\wedge })\\\\\n",
    "&= 3\\cos \\theta  + (1 - \\cos \\theta )\\\\\n",
    "&= 1 + 2\\cos \\theta .\n",
    "\\end{aligned} \n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5b276-d2c9-44be-8429-646fe1f0d6c0",
   "metadata": {},
   "source": [
    "Therefore:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta = \\arccos \\left( \\frac{\\mathrm{tr}(\\mathbf{R}) - 1}{2}  \\right) .\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Regarding the axis $ \\mathbf{n} $, since the rotation axis does not change after the rotation, we have:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{R} \\mathbf{n} = \\mathbf{n}.\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f413f5b4-e9a5-4307-ac69-318999e6ffc6",
   "metadata": {},
   "source": [
    "\n",
    "Therefore, the axis $ \\mathbf{n} $ is the eigenvector corresponding to the matrix $ \\mathbf{R}$'s eigenvalue 1. Solving this equation and normalizing it gives the axis of rotation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63607305-f879-41ab-ad02-ea81c66950cc",
   "metadata": {},
   "source": [
    "### Quaternions\n",
    "\n",
    "\n",
    "The rotation matrix describes 3 degrees of freedom with 9 quantities, of course, with redundancy; the Euler angles and the rotation vectors are compact but suffer from the singularity. In fact, we $\\textit{cannot}$ find a [three-dimensional vector description without singularity](https://www.malcolmdshuster.com/FC_Stuelpnagel_1964_param_SIAM.pdf). This is somewhat similar to using two coordinates to represent the Earth's surface (such as longitude and latitude), which also has the singularity (longitude is meaningless when the latitude is $ \\pm  90 ^ \\circ $ ).\n",
    "\n",
    "\n",
    "\n",
    "Comparing quaternions to complex numbers can help you understand quaternions faster. For example, when we want to rotate the vector of a complex plane by $\\theta$, we can multiply this complex vector by $\\mathrm{e}^{i \\theta}$, which is represented by polar coordinates. It can also be written in the usual form like the famous Euler equation:\n",
    "\\begin{equation}\n",
    "\\mathrm{e}^{i\\theta} = \\cos \\theta + i \\sin \\theta.\n",
    "\\end{equation}\n",
    "This is a unit-length complex number. Therefore, in two dimensions, the rotation can be described by a unit complex number. Similarly, we will see that 3D rotation can be described by a unit quaternion.\n",
    "\n",
    "\n",
    "A quaternion $ \\mathbf{q} $ has a real part and three imaginary parts. We write the real part in the front (and there are also some books where the real part is in the last), like this:\n",
    "\\begin{equation}\n",
    "\\mathbf{q} = q_0 + q_1 i + q_2 j + q_3 k,\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "We can also use a scalar and a vector to express quaternions:\n",
    "$ \\mathbf{q} = \\left[ s, \\mathbf{v} \\right]^T, \\quad s=q_0 \\in \\mathbb{R},\\quad \\mathbf{v} = [q_1, q_2, q_3]^T \\in \\mathbb{R}^3,$\n",
    "\n",
    "Here, $ s $ is the real part of the quaternion, and $ \\mathbf {v} $ is its imaginary part. If the imaginary part of a quaternion is $ \\mathbf {0} $, it is called $\\textit{real quaternion}$. Conversely, if its real part is $ 0 $, it is called $\\textit{imaginary quaternion}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c6fa4-2fbc-467c-953b-d2b8059df97a",
   "metadata": {},
   "source": [
    "## Conversion of Quaternions to Other Rotation Representations\n",
    "quaternion multiplication can also be written as a matrix multiplication.\n",
    "\n",
    "\n",
    "Let $\\mathbf{q}=[s,\\mathbf{v}]^T$, then define the following symbols $^{+}$ and $^{\\oplus}$ as:\n",
    "\\begin{equation}\n",
    "\t\\mathbf{q}^{+}=\\left[\\begin{array}{cc}\n",
    "\t\ts&-\\mathbf{v}^T \\\\\n",
    "\t\t\\mathbf{v}&s\\mathbf{I}+\\mathbf{v}^{\\wedge}\n",
    "\t\\end{array}\\right],\\quad\n",
    "\t\\mathbf{q}^{\\oplus}=\n",
    "\t\\left[\\begin{array}{cc}\n",
    "\t\ts & -\\mathbf{v}^T \\\\\n",
    "\t\t\\mathbf{v} & s\\mathbf{I}-\\mathbf{v}^{\\wedge}\n",
    "\t\\end{array}\\right],\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "These two symbols map the quaternion to a 4$\\times$4 matrix. Then the quaternion multiplication can be written in the form of a matrix:\n",
    "\\begin{equation}\n",
    "\t\\mathbf{q}_1^ + {\\mathbf{q}_2} = \\left[ {\\begin{array}{*{20}{c}}\n",
    "\t\t\ts_1&-\\mathbf{v}_1^T\\\\\n",
    "\t\t\t\\mathbf{v}_1 & s_1 \\mathbf{I} + \\mathbf{v}_1^\\wedge\n",
    "\t\\end{array}} \\right]\\left[ {\\begin{array}{*{20}{c}}\n",
    "\t\t\t{{s _2}} \\\\\n",
    "\t\t\t{{\\mathbf{v} _2}}\n",
    "\t\\end{array}} \\right] = \\left[ {\\begin{array}{*{20}{c}}\n",
    "\t\t\t{ - \\mathbf{v} _1^T{\\mathbf{v} _2} + {s _1}{s _2}} \\\\\n",
    "\t\t\t{{s _1}{\\mathbf{v} _2} + {s _2}{\\mathbf{v} _1} + \\mathbf{v} _1^ \\wedge {\\mathbf{v} _2}}\n",
    "\t\\end{array}} \\right] = \\mathbf{q}_1 \\mathbf{q}_2\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Note that the left side is matrix multiplication and the right side is quaternion multiplication. Similar for $^\\oplus$, we get:\n",
    "\\begin{equation}\n",
    "\t\\mathbf{q}_1 \\mathbf{q}_2 = \\mathbf{q}_1^{+} \\mathbf{q}_2 = \\mathbf{q}_2^{\\oplus} \\mathbf{q}_1.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Then, consider the problem of using a quaternion to rotate a spatial point. According to the previous section, we have:\n",
    "\\begin{equation}\n",
    "\t\\begin{split}\n",
    "\t\t\\mathbf{p}' &= \\mathbf{q} \\mathbf{p} \\mathbf{q}^{-1} = \\mathbf{q}^+ \\mathbf{p}^+ \\mathbf{q}^{ -1} \\\\\n",
    "\t\t&= \\mathbf{q}^+ \\mathbf{q}^{{-1}^{\\oplus}} \\mathbf{p}.\n",
    "\t\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Substituting the matrix corresponding to two symbols, we get:\n",
    "\\begin{equation}\\label{eq:quaternion-to-rotation-matrix-derive}\n",
    "\t{\\mathbf{q}^ + }{\\left( {{\\mathbf{q}^{ - 1}}} \\right)^ \\oplus } = \\left[ \\begin{array}{*{20}{c }}\n",
    "\t\ts&-\\mathbf{v}^T\\\\\n",
    "\t\t\\mathbf{v}&s\\mathbf{I}+\\mathbf{v}^\\wedge\n",
    "\t\\end{array} \\right]\\left[\\begin{array}{*{20}{c}}\n",
    "\t\ts&{\\mathbf{v} ^T}\\\\\n",
    "\t\t{ - \\mathbf{v} }&{s\\mathbf{I} + \\mathbf{v} ^ \\wedge }\n",
    "\t\\end{array} \\right] = \\left[ \\begin{array}{*{20}{c}}\n",
    "\t\t1&\\mathbf{0} \\\\\n",
    "\t\t\\mathbf{0}^T&\\mathbf{v}\\mathbf{v}^T + {s^2} \\mathbf{I} + 2s\\mathbf{v} ^ \\wedge + {(\\mathbf{v} ^ \\wedge)}^2\n",
    "\t\\end{array} \\right].\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a6536-4467-4f35-956c-56a3e7f4b5b5",
   "metadata": {},
   "source": [
    "Since $\\mathbf{p}'$ and $\\mathbf{p}$ are both imaginary quaternions, so in fact that the bottom right corner of the matrix gives the transformation formula $\\textit{from quaternion to rotation matrix}$ :\n",
    "\\begin{equation}\n",
    "\t\\mathbf{R} = \\mathbf{v} \\mathbf{v}^T + {s^2} \\mathbf{I} + 2s\\mathbf{v} ^ \\wedge + {(\\mathbf{v } ^ \\wedge)}^2.\n",
    "\\end{equation}\n",
    "In order to obtain the conversion formula of the quaternion to the rotation vector, we take the trace on both sides of the above formula:\n",
    "\\begin{equation}\n",
    "\t\\begin{aligned}\n",
    "\t\t\\mathrm{tr}(\\mathbf{R}) &= \\mathrm{tr}(\\mathbf{v}\\mathbf{v}^T) + 3s^2 + 2s \\cdot 0 + \\mathrm{tr }((\\mathbf{v}^\\wedge)^2) \\\\\n",
    "\t\t&= v_1^2+v_2^2+v_3^2 + 3s^2 - 2(v_1^2+v_2^2+v_3^2) \\\\\n",
    "\t\t&= (1-s^2) + 3s^2 -2(1-s^2)\\\\\n",
    "\t\t&= 4s^2 -1.\n",
    "\t\\end{aligned}\n",
    "\\end{equation}\n",
    "Also obtained by the formula:\n",
    "\\begin{equation}\n",
    "\t\\begin{aligned}\n",
    "\t\t\\theta &= \\arccos\\left(\\frac{\\mathrm{tr}(\\mathbf{R})-1}{2}\\right) \\\\\n",
    "\t\t&=\\arccos(2s^2-1),\n",
    "\t\\end{aligned}\n",
    "\\end{equation}\n",
    "which means:\n",
    "\\begin{equation}\n",
    "\t\\cos \\theta =2s^2-1=2 \\cos^2 \\frac{\\theta}{2} -1,\n",
    "\\end{equation}\n",
    "and so we have:\n",
    "\\begin{equation}\n",
    "\t\\theta = 2 \\arccos s.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307dca8-3eca-4ec0-8720-23d92fc3ea83",
   "metadata": {},
   "source": [
    "If we replace $ \\mathbf{p} $ (a general vector) with $ \\mathbf{v} $ (the imaginary part of $ \\mathbf{q} $) in the quaternion rotation operation, the equation becomes: The quaternion $\\mathbf{q} $ can be represented in matrix form as:\n",
    "\n",
    "$\n",
    "\\mathbf{q}^+ = \\left[ \\begin{array}{cc}\n",
    "s & -\\mathbf{v}^T \\\\\n",
    "\\mathbf{v} & s\\mathbf{I} + \\mathbf{v}^\\wedge\n",
    "\\end{array} \\right],\n",
    "$\n",
    "\n",
    "$\\mathbf{q}^{\\oplus}=\n",
    "\\left[\\begin{array}{cc}\n",
    "    s & -\\mathbf{v}^T \\\\\n",
    "    \\mathbf{v} & s\\mathbf{I}-\\mathbf{v}^{\\wedge}\n",
    "\\end{array}\\right]$\n",
    "\n",
    "and its conjugate $\\mathbf{q}^{-1} $ as:\n",
    "\n",
    "$\n",
    "\\left( \\mathbf{q}^{-1} \\right)^\\oplus = \\left[ \\begin{array}{cc}\n",
    "s & \\mathbf{v}^T \\\\\n",
    "-\\mathbf{v} & s\\mathbf{I} + \\mathbf{v}^\\wedge\n",
    "\\end{array} \\right].\n",
    "$\n",
    "\n",
    "Now, if we replace $\\mathbf{p} $ (a general vector) with $\\mathbf{v} $ (the imaginary part of $\\mathbf{q} $), we want to evaluate:\n",
    "\n",
    "$\n",
    "\\mathbf{q}^+ \\mathbf{v} \\left( \\mathbf{q}^{-1} \\right)^\\oplus.\n",
    "$\n",
    "\n",
    "To do this, we express $\\mathbf{v} $ in a 4D vector form as:\n",
    "\n",
    "$\n",
    "\\mathbf{v}_{\\text{4D}} = \\left[ \\begin{array}{c}\n",
    "0 \\\\\n",
    "\\mathbf{v}\n",
    "\\end{array} \\right].\n",
    "$\n",
    "\n",
    "### Step-by-Step Calculation:\n",
    "\n",
    "1. **Multiply $\\mathbf{q}^+ $ by $\\mathbf{v}_{\\text{4D}} $:**\n",
    "$\n",
    "\\mathbf{q}^+ \\mathbf{v}_{\\text{4D}} = \\left[ \\begin{array}{cc}\n",
    "s & -\\mathbf{v}^T \\\\\n",
    "\\mathbf{v} & s\\mathbf{I} + \\mathbf{v}^\\wedge\n",
    "\\end{array} \\right] \\left[ \\begin{array}{c}\n",
    "0 \\\\\n",
    "\\mathbf{v}\n",
    "\\end{array} \\right] = \\left[ \\begin{array}{c}\n",
    "-\\mathbf{v}^T \\mathbf{v} \\\\\n",
    "s\\mathbf{v} + \\mathbf{v}^\\wedge \\mathbf{v}\n",
    "\\end{array} \\right].\n",
    "$\n",
    "\n",
    "Since $\\mathbf{v}^\\wedge \\mathbf{v} = \\mathbf{0} $ (the skew-symmetric matrix times the vector results in zero), this simplifies to:\n",
    "\n",
    "$\n",
    "\\mathbf{q}^+ \\mathbf{v}_{\\text{4D}} = \\left[ \\begin{array}{c}\n",
    "-\\|\\mathbf{v}\\|^2 \\\\\n",
    "s\\mathbf{v}\n",
    "\\end{array} \\right].\n",
    "$\n",
    "\n",
    "2. **Multiply by $\\left( \\mathbf{q}^{-1} \\right)^\\oplus $:**\n",
    "$\n",
    "\\left[ \\begin{array}{cc}\n",
    "s & \\mathbf{v}^T \\\\\n",
    "-\\mathbf{v} & s\\mathbf{I} + \\mathbf{v}^\\wedge\n",
    "\\end{array} \\right] \\left[ \\begin{array}{c}\n",
    "-\\|\\mathbf{v}\\|^2 \\\\\n",
    "s\\mathbf{v}\n",
    "\\end{array} \\right].\n",
    "$\n",
    "\n",
    "Expanding this multiplication results in:\n",
    "\n",
    "$\n",
    "\\left[ \\begin{array}{c}\n",
    "s(-\\|\\mathbf{v}\\|^2) + \\mathbf{v}^T (s\\mathbf{v}) \\\\\n",
    "-\\mathbf{v}(-\\|\\mathbf{v}\\|^2) + (s\\mathbf{I} + \\mathbf{v}^\\wedge)(s\\mathbf{v})\n",
    "\\end{array} \\right].\n",
    "$\n",
    "\n",
    "### Simplification:\n",
    "- The scalar component simplifies to zero due to cancellation between $s(-\\|\\mathbf{v}\\|^2) $ and $\\mathbf{v}^T (s\\mathbf{v}) $.\n",
    "- The vector component simplifies to $s^2 \\mathbf{v} $ because $(s\\mathbf{I} + \\mathbf{v}^\\wedge)(s\\mathbf{v}) = s^2 \\mathbf{v} $ (since $\\mathbf{v}^\\wedge \\mathbf{v} = \\mathbf{0} $).\n",
    "\n",
    "### Final Result:\n",
    "$\n",
    "\\mathbf{q}^+ \\mathbf{v} \\left( \\mathbf{q}^{-1} \\right)^\\oplus = \\left[ \\begin{array}{c}\n",
    "0 \\\\\n",
    "s^2 \\mathbf{v}\n",
    "\\end{array} \\right].\n",
    "$\n",
    "\n",
    "This confirms that when the vector $\\mathbf{v} $ (the imaginary part of $\\mathbf{q} $) is used in the rotation operation $\\mathbf{q} \\mathbf{v} \\mathbf{q}^{-1} $, it remains aligned with itself, verifying that it constitutes the rotation axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba99ca63-f5ae-4715-9a5b-46ae54d43803",
   "metadata": {},
   "source": [
    "To find $\\sin \\frac{\\theta}{2} $, we start from the known relationship between $\\theta $ and $q_0 $.\n",
    "\n",
    "### Derivation:\n",
    "Given that:\n",
    "$\n",
    "\\theta = 2 \\arccos(q_0),\n",
    "$\n",
    "\n",
    "\n",
    "we have:\n",
    "$\n",
    "\\frac{\\theta}{2} = \\arccos(q_0).\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "From trigonometric identities:\n",
    "$\n",
    "\\sin^2 \\left( \\arccos(q_0) \\right) = 1 - q_0^2.\n",
    "$\n",
    "\n",
    "Therefore:\n",
    "$\n",
    "\\sin \\frac{\\theta}{2} = \\sqrt{1 - q_0^2}.\n",
    "$\n",
    "\n",
    "### Explanation:\n",
    "- $q_0 $ is the scalar part of the quaternion, and for a normalized quaternion, $q_0^2 + q_1^2 + q_2^2 + q_3^2 = 1 $.\n",
    "- The expression $\\sin \\frac{\\theta}{2} = \\sqrt{1 - q_0^2} $ holds true because $\\cos(\\frac{\\theta}{2}) = q_0 $, and $\\sin^2(\\frac{\\theta}{2}) + \\cos^2(\\frac{\\theta}{2}) = 1 $ by the Pythagorean identity.\n",
    "\n",
    "### Final Result:\n",
    "$\n",
    "\\sin \\frac{\\theta}{2} = \\sqrt{1 - q_0^2}.\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b210d3a-aed2-4dc0-889e-3436e3c54312",
   "metadata": {},
   "source": [
    "\n",
    "For the rotation axis, if we replace $\\mathbf{p}$ with the imaginary part of $\\mathbf{q}$ in the formula quaternion-to-rotation-matrix-derive, it is easy to know the imaginary part of  $\\mathbf{q}$ is not moving when it is rotated, that is, it constitutes exactly the rotation axis. So we get the rotation axis just by normalizing $\\mathbf{q}$'s imaginary part. In summary, the conversion formula from quaternion to rotation vector can be written as follows:\n",
    "\n",
    "\n",
    "$\\begin{equation}\n",
    "\t\t\\begin{cases}\n",
    "\t\t\\theta = 2\\arccos {q_0}\\\\\n",
    "\t\t{\\left[ {{n_x},{n_y},{n_z}} \\right]^T} = {{{\\left[ {{q_1},{q_2},{q_3}} \\right] }^T}}/{\\sin \\frac{\\theta }{2}}\n",
    "\t\\end{cases} .\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa15fb-7c25-4486-81e7-ba896f1b3201",
   "metadata": {},
   "source": [
    "## Exponential Map of $\\mathrm{SE}(3)$\n",
    "\n",
    "The exponential map on $\\mathfrak{se}(3)$ is described below. To save space, we no longer deduct the exponential mapping in detail like $\\mathfrak{so}(3)$. The exponential mapping on $\\mathfrak{se}(3)$ is as follows:\n",
    "\\begin{align}\n",
    "\\exp \\left( {{ \\boldsymbol{\\xi} ^ \\wedge }} \\right) &= \\left[ {\\begin{array}{*{20}{c}}\n",
    "    {\\sum\\limits_{n = 0}^\\infty {\\frac{1}{{n!}}{{\\left( {{\\boldsymbol{\\phi} ^ \\wedge }} \\right)}^n} } }&{\\sum\\limits_{n = 0}^\\infty {\\frac{1}{{\\left( {n + 1} \\right)!}}{{\\left( {{\\boldsymbol{\\phi } ^ \\wedge }} \\right)}^n} \\boldsymbol{\\rho} } }\\\\\n",
    "    {{\\mathbf{0}^T}}&1\n",
    "    \\end{array}} \\right] \\\\\n",
    "&\\buildrel \\Delta \\over = \\left[ {\\begin{array}{*{20}{c}}\n",
    "    \\mathbf{R} &{\\mathbf{J\\rho} } \\\\\n",
    "    {{\\mathbf{0}^T}}&1\n",
    "    \\end{array}} \\right] = \\mathbf{T}.\n",
    "\\end{align}\n",
    "\n",
    "With a little patience, you can derive the Taylor expansion from the practice of $\\mathfrak{so}(3)$. Let $\\boldsymbol{\\phi}=\\theta \\mathbf{a}$, where $\\mathbf{a}$ is the unit vector, then:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\sum\\limits_{n = 0}^\\infty {\\frac{1}{{\\left( {n + 1} \\right)!}}{{\\left( {{\\boldsymbol{\\phi} ^ \\wedge }} \\right)}^n}} &= \\mathbf{I} + \\frac{1}{{2!}}\\theta {\\mathbf{a}^ \\wedge } + \\frac{1}{{3 !}}{\\theta ^2}{\\left( {{\\mathbf{a}^ \\wedge }} \\right)^2} + \\frac{1}{{4!}}{\\theta ^3}{ \\left( {{\\mathbf{a}^ \\wedge }} \\right)^3} + \\frac{1}{{5!}}{\\theta ^4}{\\left( {{\\mathbf{a} ^ \\wedge }} \\right)^4} \\cdots \\\\\n",
    "&= \\frac{1}{\\theta }\\left( {\\frac{1}{{2!}}{\\theta ^2} - \\frac{1}{{4!}}{\\theta ^4} + \\cdots } \\right)\\left( {{\\mathbf{a}^ \\wedge }} \\right) + \\frac{1}{\\theta }\\left( {\\frac{1}{{3!}} {\\theta ^3} - \\frac{1}{5}{\\theta ^5} + \\cdots } \\right){\\left( {{\\mathbf{a}^ \\wedge }} \\right)^2} + \\mathbf{I}\\\\\n",
    "&= \\frac{1}{\\theta }\\left( {1 - \\cos \\theta } \\right)\\left( {{\\mathbf{a}^ \\wedge }} \\right) + \\frac{{\\theta - \\sin \\theta }}{\\theta }\\left( {\\mathbf{a}{\\mathbf{a}^T} - \\mathbf{I}} \\right) + \\mathbf{I}\\\\\n",
    "&= \\frac{{\\sin \\theta }}{\\theta }\\mathbf{I} + \\left( {1 - \\frac{{\\sin \\theta }}{\\theta }} \\right)\\mathbf{a }{\\mathbf{a}^T} + \\frac{{1 - \\cos \\theta }}{\\theta }{\\mathbf{a}^ \\wedge } \\buildrel \\Delta \\over = \\mathbf{J}.\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52fcf0e-650d-4b90-8246-c7ff76da9ef6",
   "metadata": {},
   "source": [
    "From the results, we can see the $\\mathbf{R}$ in the upper left corner of the exponential map of $\\boldsymbol{\\xi}$ is just the well-known $\\mathrm{SO}(3)$, which means the rotation part of $\\boldsymbol{\\xi}$ is just the rotation part in $\\mathfrak{so}(3)$. The $\\mathbf{J}$ in the upper right corner is given by the above derivation:\n",
    "$\\begin{equation}\n",
    "\\mathbf{J} = \\frac{{\\sin \\theta }}{\\theta } \\mathbf{I} + \\left( {1 - \\frac{{\\sin \\theta }}{\\theta }} \\right) \\mathbf{a} { \\mathbf{a}^T} + \\frac{{1 - \\cos \\theta }}{\\theta }{ \\mathbf{a}^ \\wedge }.\n",
    "\\end{equation}$\n",
    "\n",
    "This formula is somewhat similar to the Rodrigues formula but not exactly the same. We see that after passing the exponential map, the translation part is multiplied by a linear jacobian matrix $\\mathbf{J}$. Please pay attention to the $\\mathbf{J}$ here, as it will be used later.\n",
    "\n",
    "Similarly, although we can also derive the logarithmic mapping analytically, there is a more trouble-free way to find the corresponding vector on $\\mathfrak{so}(3)$ according to the transformation matrix $\\mathbf{T}$: from the upper left corner $\\mathbf{R}$ we can calculate the rotation vector, while $\\mathbf{t}$ the upper right corner satisfies:\n",
    "\\begin{equation}\n",
    "\\mathbf{t} = \\mathbf{J} \\boldsymbol{\\rho}.\n",
    "\\end{equation}\n",
    "\n",
    "Since $\\mathbf{J}$ can be obtained from $\\boldsymbol{\\phi}$, $\\boldsymbol{\\rho}$ can also be solved by this linear equation. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
