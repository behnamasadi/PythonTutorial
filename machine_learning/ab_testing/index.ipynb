{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24414a3d-e948-42c1-861a-04d3ddf9043e",
   "metadata": {},
   "source": [
    "A/B testing is a fundamental technique used in both **machine learning** and **product release rollout** to compare two versions (A and B) of a system, feature, or model to determine which one performs better according to a defined metric. Here’s how it works in both contexts:\n",
    "\n",
    "---\n",
    "\n",
    "##  1. **A/B Testing in Machine Learning**\n",
    "\n",
    "In ML, A/B testing is often used when:\n",
    "\n",
    "* You’ve developed a **new model (B)** and want to compare it against your **current production model (A)**.\n",
    "* You want to test changes to **feature engineering, model architecture**, or **inference logic**.\n",
    "\n",
    "###  **Typical Use Cases**\n",
    "\n",
    "* Compare a new recommendation model to the current one.\n",
    "* Test a new fraud detection model in production.\n",
    "* Evaluate a different hyperparameter setting or loss function.\n",
    "\n",
    "###  **How it works**\n",
    "\n",
    "* **Group A**: users or traffic are served the output of the existing model.\n",
    "* **Group B**: the rest are served the output of the new model.\n",
    "* You collect metrics like:\n",
    "\n",
    "  * Click-through rate (CTR)\n",
    "  * Precision / Recall\n",
    "  * Conversion rate\n",
    "  * Revenue impact\n",
    "  * Latency and resource usage\n",
    "\n",
    "###  Example\n",
    "\n",
    "You're running a movie recommendation service:\n",
    "\n",
    "* **Model A**: Collaborative filtering\n",
    "* **Model B**: Deep learning–based recommender\n",
    "\n",
    "You deploy both to 50% of users each, track user engagement, and find that Model B improves watch time by 15%.\n",
    "\n",
    "---\n",
    "\n",
    "##  2. **A/B Testing in Release Rollout (DevOps/ML Ops)**\n",
    "\n",
    "Here, A/B testing is part of **feature rollout strategies**, especially for:\n",
    "\n",
    "* Gradual rollouts of new code/models\n",
    "* Safe deployment of potentially risky changes\n",
    "\n",
    "###  **How it fits in a release cycle**\n",
    "\n",
    "* **Canary releases**: Send traffic to new version B for a small % of users.\n",
    "* **Shadow deployment**: Run model B alongside A (not user-facing), just to observe behavior.\n",
    "* **Full A/B test**: Randomly assign users to A or B and compare real-world metrics.\n",
    "\n",
    "###  Example in ML Ops:\n",
    "\n",
    "You trained a new spam detection model:\n",
    "\n",
    "* You deploy it in **shadow mode**, logging predictions.\n",
    "* Then move to **A/B testing** where 10% of users get the new model.\n",
    "* You compare false positives and user reports before a full rollout.\n",
    "\n",
    "---\n",
    "\n",
    "##  3. **Designing a Good A/B Test**\n",
    "\n",
    "To ensure valid results:\n",
    "\n",
    "| Principle                    | Why it Matters                                                     |\n",
    "| ---------------------------- | ------------------------------------------------------------------ |\n",
    "| **Random assignment**        | Reduces bias from external factors.                                |\n",
    "| **Large enough sample size** | Ensures statistical significance.                                  |\n",
    "| **Clear success metrics**    | Define beforehand: e.g., lower churn rate, higher accuracy.        |\n",
    "| **Statistical testing**      | Use t-tests, chi-square, or Bayesian inference to compare A and B. |\n",
    "\n",
    "---\n",
    "\n",
    "##  4. **Common Tools and Frameworks**\n",
    "\n",
    "* **For ML model serving**: Seldon, KFServing, MLflow\n",
    "* **For experimentation**: Optimizely, LaunchDarkly, Google Optimize (retired), or in-house platforms\n",
    "* **Statistical libraries**: SciPy, statsmodels, PyMC\n",
    "\n",
    "---\n",
    "\n",
    "##  Summary Table\n",
    "\n",
    "| Aspect    | Model A (Control)             | Model B (Test)                |\n",
    "| --------- | ----------------------------- | ----------------------------- |\n",
    "| Type      | Existing system               | New model/system              |\n",
    "| Purpose   | Baseline                      | Innovation                    |\n",
    "| Traffic % | Usually 50% (or configurable) | The rest                      |\n",
    "| Metrics   | Defined KPIs                  | Same KPIs                     |\n",
    "| Decision  | If B outperforms A → rollout  | Otherwise → revert or iterate |\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
