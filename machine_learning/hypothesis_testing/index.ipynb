{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550c4629",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "\n",
    "When do you need a hypothesis? Whenever you want to prove or draw a conclusion about the population with a sample of that population.\n",
    "\n",
    "\n",
    "So we make a sample from a population, if you only want to describe that sample you use **descriptive statistic**, and you calculate for instance mean or standard deviation in order to describe the sample, but if we want to make a statement about the whole population, so we use our sample and with Hypothesis Testing we can infer the population, so the goal of Hypothesis Testing is use sample from a population to test a hypothesis about the population.\n",
    "\n",
    "When you want to formulate hypothesis there are always two hypothesis that claim the opposite\n",
    "\n",
    "## Null Hypothesis\n",
    "\n",
    "**Null Hypothesis ($ H_0 $)**: This is a statement that there is no effect or no difference. It's what you're trying to test against. For instance there is no difference between **Drug A** and **Drug B**.\n",
    "\n",
    "## Alternative Hypothesis \n",
    "**Alternative Hypothesis ($ H_a $ or $ H_1 $)**: This is what you want to prove, e.g., that there is a difference or an effect.\n",
    "For instance, **Drug A** is superior to Drug B.\n",
    "\n",
    "\n",
    "Hypothesis testing can only determine with a probability of error whether a Hypothesis is accepted or rejected.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018b92a",
   "metadata": {},
   "source": [
    "## P values\n",
    "\n",
    "The **$ p $-value** used in statistics to measure how surprising or unlikely your data is, under  null hypothesis.\n",
    "\n",
    "**The intuition behind P values**\n",
    "Imagine you have a coin and you suspect it might be biased towards heads. To test this, you decide to flip the coin 100 times. Your null hypothesis (the assumption you're testing against) is that the coin is fair, meaning it has an equal chance of landing heads or tails.\n",
    "\n",
    "After flipping the coin 100 times, suppose you get an unusually high number of heads, say 70 heads and 30 tails. You might start to think this result is pretty strange if the coin were truly fair.\n",
    "\n",
    "Here's where the **$ p $-value** comes in. The **$ p $-value** is a number between 0 and 1 that tells you how likely it is to see a result as extreme as yours (or more extreme) if the null hypothesis were true. In our example, if the p-value is very low (let's say 0.01), it means that getting 70 heads out of 100 flips would be very unlikely if the coin were fair. A low p-value suggests that maybe your assumption (the null hypothesis) that the coin is fair might not be right.\n",
    "\n",
    "\n",
    "- A low **$ p $-value** (typically, a threshold like 0.05 or 5% is used), it suggests that the observed data is inconsistent with the null hypothesis, so you might reject the null hypothesis in favor of the alternative hypothesis (which is the hypothesis that there is an effect or a difference).\n",
    "- A high **$ p $-value** means you don't have enough statistical evidence to reject the null hypothesis.\n",
    "\n",
    "However, a low p-value doesn't prove the alternative hypothesis is true. It only suggests that the data you observed are unlikely under the assumption that the null hypothesis is true. Other factors, like the design of the experiment and assumptions of the statistical test, also play critical roles in the interpretation of **$ p $-value**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c9556f",
   "metadata": {},
   "source": [
    "**Technical way of describing the p-value**\n",
    "\n",
    "The **$ p $-value** is the probability of observing a test statistic as extreme as, or more extreme than, the statistic computed from the data, assuming that the null hypothesis is true. \n",
    "\n",
    "\n",
    "**Test Statistic**: This is a number calculated from your data that is used to evaluate how compatible your data is with the null hypothesis. The form of the test statistic depends on the type of test you're conducting (e.g., t-test, chi-square test). For instance, in our coin flip example, the test statistic could be the number of heads observed.\n",
    "\n",
    "**Observing a Test Statistic as Extreme as, or More Extreme Than, the Statistic Computed from the Data**: comparing what you actually observed in your experiment or study to what you would expect under the null hypothesis. \"As extreme as, or more extreme than\" refers to outcomes that are at least as unlikely as the actual outcome you got, given the null hypothesis is true.\n",
    "\n",
    "**Assuming That the Null Hypothesis is True**: The calculation of the p-value is done under the assumption that the null hypothesis is correct. This is crucial because the p-value is meant to test the strength of evidence against the null hypothesis.\n",
    "\n",
    "**Probability**: The **$ p $-value** itself is a probability. It measures the likelihood of observing your actual test statistic (or one more extreme) purely by chance if the null hypothesis were true. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124df24",
   "metadata": {},
   "source": [
    "## Test Statistic\n",
    "### t-test\n",
    "The t-test is a statistical test used to determine if there is a significant difference between the means of two groups, which may be related in certain features. It's widely used in hypothesis testing to assess the significance of the differences between two sample means. There are several types of t-tests, including:\n",
    "\n",
    "1. **One-sample t-test** compares the mean of a single group against a known mean. For instance a chocklate factory claim that its chockale br is 50 grams, We gather 30 bars and calculated the mean value which is 48 grams and we can compare it to the 50 grams.\n",
    "\n",
    "2. **Two-sample (independent) t-test** compares the means of two independent or unrelated groups to determine if there is a significant difference between them. Example: effectiveness of two painkillers on two groups of patient, compring the mean value of the time that painkiller took to effect.\n",
    "\n",
    "3. **Paired t-test** compares the means from the same group at different times (say, one year apart), or the means from two groups that are somehow related or paired. For example effectiveness of a diet, we calculated the mean weight of participants before a diet and after the diet. \n",
    "\n",
    "\n",
    "\n",
    "### Formula for Two-sample (independent) t-test\n",
    "\n",
    "The formula to calculate the t-value in an independent t-test is:\n",
    "\n",
    "$ t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{ \\frac{s_1^2}{N_1} + \\frac{s_2^2}{N_2} }} $\n",
    "\n",
    "where:\n",
    "- $ \\bar{X}_1 $ and $ \\bar{X}_2 $ are the sample means,\n",
    "- $ s_1^2 $ and $ s_2^2 $ are the sample variances,\n",
    "- $ N_1 $ and $ N_2 $ are the sample sizes.\n",
    "\n",
    "The degrees of freedom (df) for this test is $ df = N_1 + N_2 - 2 $.\n",
    "\n",
    "After calculating the t-value, you compare it against a critical value from the t-distribution table based on your chosen significance level (alpha, typically 0.05) and degrees of freedom to determine if the difference is statistically significant.\n",
    "\n",
    "### Numerical Example\n",
    "\n",
    "Imagine you want to test if there is a significant difference in the exam scores between two groups of students, Group A and Group B. Here are their scores:\n",
    "\n",
    "- Group A: 85, 86, 88, 75, 78, 94, 98, 90, 94, 92\n",
    "- Group B: 78, 74, 88, 82, 82, 85, 89, 92, 90, 83\n",
    "\n",
    "Let's calculate the t-statistic for these two groups.\n",
    "\n",
    "The calculated t-statistic for the difference between the means of Group A and Group B is approximately 1.27. The critical t-value for a two-tailed test with $ \\alpha = 0.05 $ (95% confidence level) and 18 degrees of freedom is approximately 2.10. Since the absolute value of the t-statistic is less than the critical t-value, we fail to reject the null hypothesis. This means that based on our sample data and the chosen significance level, there is not enough evidence to conclude that there is a significant difference in the exam scores between the two groups. The p-value associated with our t-statistic is approximately 0.219, which is greater than 0.05, further supporting our failure to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c989d6",
   "metadata": {},
   "source": [
    "## Example Drug A and Drug B\n",
    "\n",
    "Imagine you have **Drug A** and **Drug B** and you test them on two patients, can we say because it worked on **patient1** and didn't work on **patient2** it is working? There might be several factors that contributed to that result. So now let's try it on $2000$ patients and **Drug A** cured $97\\%$ of people while **Drug B** cured only $3\\%$, so now the chance the result was random and there is no difference between them is unrealistic. Now imagine the success of **Drug A** is $37%$ and **Drug B** is  $31%$ on $50$ patients.\n",
    "\n",
    "So given that no study is perfect and there are always a few random things that change the result, how can we become confident that Drug A is superior?\n",
    "\n",
    "That's where the **$ p $-value** comes in. **$ p $-value** are numbers between  0 and 1 and quantify how confident we should be **Drug A** is different from **Drug B**.\n",
    "The closer a **$ p $-value** is to 0 the more confident we are that **Drug A** and **Drug B** are different. \n",
    "\n",
    "\n",
    "In practice, the commonly used threshold is $0.05$, meaning if there is no difference between **Drug A** and **Drug B**, and we did the exact same experiment then only $5\\%$ of those experiments would result is the wrong decision. Now let's repeat the experiment repeatedly, and we get the following (**$ p $-value** calculated using the Fisher test):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d133df9",
   "metadata": {},
   "source": [
    "| Drug A  |           | Drug B |           | p-value |\n",
    "|---------|-----------|--------|-----------|---------|\n",
    "| Cured   | Not Cured | Cured  | Not Cured |         |\n",
    "| 73      | 125       | 71     | 127       | 0.9     |\n",
    "| 71      | 127       | 72     | 126       | 1.0     |\n",
    "| 75      | 123       | 70     | 128       | 0.7     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882a915",
   "metadata": {},
   "source": [
    "## Example Effects of a new Fertilizer on Plant Growth\n",
    "\n",
    "Imagine you're a botanist studying the effects of a new fertilizer on plant growth. You have two groups of plants:\n",
    "\n",
    "1. **Control Group**: Plants not given the fertilizer.\n",
    "2. **Treatment Group**: Plants given the fertilizer.\n",
    "\n",
    "You want to know if the fertilizer has a significant effect on plant growth. To do this, you measure the height of the plants after a fixed period.\n",
    "\n",
    "**Hypotheses**:\n",
    "- $ H_0 $: The fertilizer has no effect on plant growth. (Mean height of Control Group = Mean height of Treatment Group)\n",
    "- $ H_a $: The fertilizer has an effect on plant growth. (Mean height of Control Group ≠ Mean height of Treatment Group)\n",
    "\n",
    "**Data**:\n",
    "Let's assume you measured the height (in cm) of 10 plants from each group:\n",
    "\n",
    "- Control Group: [15, 17, 16, 14, 15, 16, 17, 15, 16, 17]\n",
    "- Treatment Group: [18, 19, 20, 19, 18, 21, 19, 20, 19, 18]\n",
    "\n",
    "We'll use a two-sample t-test to determine if there's a significant difference in the means of the two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1fe46f",
   "metadata": {},
   "source": [
    "To calculate the p-value using a t-test for comparing the means of the control group and the treatment group, we'll go through the following steps:\n",
    "\n",
    "1. **Calculate the mean** of each group.\n",
    "2. **Calculate the standard deviation** of each group.\n",
    "3. **Calculate the standard error of the mean (SEM)** for each group.\n",
    "4. **Calculate the t-statistic** using the means, SEMs, and sample sizes of both groups.\n",
    "5. **Calculate the degrees of freedom** needed to look up the p-value.\n",
    "6. **Calculate the p-value** based on the t-statistic and degrees of freedom.\n",
    "\n",
    "\n",
    "\n",
    "For a two-tailed test (which checks for any difference between the means, not specifying direction), the p-value can be conceptualized as:\n",
    "\n",
    "$ \\text{p-value} = 2 \\times (1 - \\text{CDF}(t, df)) $\n",
    "\n",
    "Where:\n",
    "- $ \\text{CDF} $ refers to the cumulative distribution function for the t-distribution.\n",
    "- $ t $ is the observed t-statistic calculated from your data.\n",
    "- $ df $ are the degrees of freedom, which, for an independent samples t-test, are usually calculated as $ n_1 + n_2 - 2 $ for equal variances, or using a more complex formula for unequal variances and sample sizes.\n",
    "\n",
    "This formula is calculating the probability of observing a t-statistic as extreme as, or more extreme than, the observed t-statistic under the null hypothesis. The \"2 ×\" part accounts for both tails of the distribution since we're interested in differences in either direction (higher or lower).\n",
    "\n",
    "In practice, this calculation is not done manually but through  software. These functions internally use the properties of the t-distribution to find the p-value corresponding to the calculated t-statistic and the degrees of freedom for your specific test scenario.\n",
    "\n",
    "\n",
    "\n",
    "### Control Group\n",
    "- **Mean**: 15.8 cm\n",
    "- **Standard Deviation**: 1.033 cm\n",
    "- **Standard Error of the Mean (SEM)**: 0.327 cm\n",
    "\n",
    "### Treatment Group\n",
    "- **Mean**: 19.1 cm\n",
    "- **Standard Deviation**: 0.994 cm\n",
    "- **Standard Error of the Mean (SEM)**: 0.314 cm\n",
    "\n",
    "### T-test Results\n",
    "- **T-statistic**: -7.279\n",
    "- **P-value**: approximately 0.0000009162\n",
    "\n",
    "The T-statistic is -7.279, which indicates a significant difference between the control and treatment groups, given the very low P-value (less than 0.001). This means there is a statistically significant difference in plant height between the control group and the treatment group, favoring the hypothesis that the new fertilizer has a positive effect on plant growth.\n",
    "\n",
    "\n",
    "\n",
    "Refs [1](https://www.youtube.com/watch?v=vemZtEM63GY), [2](https://www.youtube.com/watch?v=udyAvvaMjfM), [3](https://www.youtube.com/watch?v=p0W1oKPP6eQ), [4](https://www.youtube.com/watch?v=0oc49DyA3hU), [5](https://www.youtube.com/watch?v=JQc3yx0-Q9E)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11e88a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.8,\n",
       " 1.0327955589886444,\n",
       " 19.1,\n",
       " 0.9944289260117533,\n",
       " 0.3265986323710904,\n",
       " 0.31446603773522014,\n",
       " -7.278624758728698,\n",
       " 9.162003368633656e-07)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "control_group = np.array([15, 17, 16, 14, 15, 16, 17, 15, 16, 17])\n",
    "treatment_group = np.array([18, 19, 20, 19, 18, 21, 19, 20, 19, 18])\n",
    "\n",
    "# Step 1 & 2: Calculate mean and standard deviation\n",
    "mean_control = np.mean(control_group)\n",
    "std_dev_control = np.std(control_group, ddof=1)  # Sample standard deviation\n",
    "mean_treatment = np.mean(treatment_group)\n",
    "std_dev_treatment = np.std(treatment_group, ddof=1)  # Sample standard deviation\n",
    "\n",
    "# Step 3: Calculate the Standard Error of the Mean (SEM) for each group\n",
    "n_control = len(control_group)\n",
    "n_treatment = len(treatment_group)\n",
    "sem_control = std_dev_control / np.sqrt(n_control)\n",
    "sem_treatment = std_dev_treatment / np.sqrt(n_treatment)\n",
    "\n",
    "# Step 4 & 5: Calculate t-statistic and degrees of freedom\n",
    "# Using scipy to calculate t-statistic and p-value directly\n",
    "t_stat, p_value = ttest_ind(control_group, treatment_group)\n",
    "\n",
    "mean_control, std_dev_control, mean_treatment, std_dev_treatment, sem_control, sem_treatment, t_stat, p_value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
