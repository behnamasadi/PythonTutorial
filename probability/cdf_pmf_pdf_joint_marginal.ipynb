{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optional-viking",
   "metadata": {},
   "source": [
    "## 1) Probability Density Function\n",
    "### 1-1) Discrete Random Variable PMF\n",
    " \n",
    "For a discrete random variable $X$ that takes on a finite or countably infinite number of possible values, we determined  for all of the possible values of , and called it the probability mass function **p.m.f.**\n",
    "p.m.f. gives the probability that a discrete random variable is exactly equal to some value.\n",
    " \n",
    "### Example of p.m.f\n",
    "we recorded the sequence of heads and tails in two tosses of a fair coin. The sample space for this random experiment is given by: $S = \\{hh, ht, th, tt\\}.\\notag$\n",
    "\n",
    "Suppose we are only interested in tosses that result in heads. We can define a random variable  $X$  that tracks the number of heads obtained in an outcome.\n",
    "\n",
    "\n",
    "$ X: S  \\rightarrow \\mathbb{R} $\n",
    "\n",
    "\n",
    "$\\begin{align*} \n",
    " S\\ &\\stackrel{\\text{function:}\\ X}{\\longrightarrow}\\ \\text{outputs:}\\ \\mathbb{R} \\\\ \n",
    "hh &\\quad\\stackrel{X}{\\mapsto}\\quad 2 \\\\ \n",
    "th &\\quad\\stackrel{X}{\\mapsto}\\quad 1 \\\\ \n",
    "ht &\\quad\\stackrel{X}{\\mapsto}\\quad 1 \\\\ \n",
    "tt &\\quad\\stackrel{X}{\\mapsto}\\quad 0 \n",
    "\\end{align*}$\n",
    "\n",
    "\n",
    "we compute the probability that the random variable  $X$  equals  1. There are two outcomes that lead to  $X$  taking the value 1, namely  $ht$  and  $th$\n",
    "\n",
    "$X(hh) = 2,\\quad X(ht) = X(th) = 1,\\quad X(tt) = 0.\\notag$\n",
    "\n",
    "\n",
    "$P(X=1) = P(\\{ht, th\\}) = \\frac{\\text{# outcomes in}\\ \\{ht, th\\}}{\\text{# outcomes in}\\ S} = \\frac{2}{4} = 0.5\\notag$\n",
    "\n",
    "\n",
    "$\\begin{align*} \n",
    "p(0) &= P(X=0) = P(\\{tt\\}) = 0.25 \\\\ \n",
    "p(2) &= P(X=2) = P(\\{hh\\}) = 0.25 \n",
    "\\end{align*}$\n",
    "\n",
    "We can represent probability mass functions numerically with:\n",
    "- Table\n",
    "- Graphically with a histogram, \n",
    "- Analytically with a formula.\n",
    "\n",
    "<img src='images/pmf_table_histogram.png'>\n",
    "\n",
    "Refs: <a href=\"https://stats.libretexts.org/Courses/Saint_Mary's_College_Notre_Dame/MATH_345__-_Probability_(Kuter)/3%3A_Discrete_Random_Variables/3.2%3A_Probability_Mass_Functions_(PMFs)_and_Cumulative_Distribution_Functions_(CDFs)_for_Discrete_Random_Variables#:~:text=In%20Example%203.2.,we%20found%20to%20be%200.5.\">1</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-trademark",
   "metadata": {},
   "source": [
    "### 1-2) Continuous Random Variable PDF\n",
    "For continuous random variables $X$, the probability that $X$ takes on any particular value  is 0. That is, finding $P(X=x)$ for a continuous random variable. Instead, we'll need to find the probability that  falls in some interval $(a,b)$ , that is, we'll need to find $P(a<X<b)$. We'll do that using a probability density function **p.d.f.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-boxing",
   "metadata": {},
   "source": [
    "#### Examples of continuous p.d.f\n",
    "\n",
    "\n",
    "1) suppose $X$ is uniformly distributed on the unit interval ${\\displaystyle [a,b]}$.\n",
    "\n",
    "${\\displaystyle {\\begin{cases}{\\frac {1}{b-a}}&{\\text{for }}x\\in [a,b]\\\\0&{\\text{otherwise}}\\end{cases}}}$\n",
    "\n",
    "\n",
    "2) Suppose $X$ is exponential distributed. Then the p.d.f of $X$ is given by\n",
    "\n",
    "$\t{\\displaystyle \\lambda e^{-\\lambda x}}$\n",
    "\n",
    "3) Suppose $X$ is normal distributed. Then the p.d.f of $X$ is given by\n",
    "\n",
    "${\\displaystyle {\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {x-\\mu }{\\sigma }}\\right)^{2}}}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-shanghai",
   "metadata": {},
   "source": [
    "## 2) Cumulative Distribution Function c.d.f\n",
    "\n",
    "The cumulative distribution function, **c.d.f.** of a random variable $X$ is a function on the real numbers that is denoted as  𝐹  and is given by:\n",
    "\n",
    "$F(x) = P(X\\leq x),\\quad \\text{for any}\\ x\\in\\mathbb{R}. \\label{cdf}$\n",
    "\n",
    "${\\displaystyle F:\\mathbb {R} \\rightarrow [0,1]}$ \n",
    "\n",
    " \n",
    "${\\displaystyle \\lim _{x\\rightarrow -\\infty }F(x)=0}$   \n",
    "\n",
    "\n",
    "${\\displaystyle \\lim _{x\\rightarrow \\infty }F(x)=1}$\n",
    " \n",
    "\n",
    "${\\displaystyle \\operatorname {P} (a<X\\leq b)=F_{X}(b)-F_{X}(a)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-evanescence",
   "metadata": {},
   "source": [
    "### 2-1) Discrete Random Variable c.d.f\n",
    "If $X$ is a purely discrete random variable, then it attains values ${\\displaystyle x_{1},x_{2},\\ldots }$   with probability ${\\displaystyle p_{i}=p(x_{i})}$, and the **c.d.f** of $X$ will be discontinuous at the points $x_{i}$:\n",
    "\n",
    "${\\displaystyle F_{X}(x)=\\operatorname {P} (X\\leq x)=\\sum _{x_{i}\\leq x}\\operatorname {P} (X=x_{i})=\\sum _{x_{i}\\leq x}p(x_{i}).} $\n",
    "\n",
    "#### Examples of discrete c.d.f\n",
    "1. In the tossing a fair coin example, we have: \n",
    "\n",
    "\n",
    "$\\begin{align*} \n",
    "F(0) &= P(X\\leq0) = P(X=0) = 0.25 \\\\ \n",
    "F(1) &= P(X\\leq1) = P(X=0\\ \\text{or}\\ 1) = p(0) + p(1) = 0.75 \\\\ \n",
    "F(2) &= P(X\\leq2) = P(X=0\\ \\text{or}\\ 1\\ \\text{or}\\ 2) = p(0) + p(1) + p(2) = 1 \n",
    "\\end{align*}$\n",
    "\n",
    "\n",
    "$F(x) = \\left\\{\\begin{array}{l l} \n",
    "0, & \\text{for}\\ x<0 \\\\ \n",
    "0.25 & \\text{for}\\ 0\\leq x <1 \\\\ \n",
    "0.75 & \\text{for}\\ 1\\leq x <2 \\\\ \n",
    "1 & \\text{for}\\ x\\geq 2. \n",
    "\\end{array}\\right.\\notag$\n",
    "\n",
    "\n",
    "2. A random variable  $X$  has a Bernoulli distribution with parameter  $p$ , where  $0≤𝑝≤1$ , if it has only two possible values, typically denoted  0  and  1. \n",
    "\n",
    "Bernoulli distribution **p.m.f.**:\n",
    "\n",
    "\n",
    "$\\begin{align*} \n",
    "p(0) &= P(X=0) = 1-p,\\\\ \n",
    "p(1) &= P(X=1) = p. \n",
    "\\end{align*}$\n",
    "\n",
    "\n",
    "Bernoulli distribution **c.d.f.**:\n",
    "\n",
    "$F(x) = \\left\\{\\begin{array}{r r} \n",
    "0, & x<0 \\\\ \n",
    "1-p, & 0\\leq x<1, \\\\ \n",
    "1, & x\\geq1. \n",
    "\\end{array}\\right.\\label{Berncdf}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-singapore",
   "metadata": {},
   "source": [
    "### 2-2) Continuous Random Variable \n",
    "The **c.d.f** of a continuous random variable $X$ can be expressed as follows:\n",
    "\n",
    "\n",
    "$F(x) = P(X\\leq x) = \\int\\limits^x_{-\\infty}\\! f(t)\\, dt, \\quad\\text{for}\\ x\\in\\mathbb{R}.\\notag$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-therapist",
   "metadata": {},
   "source": [
    "#### Examples of continuous c.d.f\n",
    "1) suppose $X$ is uniformly distributed on the unit interval ${\\displaystyle [a,b]}$.\n",
    "\n",
    "${\\displaystyle {\\begin{cases}0&{\\text{for }}x<a\\\\{\\frac {x-a}{b-a}}&{\\text{for }}x\\in [a,b]\\\\1&{\\text{for }}x>b\\end{cases}}}$\n",
    "\n",
    "\n",
    "2) Suppose $X$ is exponential distributed. Then the c.d.f of $X$ is given by\n",
    "\n",
    "${\\displaystyle F_{X}(x;\\lambda )={\\begin{cases}1-e^{-\\lambda x}&x\\geq 0,\\\\0&x<0.\\end{cases}}}$\n",
    "\n",
    "3) Suppose $X$ is normal distributed. Then the c.d.f of $X$ is given by\n",
    "\n",
    "${\\displaystyle F(x;\\mu ,\\sigma )={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}\\int _{-\\infty }^{x}\\exp \\left(-{\\frac {(t-\\mu )^{2}}{2\\sigma ^{2}}}\\ \\right)\\,dt}={\\displaystyle {\\frac {1}{2}}\\left[1+\\operatorname {erf} \\left({\\frac {x-\\mu }{\\sigma {\\sqrt {2}}}}\\right)\\right]}$\n",
    "\n",
    "4) Suppose $X$ is binomial distributed. Then the c.d.f of $X$ is given by\n",
    "\n",
    "${\\displaystyle F(k;n,p)=\\Pr(X\\leq k)=\\sum _{i=0}^{\\lfloor k\\rfloor }{n \\choose i}p^{i}(1-p)^{n-i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-syndicate",
   "metadata": {},
   "source": [
    "### 2-3) Relationship between PDF and CDF for a Continuous Random Variable\n",
    "\n",
    "Let  $X$  be a continuous random variable with pdf $f$  and cdf  $F$:\n",
    "- The cdf is found by integrating the pdf: $F(x) = \\int\\limits^x_{-\\infty}\\! f(t)\\, dt\\notag$\n",
    "- The pdf can be found by differentiating the cdf: $f(x) = \\frac{d}{dx}\\left[F(x)\\right]\\notag$\n",
    "\n",
    "\n",
    "#### Example\n",
    "\n",
    "Lets say your you have the following p.d.f\n",
    "\n",
    "$f(x) = \\left\\{\\begin{array}{l l} \n",
    "x, & \\text{for}\\ 0\\leq x\\leq 1 \\\\ \n",
    "2-x, & \\text{for}\\ 1< x\\leq 2 \\\\ \n",
    "0, & \\text{otherwise} \n",
    "\\end{array}\\right.\\notag$\n",
    "\n",
    "The c.d.f would be the following:\n",
    "\n",
    "\n",
    "$F(x) = \\left\\{\\begin{array}{l l} \n",
    "0, & \\text{for}\\ x<0 \\\\ \n",
    "\\frac{x^2}{2}, & \\text{for}\\ 0\\leq x \\leq 1 \\\\ \n",
    "2x - \\frac{x^2}{2} - 1, & \\text{for}\\ 1< x\\leq 2 \\\\ \n",
    "1, & \\text{for}\\ x>2 \n",
    "\\end{array}\\right.\\notag$\n",
    "\n",
    "Refs: <a href=\"https://stats.libretexts.org/Courses/Saint_Mary's_College_Notre_Dame/MATH_345__-_Probability_(Kuter)/4%3A_Continuous_Random_Variables/4.1%3A_Probability_Density_Functions_(PDFs)_and_Cumulative_Distribution_Functions_(CDFs)_for_Continuous_Random_Variables#Example_.5C(.5CPageIndex.7B1.7D.5C)\"> 1</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-neighborhood",
   "metadata": {},
   "source": [
    "## 3) Joint Probability Distribution\n",
    "\n",
    "Given random variables ${\\displaystyle X,Y,\\ldots }$, that are defined on a probability space, the joint probability distribution for ${\\displaystyle X,Y,\\ldots }$ is a probability distribution that gives the probability that each of ${\\displaystyle X,Y,\\ldots }$ falls in any particular range or discrete set of values specified for that variable.\n",
    "\n",
    "\n",
    "\n",
    "The joint probability mass function of two discrete random variables $X,Y$ is:\n",
    "\n",
    "${\\displaystyle p_{X,Y}(x,y)=\\mathrm {P} (X=x\\ \\mathrm {and} \\ Y=y)}$\n",
    "\n",
    "\n",
    "or written in terms of conditional distributions\n",
    "\n",
    "${\\displaystyle p_{X,Y}(x,y)=\\mathrm {P} (Y=y\\mid X=x)\\cdot \\mathrm {P} (X=x)=\\mathrm {P} (X=x\\mid Y=y)\\cdot \\mathrm {P} (Y=y)}$\n",
    "\n",
    "\n",
    "where ${\\displaystyle \\mathrm {P} (Y=y\\mid X=x)}\\mathrm {P} $ is the probability of ${\\displaystyle Y=y}$ given that ${\\displaystyle X=x}$.\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider the tossing of a fair die and let $A = 1$ if the number is even (i.e., 2, 4, or 6) and $A = 0$ otherwise. Furthermore, let $B = 1$ if the number is prime (i.e., 2, 3, or 5) and $B = 0$ otherwise.\n",
    "\n",
    "\n",
    "|   |1\t|2\t|3\t|4\t|5\t|6  |\n",
    "|---|---|---|---|---|---|---|\n",
    "|A\t|0\t|1\t|0\t|1\t|0\t|1  |\n",
    "|B\t|0\t|1\t|1\t|0\t|1\t|0  |\n",
    "\n",
    "Then, the joint distribution of $A$ and $B$, expressed as a probability mass function, is:\n",
    "\n",
    "$P(A=0,B=0)=P\\{1\\}=\\frac{1}{6}$\n",
    "\n",
    "$P(A=0,B=1)=P\\{3,5\\}=\\frac{2}{6}$\n",
    "\n",
    "$P(A=1,B=0)=P\\{4,6\\}=\\frac{2}{6}$\n",
    "\n",
    "$P(A=1,B=1)=P\\{2\\}=\\frac{1}{6}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-bedroom",
   "metadata": {},
   "source": [
    "### 3-1) Joint Probability Mass Function (joint pmf)\n",
    "\n",
    "If discrete random variables  $X$  and  $Y$  are defined on the same sample space  $S$ , then their joint probability mass function (joint pmf) is given by\n",
    "$p(x,y) = P(X=x\\ \\ \\text{and}\\ \\ Y=y),\\notag$\n",
    " \n",
    "\n",
    "where  $(x,y)$  is a pair of possible values for the pair of random variables  $(x,y)$ , and  $p(x,y)$  satisfies the following conditions:\n",
    "\n",
    "- $0 \\leq p(x,y) \\leq 1$ \n",
    "- $\\displaystyle{\\mathop{\\sum\\sum}_{(x,y)}p(x,y) = 1}$\n",
    "- $\\displaystyle{P\\left((X,Y)\\in A\\right)) = \\mathop{\\sum\\sum}_{(x,y)\\in A} p(x,y)}$\n",
    "\n",
    "\n",
    "Refs: [1](https://stats.libretexts.org/Courses/Saint_Mary's_College_Notre_Dame/MATH_345__-_Probability_(Kuter)/5%3A_Probability_Distributions_for_Combinations_of_Random_Variables/5.1%3A_Joint_Distributions_of_Discrete_Random_Variables#:~:text=Suppose%20that%20X%20and%20Y,p(x%2Cy).)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-singing",
   "metadata": {},
   "source": [
    "#### Example\n",
    "Consider example of tossing a coin three times, random variable $X$  denote the number of heads obtained, random variable  $Y$  denote the winnings earned in a single play,\n",
    "\n",
    "\n",
    "\n",
    "- $\\$1$ if first  $h$  occurs on the first toss $\\{hhh,htt,hht,hth\\}$\n",
    "- $\\$2$ if first $h$ occurs on the second toss $\\{thh,tht\\}$\n",
    "- $\\$3$ if first $h$ occurs on the third toss $\\{tth\\}$\n",
    "- $\\$-1$ if no $h$ occur $\\{ttt\\}$\n",
    "\n",
    "\n",
    "Note that the possible values of $X$ are  $x=0,1,2,3$ , and the possible values of  $Y$  are  $y=−1,1,2,3$ . \n",
    "\n",
    "The joint pmf table for our above exmple would be:\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>p(x,y)</th>\n",
    "            <th class=\"mt-align-center\" colspan=\"4\" rowspan=\"1\" scope=\"row\">\\(X\\)</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">\\(Y\\)</th>\n",
    "            <th class=\"mt-align-center\">0</th>\n",
    "            <th class=\"mt-align-center\">1</th>\n",
    "            <th class=\"mt-align-center\">2</th>\n",
    "            <th class=\"mt-align-center\">3</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">-1</th>\n",
    "            <td class=\"mt-align-center\"><span class=\"mt-color-2ecc71\">1/8</span></td>\n",
    "            <td class=\"mt-align-center\">0</td>\n",
    "            <td class=\"mt-align-center\">0</td>\n",
    "            <td class=\"mt-align-center\">0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">1</th>\n",
    "            <td class=\"mt-align-center\">0</td>\n",
    "            <td class=\"mt-align-center\"><span class=\"mt-color-e67e22\">1/8</span></td>\n",
    "            <td class=\"mt-align-center\"><span class=\"mt-color-3498db\">2/8</span></td>\n",
    "            <td class=\"mt-align-center\"><span class=\"mt-color-8e44ad\">1/8</span></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">2</th>\n",
    "            <td class=\"mt-align-center\">0</td>\n",
    "            <td class=\"mt-align-center\"><span class=\"mt-color-e67e22\">1/8</span></td>\n",
    "            <td class=\"mt-align-center\"><span class=\"mt-color-3498db\">1/8</span></td>\n",
    "            <td class=\"mt-align-center\">0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">3</th>\n",
    "            <td class=\"mt-align-center\">0</td>\n",
    "            <td class=\"mt-align-center\"><span class=\"mt-color-e67e22\">1/8</span></td>\n",
    "            <td class=\"mt-align-center\">0</td>\n",
    "            <td class=\"mt-align-center\">0</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "$S = \\{{ttt}, {htt}, {tht}, {tth}, {hht}, {hth}, {thh}, {hhh}\\}\\notag$\n",
    "\n",
    "$p(0,-1) = P(X=0\\ \\text{and}\\ Y=-1) = P(ttt) = \\frac{1}{8}.\\notag$\n",
    "\n",
    "\n",
    "$p(1,1) = P(X=1\\ \\text{and}\\ Y=1) = P(htt) = \\frac{1}{8}.\\notag$\n",
    "\n",
    "\n",
    "$p(2,1) = P(X=2\\ \\text{and}\\ Y=1) = P(\\text{tht or thh} ) = \\frac{2}{8}.\\notag$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-routine",
   "metadata": {},
   "source": [
    "### 3-2) Joint Cumulative Distribution function (joint cdf)\n",
    "In the discrete case, we can obtain the joint cumulative distribution function (joint cdf) of  $X$  and  $Y$  by summing the joint pmf:\n",
    "\n",
    "$F(x,y) = P(X\\leq x\\ \\text{and}\\ Y\\leq y) = \\sum_{x_i \\leq x} \\sum_{y_j \\leq y} p(x_i, y_j)\\notag$\n",
    "\n",
    "#### Example\n",
    "\n",
    "The joint cdf table for our above exmple would be:\n",
    "\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">F(x,y)</th>\n",
    "            <th class=\"mt-align-center\" colspan=\"4\" rowspan=\"1\" scope=\"col\">\\(X\\)</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">Y</th>\n",
    "            <th class=\"mt-align-center\">0</th>\n",
    "            <th class=\"mt-align-center\">1</th>\n",
    "            <th class=\"mt-align-center\">2</th>\n",
    "            <th class=\"mt-align-center\">3</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">-1</th>\n",
    "            <td class=\"mt-align-center\">1/8</td>\n",
    "            <td class=\"mt-align-center\">1/8</td>\n",
    "            <td class=\"mt-align-center\">1/8</td>\n",
    "            <td class=\"mt-align-center\">1/8</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">1</th>\n",
    "            <td class=\"mt-align-center\">1/8</td>\n",
    "            <td class=\"mt-align-center\">1/4</td>\n",
    "            <td class=\"mt-align-center\">1/2</td>\n",
    "            <td class=\"mt-align-center\">5/8</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">2</th>\n",
    "            <td class=\"mt-align-center\">1/8</td>\n",
    "            <td class=\"mt-align-center\">3/8</td>\n",
    "            <td class=\"mt-align-center\">3/4</td>\n",
    "            <td class=\"mt-align-center\">7/8</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th class=\"mt-align-center\" scope=\"row\">3</th>\n",
    "            <td class=\"mt-align-center\">1/8</td>\n",
    "            <td class=\"mt-align-center\">1/2</td>\n",
    "            <td class=\"mt-align-center\">7/8</td>\n",
    "            <td class=\"mt-align-center\">1</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "$F(1,1) = P(X\\leq1\\ \\text{and}\\ Y\\leq1) = \\sum_{x\\leq1}\\sum_{y\\leq1} p(x,y) = p(0,-1) + p(0,1) + p(-1,1) + p(1,1) = \\frac{1}{4}\\notag$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-savage",
   "metadata": {},
   "source": [
    "### Semicolon notation in joint probability\n",
    "\n",
    "In $p_{\\theta} (x|z, y) = f(x; z, y, \\theta)$, \n",
    "\n",
    "$f(x; z, y, \\theta)$\n",
    "\n",
    "is a function of $x$ with \"parameters\" $y,x,\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-seattle",
   "metadata": {},
   "source": [
    "## 4) Marginal Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-embassy",
   "metadata": {},
   "source": [
    "### 4-1-1) Marginal probability mass functions (Marginal pmf)\n",
    "\n",
    "\n",
    "Suppose that discrete random variables  $X$  and  $Y$  have joint pmf  $p(x,y)$. Let  $y_1, y_2, \\ldots, y_j, \\ldots$  denote the possible values of  $Y$ , and let  $x_1, x_2, \\ldots, x_i, \\ldots$  denote the possible values of  $X$ . The marginal probability mass functions (marginal pmf's) of  $X$  and  $Y$  are respectively given by the following:\n",
    "\n",
    "\n",
    "$\\begin{align*} \n",
    "p_X(x) &= \\sum_j p(x, y_j) \\quad(\\text{fix a value of}\\ X\\ \\text{and sum over possible values of}\\ Y) \\\\ \n",
    "p_Y(y) &= \\sum_i p(x_i, y) \\quad(\\text{fix a value of}\\ Y\\ \\text{and sum over possible values of}\\ X) \n",
    "\\end{align*}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-myrtle",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th  scope=\"col\">x</th>\n",
    "            <th  scope=\"col\">pₓ(x)</th>\n",
    "            <th  scope=\"col\">y</th>\n",
    "            <th  scope=\"col\">pᵧ(y)</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td >0</td>\n",
    "            <td >1/8</td>\n",
    "            <td >-1</td>\n",
    "            <td >1/8</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td >1</td>\n",
    "            <td >3/8</td>\n",
    "            <td >1</td>\n",
    "            <td >1/2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td >2</td>\n",
    "            <td >3/8</td>\n",
    "            <td >2</td>\n",
    "            <td >1/4</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td >3</td>\n",
    "            <td >1/8</td>\n",
    "            <td >3</td>\n",
    "            <td >1/8</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "According to the joint **pmf** table for our above exmple, we would have:\n",
    "\n",
    "$p_X(0) = \\sum_j p(X=0,y_j)= p(X=0,Y=-1)+p(X=0,Y=1)+p(X=0,Y=2)+p(X=0,Y=3) = \\frac{1}{8}+0+0+0.\\notag$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-partner",
   "metadata": {},
   "source": [
    "### 4-1-2) Marginal probability density functions (Marginal pdf)\n",
    "\n",
    "\n",
    "The marginal probability density functions of the continuous random variables $X$ and $Y$ are given, respectively, by:\n",
    "\n",
    "$f_X(x)=\\int_{-\\infty}^\\infty f(x,y)dy,\\qquad x\\in S_1$\n",
    "\n",
    "$f_Y(y)=\\int_{-\\infty}^\\infty f(x,y)dx,\\qquad y\\in S_2$\n",
    "\n",
    "#### Example\n",
    "Let $X$ and $Y$ have joint probability density function:\n",
    "\n",
    "\n",
    "$f(x,y) = \\left\\{\\begin{array}{l l} \n",
    "4xy &  0<x<1 , 0<y<1 \\\\ \n",
    "0 & \\text{otherwise}. \n",
    "\\end{array}\\right.\\notag$\n",
    "\n",
    "\n",
    "$f_X(x)=\\int_0^1 4xy dy=4x\\left[\\dfrac{y^2}{2}\\right]_{y=0}^{y=1}=2x, \\qquad 0<x<1$\n",
    "\n",
    "$f_Y(y)=\\int_0^1 4xy dx=4y\\left[\\dfrac{x^2}{2}\\right]_{x=0}^{x=1}=2y, \\qquad 0<y<1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-hamburg",
   "metadata": {},
   "source": [
    "### 4-2) Marginal cumulative distribution functio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-excuse",
   "metadata": {},
   "source": [
    "### 4-3) Marginal distribution vs. conditional distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-palace",
   "metadata": {},
   "source": [
    "### 4-4) Marginal Probability  and Expected Value\n",
    "\n",
    "A marginal probability can always be written as an expected value:\n",
    "\n",
    "${\\displaystyle p_{X}(x)=\\int _{y}p_{X\\mid Y}(x\\mid y)\\,p_{Y}(y)\\,\\mathrm {d} y=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)]\\;.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-virtue",
   "metadata": {},
   "source": [
    "### 4-5) Marginal likelihood\n",
    "\n",
    "A marginal likelihood function (integrated likelihood), is a likelihood function in which some parameter variables have been marginalized. \n",
    "\n",
    "#### In the context of Bayesian statistics\n",
    "Given a set of independent identically distributed data points ${\\displaystyle \\mathbf {X} =(x_{1},\\ldots ,x_{n}),}$, where $x_{i}\\sim p(x_{i}|\\theta )$ according to some probability distribution parameterized by $\\theta$ , where $\\theta$  itself is a random variable described by a distribution, i.e. ${\\displaystyle \\theta \\sim p(\\theta \\mid \\alpha ),}$ the marginal likelihood in general asks what the probability ${\\displaystyle p(\\mathbf {X} \\mid \\alpha )}$ is, where $\\theta$  has been marginalized out (integrated out): \n",
    "\n",
    "\n",
    "${\\displaystyle p(\\mathbf {X} \\mid \\alpha )=\\int _{\\theta }p(\\mathbf {X} \\mid \\theta )\\,p(\\theta \\mid \\alpha )\\ \\operatorname {d} \\!\\theta }$\n",
    "\n",
    "####  In classical statistics\n",
    "In In classical statistics, the concept of marginal likelihood occurs instead in the context of a joint parameter ${\\displaystyle \\theta =(\\psi ,\\lambda )}$, where $\\psi$  is the actual parameter of interest, and $\\lambda$  is a non-interesting nuisance parameter.\n",
    "\n",
    "\n",
    "We know that:\n",
    "\n",
    "$P(B|C)=\\sum_{i} P(B|A_i,C)P(A_i|C) $\n",
    "\n",
    "And we also know \n",
    "\n",
    "${\\mathcal {L}}(\\theta|X)=p(X|\\theta)=p_{\\theta }(X)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "by marginalizing out $\\lambda$ :\n",
    "\n",
    "${\\displaystyle {\\mathcal {L}}(\\psi ;\\mathbf {X} )=p(\\mathbf {X} \\mid \\psi )=\\int _{\\lambda }p(\\mathbf {X} \\mid \\lambda ,\\psi )\\,p(\\lambda \\mid \\psi )\\ \\operatorname {d} \\!\\lambda }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-microwave",
   "metadata": {},
   "source": [
    "## Marginalization of conditional probability\n",
    "\n",
    "$P(E=e|A=a)=\\frac{P(E=e,A=a)}{P(A=a)}=\\frac{\\sum_{c}P(E=e,C=c,A=a)}{P(A=a)}$\n",
    "using the definition of conditional probability, this is equal to:\n",
    "$\\sum_{c}P(E=e,C=c|A=a)$\n",
    "\n",
    "Refs: [1](https://stats.stackexchange.com/questions/256271/marginalization-of-conditional-probability)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
