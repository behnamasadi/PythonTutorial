{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83131a85-c74c-43d0-ab42-8a4d892bd92e",
   "metadata": {},
   "source": [
    "## Expected Value\n",
    "\n",
    "The expected value (EV) is a fundamental concept in probability and statistics that represents the long-term average or mean value of a random variable over many trials or observations. It is essentially a weighted average, where each possible outcome of the random variable is weighted by its probability of occurring.\n",
    "\n",
    "For a discrete random variable $X$ with possible values $x_1, x_2, \\ldots, x_n$ and corresponding probabilities $P(X = x_1), P(X = x_2), \\ldots, P(X = x_n)$, the expected value $E(X)$ is given by:\n",
    "\n",
    "$ E(X) = \\sum_{i=1}^{n} x_i P(X = x_i) $\n",
    "\n",
    "For a continuous random variable $X$ with probability density function $f(x)$, the expected value $E(X)$ is given by:\n",
    "\n",
    "$ E(X) = \\int_{-\\infty}^{\\infty} x f(x) \\, dx $\n",
    "\n",
    "### Important Properties of Expected Value\n",
    "\n",
    "1. **Linearity of Expectation:**\n",
    "   The expected value operator is linear, meaning that for any random variables $X$ and $Y$, and any constants $a$ and $b$:\n",
    "\n",
    "   $ E(aX + bY) = aE(X) + bE(Y) $\n",
    "\n",
    "   This property also extends to the sum of multiple random variables:\n",
    "\n",
    "   $ E\\left(\\sum_{i=1}^{n} a_i X_i\\right) = \\sum_{i=1}^{n} a_i E(X_i) $\n",
    "\n",
    "2. **Expectation of a Constant:**\n",
    "   If $c$ is a constant, then the expected value of $c$ is just $c$:\n",
    "\n",
    "   $ E(c) = c $\n",
    "\n",
    "3. **Expected Value of the Sum of Random Variables:**\n",
    "   For any random variables $X$ and $Y$:\n",
    "\n",
    "   $ E(X + Y) = E(X) + E(Y) $\n",
    "\n",
    "   This holds true whether $X$ and $Y$ are independent or not.\n",
    "\n",
    "4. **Expected Value of a Product of Independent Random Variables:**\n",
    "   If $X$ and $Y$ are independent random variables, then:\n",
    "\n",
    "   $ E(XY) = E(X) \\cdot E(Y) $\n",
    "\n",
    "5. **Non-Negativity:**\n",
    "   If $X$ is a non-negative random variable (i.e., $X \\geq 0$ always), then:\n",
    "\n",
    "   $ E(X) \\geq 0 $\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "Consider a discrete random variable $X$ that can take values 1, 2, and 3 with probabilities 0.2, 0.5, and 0.3, respectively. The expected value $E(X)$ can be calculated as follows:\n",
    "\n",
    "$ E(X) = 1 \\cdot 0.2 + 2 \\cdot 0.5 + 3 \\cdot 0.3 $\n",
    "$ E(X) = 0.2 + 1 + 0.9 $\n",
    "$ E(X) = 2.1 $\n",
    "\n",
    "So, the expected value $E(X)$ is 2.1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96773d-a9a0-4e07-ad5b-00138293b3dc",
   "metadata": {},
   "source": [
    "Variance is a statistical measure that describes the spread or dispersion of a set of data points. It quantifies how much the values in a dataset deviate from the mean (average) of the dataset. A higher variance indicates that the data points are more spread out from the mean, while a lower variance indicates that they are closer to the mean.\n",
    "\n",
    "### Population Variance\n",
    "\n",
    "The variance of a population (denoted as $\\sigma^2$) is calculated using the following steps:\n",
    "\n",
    "1. Find the mean (average) of the population.\n",
    "2. Subtract the mean from each data point to find the deviation of each data point from the mean.\n",
    "3. Square each deviation to eliminate negative values.\n",
    "4. Find the average of these squared deviations.\n",
    "\n",
    "The formula for the population variance is:\n",
    "\n",
    "$ \\sigma^2 = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\mu)^2 $\n",
    "\n",
    "Where:\n",
    "- $ \\sigma^2 $ is the population variance.\n",
    "- $ N $ is the number of data points in the population.\n",
    "- $ x_i $ represents each individual data point.\n",
    "- $ \\mu $ is the mean of the population.\n",
    "- $\\sum$ denotes the summation.\n",
    "\n",
    "### Sample Variance\n",
    "\n",
    "The variance of a sample (denoted as $s^2$) is similar to the population variance but with a slight adjustment. Since a sample is a subset of the population, we divide by $n-1$ (where $n$ is the sample size) instead of $N$ to correct for the bias in the estimation of the population variance.\n",
    "\n",
    "The formula for the sample variance is:\n",
    "\n",
    "$ s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 $\n",
    "\n",
    "Where:\n",
    "- $ s^2 $ is the sample variance.\n",
    "- $ n $ is the number of data points in the sample.\n",
    "- $ x_i $ represents each individual data point.\n",
    "- $ \\bar{x} $ is the mean of the sample.\n",
    "- $\\sum$ denotes the summation.\n",
    "\n",
    "### Steps to Calculate Variance\n",
    "\n",
    "1. **Calculate the Mean:**\n",
    "   - For a population: $ \\mu = \\frac{1}{N} \\sum_{i=1}^{N} x_i $\n",
    "   - For a sample: $ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $\n",
    "\n",
    "2. **Find Deviations from the Mean:**\n",
    "   - Subtract the mean from each data point: $ x_i - \\mu $ (for population) or $ x_i - \\bar{x} $ (for sample).\n",
    "\n",
    "3. **Square Each Deviation:**\n",
    "   - Square each deviation to get rid of negative values.\n",
    "\n",
    "4. **Calculate the Average of Squared Deviations:**\n",
    "   - For a population: $ \\sigma^2 = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\mu)^2 $\n",
    "   - For a sample: $ s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 $\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "Suppose we have the following sample data points: 4, 8, 6, 5, 3.\n",
    "\n",
    "1. **Calculate the Sample Mean:**\n",
    "\n",
    "$ \\bar{x} = \\frac{4 + 8 + 6 + 5 + 3}{5} = \\frac{26}{5} = 5.2 $\n",
    "\n",
    "2. **Find Deviations from the Mean:**\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "4 - 5.2 &= -1.2 \\\\\n",
    "8 - 5.2 &= 2.8 \\\\\n",
    "6 - 5.2 &= 0.8 \\\\\n",
    "5 - 5.2 &= -0.2 \\\\\n",
    "3 - 5.2 &= -2.2 \\\\\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "3. **Square Each Deviation:**\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "(-1.2)^2 &= 1.44 \\\\\n",
    "(2.8)^2 &= 7.84 \\\\\n",
    "(0.8)^2 &= 0.64 \\\\\n",
    "(-0.2)^2 &= 0.04 \\\\\n",
    "(-2.2)^2 &= 4.84 \\\\\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "4. **Calculate the Average of Squared Deviations (Sample Variance):**\n",
    "\n",
    "$ s^2 = \\frac{1}{5-1} \\sum_{i=1}^{5} (x_i - \\bar{x})^2 = \\frac{1}{4} (1.44 + 7.84 + 0.64 + 0.04 + 4.84) = \\frac{1}{4} \\times 14.8 = 3.7 $\n",
    "\n",
    "So, the sample variance $s^2$ is 3.7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-ethnic",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "Covariance is a measure of the joint variability of two random variables\n",
    "\n",
    "${\\displaystyle {\\begin{aligned}\\operatorname {cov} (X,Y)&=\\operatorname {E} \\left[\\left(X-\\operatorname {E} \\left[X\\right]\\right)\\left(Y-\\operatorname {E} \\left[Y\\right]\\right)\\right]\\\\&=\\operatorname {E} \\left[XY-X\\operatorname {E} \\left[Y\\right]-\\operatorname {E} \\left[X\\right]Y+\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right]\\right]\\\\&=\\operatorname {E} \\left[XY\\right]-\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right]-\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right]+\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right]\\\\&=\\operatorname {E} \\left[XY\\right]-\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right],\\end{aligned}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-feelings",
   "metadata": {},
   "source": [
    "### Example: \n",
    "We have 5 observation from a 3-dimensional variable (assuming each row represents a different variable and each column a different observation):\n",
    "\n",
    "|    |     |     |     |    |\n",
    "|--- |---  |---  |---  |--- |\n",
    "|4.  |4.2  |3.9  |4.3  |4.1 | \n",
    "|2.  |2.1  |2.   |2.1  |2.2 |\n",
    "|0.6 |0.59 |0.58 |0.62 |0.63|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-force",
   "metadata": {},
   "source": [
    "## Covariance matrix\n",
    "is a square matrix giving the covariance between each pair of elements of a given random vector. Any covariance matrix is symmetric and positive semi-definite \n",
    "\n",
    "For the column vector $\\mathbf {X}$\n",
    "\n",
    "$\\displaystyle \\mathbf {X} =(X_{1},X_{2},...,X_{n})^{\\mathrm {T} }$\n",
    "\n",
    "${\\displaystyle \\operatorname {K} _{\\mathbf {X} \\mathbf {X} }=\\operatorname {cov} [\\mathbf {X} ,\\mathbf {X} ]=\\operatorname {E} [(\\mathbf {X} -\\mathbf {\\mu _{X}} )(\\mathbf {X} -\\mathbf {\\mu _{X}} )^{\\rm {T}}]=\\operatorname {E} [\\mathbf {X} \\mathbf {X} ^{T}]-\\mathbf {\\mu _{X}} \\mathbf {\\mu _{X}} ^{T}}{\\displaystyle \\operatorname {K} _{\\mathbf {X} \\mathbf {X} }=\\operatorname {cov} [\\mathbf {X} ,\\mathbf {X} ]=\\operatorname {E} [(\\mathbf {X} -\\mathbf {\\mu _{X}} )(\\mathbf {X} -\\mathbf {\\mu _{X}} )^{\\rm {T}}]=\\operatorname {E} [\\mathbf {X} \\mathbf {X} ^{T}]-\\mathbf {\\mu _{X}} \\mathbf {\\mu _{X}} ^{T}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3b184-74cc-4d84-982c-e8b30fc562e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "- Variable 1: $X_1 = [4.0, 4.2, 3.9, 4.3, 4.1] $\n",
    "- Variable 2: $X_2 = [2.0, 2.1, 2.0, 2.1, 2.2] $\n",
    "- Variable 3: $X_3 = [0.6, 0.59, 0.58, 0.62, 0.63] $\n",
    "\n",
    "Calculate the Mean of Each Variable\n",
    "\n",
    "1. **Mean of $X_1 $**:\n",
    "$ \\bar{X}_1 = \\frac{4.0 + 4.2 + 3.9 + 4.3 + 4.1}{5} $\n",
    "\n",
    "2. **Mean of $X_2 $**:\n",
    "$ \\bar{X}_2 = \\frac{2.0 + 2.1 + 2.0 + 2.1 + 2.2}{5} $\n",
    "\n",
    "3. **Mean of $X_3 $**:\n",
    "$ \\bar{X}_3 = \\frac{0.6 + 0.59 + 0.58 + 0.62 + 0.63}{5} $\n",
    "\n",
    "\n",
    "#### Means of Each Variable\n",
    "- Mean of $X_1 $: $\\bar{X}_1 = 4.1 $\n",
    "- Mean of $X_2 $: $\\bar{X}_2 = 2.08 $\n",
    "- Mean of $X_3 $: $\\bar{X}_3 = 0.604 $\n",
    "\n",
    "\n",
    " Calculate the Covariances\n",
    "\n",
    "The covariance between two variables $X_i $ and $X_j $ is given by:\n",
    "$ \\text{Cov}(X_i, X_j) = \\frac{1}{n-1} \\sum_{k=1}^n (X_{ik} - \\bar{X}_i)(X_{jk} - \\bar{X}_j) $\n",
    "where $n $ is the number of observations (5 in this case), and $X_{ik} $ is the $k $-th observation of the $i $-th variable.\n",
    "\n",
    "- **Covariance $\\text{Cov}(X_1, X_1) $ (Variance of $X_1 $)**:\n",
    "$ \\text{Cov}(X_1, X_1) = \\frac{1}{4} \\left( (4.0 - \\bar{X}_1)^2 + (4.2 - \\bar{X}_1)^2 + (3.9 - \\bar{X}_1)^2 + (4.3 - \\bar{X}_1)^2 + (4.1 - \\bar{X}_1)^2 \\right) $\n",
    "\n",
    "- **Covariance $\\text{Cov}(X_1, X_2) $**:\n",
    "$ \\text{Cov}(X_1, X_2) = \\frac{1}{4} \\left( (4.0 - \\bar{X}_1)(2.0 - \\bar{X}_2) + (4.2 - \\bar{X}_1)(2.1 - \\bar{X}_2) + \\dots \\right) $\n",
    "\n",
    "And similarly for $\\text{Cov}(X_1, X_3) $, $\\text{Cov}(X_2, X_2) $, $\\text{Cov}(X_2, X_3) $, and $\\text{Cov}(X_3, X_3) $.\n",
    "\n",
    "\n",
    "\n",
    "#### Covariance Matrix\n",
    "The covariance matrix for the given data is:\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "0.025 & 0.0075 & 0.00175 \\\\\n",
    "0.0075 & 0.007 & 0.00135 \\\\\n",
    "0.00175 & 0.00135 & 0.00043\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "### Interpretation\n",
    "Each entry $\\text{Cov}(X_i, X_j) $ in the matrix represents the covariance between variables $X_i $ and $X_j $. The diagonal entries represent the variances of each variable:\n",
    "- $\\text{Cov}(X_1, X_1) = 0.025 $ (Variance of $X_1 $)\n",
    "- $\\text{Cov}(X_2, X_2) = 0.007 $ (Variance of $X_2 $)\n",
    "- $\\text{Cov}(X_3, X_3) = 0.00043 $ (Variance of $X_3 $)\n",
    "\n",
    "### Detailed Equations\n",
    "\n",
    "1. **Covariance $\\text{Cov}(X_1, X_1) $**:\n",
    "$\n",
    "\\text{Cov}(X_1, X_1) = \\frac{1}{4} \\left( (4.0 - 4.1)^2 + (4.2 - 4.1)^2 + (3.9 - 4.1)^2 + (4.3 - 4.1)^2 + (4.1 - 4.1)^2 \\right) = 0.025\n",
    "$\n",
    "\n",
    "2. **Covariance $\\text{Cov}(X_1, X_2) $**:\n",
    "$\n",
    "\\text{Cov}(X_1, X_2) = \\frac{1}{4} \\left( (4.0 - 4.1)(2.0 - 2.08) + (4.2 - 4.1)(2.1 - 2.08) + \\dots \\right) = 0.0075\n",
    "$\n",
    "\n",
    "3. **Covariance $\\text{Cov}(X_1, X_3) $**:\n",
    "$\n",
    "\\text{Cov}(X_1, X_3) = \\frac{1}{4} \\left( (4.0 - 4.1)(0.6 - 0.604) + (4.2 - 4.1)(0.59 - 0.604) + \\dots \\right) = 0.00175\n",
    "$\n",
    "\n",
    "4. **Covariance $\\text{Cov}(X_2, X_3) $**:\n",
    "$\n",
    "\\text{Cov}(X_2, X_3) = \\frac{1}{4} \\left( (2.0 - 2.08)(0.6 - 0.604) + (2.1 - 2.08)(0.59 - 0.604) + \\dots \\right) = 0.00135\n",
    "$\n",
    "\n",
    "5. **Variance $\\text{Cov}(X_3, X_3) $**:\n",
    "$\n",
    "\\text{Cov}(X_3, X_3) = \\frac{1}{4} \\left( (0.6 - 0.604)^2 + (0.59 - 0.604)^2 + \\dots \\right) = 0.00043\n",
    "$\n",
    "\n",
    "These calculations demonstrate the relationships between the three variables in terms of their linear dependence and variability with respect to each other. The positive values indicate a positive linear relationship between the paired variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04faf3df",
   "metadata": {},
   "source": [
    "\n",
    "$\\mu=\\boldsymbol{\\bar{X}}=\\left [ 4.10, 2.08, 0.604 \\right ]$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512dee77-9aff-4089-bd30-54198d81c88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.1  , 2.08 , 0.604]),\n",
       " array([[0.025  , 0.0075 , 0.00175],\n",
       "        [0.0075 , 0.007  , 0.00135],\n",
       "        [0.00175, 0.00135, 0.00043]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "X = np.array([\n",
    "    [4.0, 4.2, 3.9, 4.3, 4.1],\n",
    "    [2.0, 2.1, 2.0, 2.1, 2.2],\n",
    "    [0.6, 0.59, 0.58, 0.62, 0.63]\n",
    "])\n",
    "\n",
    "# Step 1: Calculate the mean of each variable\n",
    "means = np.mean(X, axis=1)\n",
    "\n",
    "# Step 2: Calculate the covariance matrix\n",
    "n = X.shape[1]\n",
    "covariance_matrix = np.cov(X, bias=False)  # using default normalization by (n-1)\n",
    "\n",
    "means, covariance_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34963b7-e86a-4432-aa0c-73eae19d30bd",
   "metadata": {},
   "source": [
    "To express the covariance matrix in the form $[X - \\mu_X][X - \\mu_X]^T$ involves a matrix calculation where $X$ is the matrix of observations and $\\mu_X$ is the matrix of mean values repeated for each observation.\n",
    "\n",
    "### Given Data and Definitions\n",
    "\n",
    "- $X$ (Data matrix where each row is a variable, and each column is an observation):\n",
    "  $\n",
    "  X = \\begin{bmatrix}\n",
    "  4.0 & 4.2 & 3.9 & 4.3 & 4.1 \\\\\n",
    "  2.0 & 2.1 & 2.0 & 2.1 & 2.2 \\\\\n",
    "  0.6 & 0.59 & 0.58 & 0.62 & 0.63\n",
    "  \\end{bmatrix}\n",
    "  $\n",
    "\n",
    "- $\\mu_X$ (Mean vector, each mean repeated across corresponding rows):\n",
    "  $\n",
    "  \\mu_X = \\begin{bmatrix}\n",
    "  4.1 & 4.1 & 4.1 & 4.1 & 4.1 \\\\\n",
    "  2.08 & 2.08 & 2.08 & 2.08 & 2.08 \\\\\n",
    "  0.604 & 0.604 & 0.604 & 0.604 & 0.604\n",
    "  \\end{bmatrix}\n",
    "  $\n",
    "\n",
    "### Calculation\n",
    "\n",
    "1. **Center the data matrix $X$ by subtracting $\\mu_X$:**\n",
    "   $\n",
    "   X - \\mu_X = \\begin{bmatrix}\n",
    "   4.0 - 4.1 & 4.2 - 4.1 & 3.9 - 4.1 & 4.3 - 4.1 & 4.1 - 4.1 \\\\\n",
    "   2.0 - 2.08 & 2.1 - 2.08 & 2.0 - 2.08 & 2.1 - 2.08 & 2.2 - 2.08 \\\\\n",
    "   0.6 - 0.604 & 0.59 - 0.604 & 0.58 - 0.604 & 0.62 - 0.604 & 0.63 - 0.604\n",
    "   \\end{bmatrix}\n",
    "   $\n",
    "\n",
    "2. **Compute the product $[X - \\mu_X][X - \\mu_X]^T$:**\n",
    "   $\n",
    "   [X - \\mu_X][X - \\mu_X]^T = \\frac{1}{4} (X - \\mu_X)(X - \\mu_X)^T\n",
    "   $\n",
    "   The factor of $\\frac{1}{4}$ is used because the standard formula for covariance uses $n-1$ (with $n$ being the number of observations) as the denominator to get an unbiased estimate.\n",
    "\n",
    "Let's calculate this matrix product to verify that it yields the covariance matrix:\n",
    "\n",
    "### Centered Data Matrix $(X - \\mu_X)$\n",
    "\n",
    "The matrix $X - \\mu_X$ where each entry is the deviation of each observation from the mean is given by:\n",
    "$\n",
    "X - \\mu_X = \\begin{bmatrix}\n",
    "-0.1 & 0.1 & -0.2 & 0.2 & 0.0 \\\\\n",
    "-0.08 & 0.02 & -0.08 & 0.02 & 0.12 \\\\\n",
    "-0.004 & -0.014 & -0.024 & 0.016 & 0.026\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "### Covariance Matrix Calculation $[X - \\mu_X][X - \\mu_X]^T$\n",
    "\n",
    "The covariance matrix calculated using the formula $\\frac{1}{n-1} (X - \\mu_X)(X - \\mu_X)^T$ matches the previous calculation:\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "0.025 & 0.0075 & 0.00175 \\\\\n",
    "0.0075 & 0.007 & 0.00135 \\\\\n",
    "0.00175 & 0.00135 & 0.00043\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "This matrix is exactly the covariance matrix we obtained earlier, verifying that both approaches are consistent. The diagonal entries represent the variances of each variable, and the off-diagonal entries represent the covariances between different variables.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "Each element $ \\text{Cov}(X_i, X_j) $ of the covariance matrix represents the covariance between variables $ X_i $ and $ X_j $. The covariance provides insights into how much the variables change together. A positive covariance indicates that the variables tend to move in the same direction, whereas a negative covariance suggests they move in opposite directions.\n",
    "\n",
    "- The diagonal entries (variances) tell how spread out the data is around the mean for each variable.\n",
    "- The off-diagonal entries (covariances) tell how much two variables change together, providing a sense of their linear relationship. \n",
    "\n",
    "This matrix is key in many statistical analyses, including principal component analysis (PCA) and multivariate analysis of variance (MANOVA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-subscriber",
   "metadata": {},
   "source": [
    "## Covariance Properties\n",
    "1) For any constant (i.e. non-random) $m\\times n $ matrix $\\mathbf {A} $ and constant $m\\times 1$ vector $\\mathbf {a}$ one has ${\\displaystyle \\operatorname {var} (\\mathbf {AX} +\\mathbf {a} )=\\mathbf {A} \\,\\operatorname {var} (\\mathbf {X} )\\,\\mathbf {A} ^{\\rm {T}}}$\n",
    "\n",
    "2) If $\\mathbf {Y}$  is another random vector with the same dimension  as $\\mathbf {X}$  then ${\\displaystyle \\operatorname {var} (\\mathbf {X} +\\mathbf {Y} )=\\operatorname {var} (\\mathbf {X} )+\\operatorname {cov} (\\mathbf {X} ,\\mathbf {Y} )+\\operatorname {cov} (\\mathbf {Y} ,\\mathbf {X} )+\\operatorname {var} (\\mathbf {Y} )}{\\displaystyle \\operatorname {var} (\\mathbf {X} +\\mathbf {Y} )=\\operatorname {var} (\\mathbf {X} )+\\operatorname {cov} (\\mathbf {X} ,\\mathbf {Y} )+\\operatorname {cov} (\\mathbf {Y} ,\\mathbf {X} )+\\operatorname {var} (\\mathbf {Y} )} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-point",
   "metadata": {},
   "source": [
    "## Inverse of the covariance matrix\n",
    "The inverse of this matrix, ${\\displaystyle \\operatorname {K} _{\\mathbf {X} \\mathbf {X} }^{-1}}$, if it exists, is the inverse covariance matrix, also known as the concentration matrix or precision matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-award",
   "metadata": {},
   "source": [
    "## Cross-covariance matrix\n",
    "${\\displaystyle \\operatorname {K} _{\\mathbf {X} \\mathbf {Y} }=\\operatorname {cov} (\\mathbf {X} ,\\mathbf {Y} ){\\stackrel {\\mathrm {def} }{=}}\\ \\operatorname {E} [(\\mathbf {X} -\\mathbf {\\mu _{X}} )(\\mathbf {Y} -\\mathbf {\\mu _{Y}} )^{\\rm {T}}]}$\t\n",
    " \n",
    "\n",
    "\n",
    "${\\displaystyle \\operatorname {K} _{\\mathbf {X} \\mathbf {Y} }={\\begin{bmatrix}\\mathrm {E} [(X_{1}-\\operatorname {E} [X_{1}])(Y_{1}-\\operatorname {E} [Y_{1}])]&\\mathrm {E} [(X_{1}-\\operatorname {E} [X_{1}])(Y_{2}-\\operatorname {E} [Y_{2}])]&\\cdots &\\mathrm {E} [(X_{1}-\\operatorname {E} [X_{1}])(Y_{n}-\\operatorname {E} [Y_{n}])]\\\\\\\\\\mathrm {E} [(X_{2}-\\operatorname {E} [X_{2}])(Y_{1}-\\operatorname {E} [Y_{1}])]&\\mathrm {E} [(X_{2}-\\operatorname {E} [X_{2}])(Y_{2}-\\operatorname {E} [Y_{2}])]&\\cdots &\\mathrm {E} [(X_{2}-\\operatorname {E} [X_{2}])(Y_{n}-\\operatorname {E} [Y_{n}])]\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\\\mathrm {E} [(X_{m}-\\operatorname {E} [X_{m}])(Y_{1}-\\operatorname {E} [Y_{1}])]&\\mathrm {E} [(X_{m}-\\operatorname {E} [X_{m}])(Y_{2}-\\operatorname {E} [Y_{2}])]&\\cdots &\\mathrm {E} [(X_{m}-\\operatorname {E} [X_{m}])(Y_{n}-\\operatorname {E} [Y_{n}])]\\end{bmatrix}}}$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc027d03-99e7-4af0-8aa0-7460bb3cd06d",
   "metadata": {},
   "source": [
    "## Biased sample covarianceand unbiased\n",
    "\n",
    "\n",
    "Biased sample covariance has $\\frac{1}{N}$ whereas the unbiased version has $\\frac{1}{N-1}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
