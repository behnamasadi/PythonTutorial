{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "complimentary-blast",
   "metadata": {},
   "source": [
    "## Expected Value\n",
    "Denoted ${\\displaystyle E(X)}$ or ${\\displaystyle E[X]}$  is a generalization of the weighted average, also known as the expectation, mathematical expectation, mean, average, or first moment.\n",
    "\n",
    "Let ${\\displaystyle X}$ be a random variable with a finite number of finite outcomes ${\\displaystyle x_{1},x_{2},\\ldots ,x_{k}}$ occurring with probabilities ${\\displaystyle p_{1},p_{2},\\ldots ,p_{k},}$ respectively. The expectation of ${\\displaystyle X}$ is defined as:\n",
    "\n",
    "${\\displaystyle \\operatorname {E} [X]=\\sum _{i=1}^{k}x_{i}\\,p_{i}=x_{1}p_{1}+x_{2}p_{2}+\\cdots +x_{k}p_{k}.}$\n",
    "\n",
    "\n",
    "If ${\\displaystyle X}$ is a random variable with a probability density function of ${\\displaystyle f(x)}$, then the expected value is defined as the Lebesgue integral\n",
    "\n",
    "${\\displaystyle \\operatorname {E} [X]=\\int _{\\mathbb {R} }xf(x)\\,dx,}$\n",
    "\n",
    "## Expected Value Properties\n",
    "\n",
    "${\\displaystyle {\\begin{aligned}\\operatorname {E} [X+Y]&=\\operatorname {E} [X]+\\operatorname {E} [Y]\\end{aligned}}}$\n",
    "\n",
    "$\\operatorname {E}[aX]=a\\operatorname {E}[X]$\n",
    "\n",
    "If ${\\displaystyle X\\leq Y}$ , and both ${\\displaystyle \\operatorname {E} [X]}$ and ${\\displaystyle \\operatorname {E} [Y]}$ exist, then ${\\displaystyle \\operatorname {E} [X]\\leq \\operatorname {E} [Y]}$\n",
    "\n",
    "\n",
    "In general, the expected value is not multiplicative, i.e. ${\\displaystyle \\operatorname {E} [XY]}$ is not necessarily equal to ${\\displaystyle \\operatorname {E} [X]\\cdot \\operatorname {E} [Y]}$. If ${\\displaystyle X}$ and ${\\displaystyle Y}$ are **independent**, then  ${\\displaystyle \\operatorname {E} [XY]=\\operatorname {E} [X]\\operatorname {E} [Y]}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-wealth",
   "metadata": {},
   "source": [
    "## Expected Value\n",
    "\n",
    "\n",
    "$\\mathbb{E}[X] = \\int_x x \\cdot p(x) \\ dx$\n",
    "\n",
    "Indicates the \"average\" value of the random variable $X$. \n",
    "\n",
    "\n",
    "\n",
    "## Expected Value of a Function\n",
    "Sometimes interest will focus on the expected value of some function\n",
    "$h(X)$ rather than on just $E(X)$.\n",
    "\n",
    "If the random variable $X$ has a set of possible values $D$ and pmf $p(x)$, then the expected value of any function $h(X)$, denoted by $E[h(X)]$ or $\\mu_{h(X)}$:\n",
    "\n",
    "$E[h(X)]=\\sum_{D} h(x).p(x) $\n",
    "\n",
    "\n",
    "For a continuous function the expectation function is:\n",
    "\n",
    "$\\mathbb{E}[h(X)]=\\int_x h(x) \\cdot p(x) \\ dx$\n",
    "\n",
    "### Example\n",
    "A computer store has purchased three computers of a certain type at 500 USD apiece. It will sell them for 1000 USD apiece. The manufacturer has agreed to repurchase any computers still unsold after a specified period at 200 USD apiece.\n",
    "Let $X$ denote the number of computers sold, and suppose that: \n",
    "- $p(0) =0.1$ \n",
    "- $p(1) =0.2$ \n",
    "- $p(2) =0.3$\n",
    "- $p(3) =0.4$\n",
    "\n",
    "With $h(X)$ denoting the profit associated with selling $X$ units, the given information implies that:\n",
    "\n",
    "$h(X)= revenue-cost$\n",
    "\n",
    "$cost=3*500$\n",
    "\n",
    "$revenue=1000 \\times x + 200\\times(3 - x)$\n",
    "\n",
    "The expected profit is then:\n",
    "\n",
    "$E[h(X)]=p(0)\\times h(0) +p(1)\\times h(1) +p(2)\\times h(2) +p(3)\\times h(3)= (-900)(.1) + (- 100)(.2) + (700)(.3) + (1500)(.4)=700$\n",
    "\n",
    "\n",
    "\n",
    "Refs:[1](https://www.stat.purdue.edu/~zhanghao/STAT511/handout/Stt511%20Sec3.3.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-pattern",
   "metadata": {},
   "source": [
    "## Conditional expectation\n",
    "Conditional expectation value, or conditional mean of a random variable is its expected value (the value it would take “on average” over an arbitrarily large number of occurrences) given that a certain set of \"conditions\" is known to occur. \n",
    "\n",
    "Depending on the context, the conditional expectation can be either a random variable  ${\\displaystyle E(X\\mid Y)}$\n",
    "or a function ${\\displaystyle E(X\\mid Y=y)}$ or ${\\displaystyle E(X\\mid Y)=f(Y)}$.\n",
    "\n",
    "\n",
    "### Discrete random variables\n",
    "\n",
    "${\\displaystyle {\\begin{aligned}\\operatorname {E} (X\\mid Y=y)&=\\sum _{x}xP(X=x\\mid Y=y)\\\\&=\\sum _{x}x{\\frac {P(X=x,Y=y)}{P(Y=y)}}\\end{aligned}}}$\n",
    "\n",
    "${\\displaystyle P(X=x,Y=y)}$ is the **joint probability mass function** of $X$ and $Y$.\n",
    "\n",
    "\n",
    "The joint probability mass function of two discrete random variables ${\\displaystyle X,Y}$ is:\n",
    "\n",
    "${\\displaystyle p_{X,Y}(x,y)=\\mathrm {P} (X=x\\ \\mathrm {and} \\ Y=y)}$\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "### Continuous random variables\n",
    "\n",
    "${\\displaystyle {\\begin{aligned}\\operatorname {E} (X\\mid Y=y)&=\\int _{-\\infty }^{\\infty }xf_{X|Y}(x,y)\\mathrm {d} x\\\\&=\\int _{-\\infty }^{\\infty }{\\frac {xf_{X,Y}(x,y)}{f_{Y}(y)}}\\mathrm {d} x\\end{aligned}}}$\n",
    "\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider the roll of a fair die and let $A = 1$ if the number is even (i.e., 2, 4, or 6) and $A = 0$ otherwise. Furthermore, let $B = 1$ if the number is prime (i.e., 2, 3, or 5) and $B = 0$ otherwise.\n",
    "\n",
    "\n",
    "|   |1\t|2\t|3\t|4\t|5\t|6  |\n",
    "|---|---|---|---|---|---|---|\n",
    "|A\t|0\t|1\t|0\t|1\t|0\t|1  |\n",
    "|B\t|0\t|1\t|1\t|0\t|1\t|0  |\n",
    "\n",
    "\n",
    "1. The unconditional expectation of $A$ is ${\\displaystyle E[A]=(0+1+0+1+0+1)/6=1/2}$\n",
    "2. The expectation of A conditional on $B = 1$ (i.e., conditional on the die roll being 2, 3, or 5) is ${\\displaystyle E[A\\mid B=1]=(1+0+0)/3=1/3}$\n",
    "3. The expectation of A conditional on $B = 0$ (i.e., conditional on the die roll being 1, 4, or 6) is ${\\displaystyle E[A\\mid B=0]=(0+1+1)/3=2/3}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-context",
   "metadata": {},
   "source": [
    "## Expectations of Functions of Jointly Distributed Discrete Random Variables\n",
    "\n",
    "\n",
    "Suppose that  $X$  and  $Y$  are jointly distributed discrete random variables with joint pmf  $p(x,y)$.\n",
    "\n",
    "If  $g(X,Y)$  is a function of these two random variables, then its expected value is given by the following:\n",
    "\n",
    "$\\text{E}[g(X,Y)] = \\mathop{\\sum\\sum}_{(x,y)}g(x,y)p(x,y).\\notag$\n",
    "\n",
    "### Example\n",
    "\n",
    "\n",
    "We toss a fair coin three times and record the sequence of heads  $(h)$  and tails  $(t)$. Random variable  $X$  denote the number of heads obtained and random variable  $Y$  denote the winnings earned in a single play of a game with the following rules\n",
    "\n",
    "- $\\$1$ if first  $h$  occurs on the first toss\n",
    "- $\\$2$ if first $h$ occurs on the second toss\n",
    "- $\\$3$ if first $h$ occurs on the third toss\n",
    "- $\\$-1$ if no $h$ occur\n",
    "\n",
    "\n",
    "Note that the possible values of $X$ are  $x=0,1,2,3$ , and the possible values of  $Y$  are  $y=−1,1,2,3$. \n",
    "\n",
    "\n",
    "Joint pmf of $X$ and $Y$\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>p (x,y)</th>\n",
    "            <th  colspan=\"4\" rowspan=\"1\" scope=\"row\">\\(X\\)</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <th  scope=\"row\">$Y$</th>\n",
    "            <th >0</th>\n",
    "            <th >1</th>\n",
    "            <th >2</th>\n",
    "            <th >3</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th  scope=\"row\">-1</th>\n",
    "            <td ><span  >1/8</span></td>\n",
    "            <td >0</td>\n",
    "            <td >0</td>\n",
    "            <td >0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th  scope=\"row\">1</th>\n",
    "            <td >0</td>\n",
    "            <td ><span  >1/8</span></td>\n",
    "            <td ><span  >2/8</span></td>\n",
    "            <td ><span  >1/8</span></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th  scope=\"row\">2</th>\n",
    "            <td >0</td>\n",
    "            <td ><span  >1/8</span></td>\n",
    "            <td ><span  >1/8</span></td>\n",
    "            <td >0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th  scope=\"row\">3</th>\n",
    "            <td >0</td>\n",
    "            <td ><span  >1/8</span></td>\n",
    "            <td >0</td>\n",
    "            <td >0</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. If, we define  $g(x,y)=xy$ , and compute the expected value of  $XY$ :\n",
    "$\\begin{align*} \n",
    "    \\text{E}[XY] = \\mathop{\\sum\\sum}_{(x,y)}xy\\cdot p(x,y) &= (0)(-1)\\left(\\frac{1}{8}\\right) \\\\ \n",
    "    &\\ + (1)(1)\\left(\\frac{1}{8}\\right) + (2)(1)\\left(\\frac{2}{8}\\right) + (3)(1)\\left(\\frac{1}{8}\\right) \\\\ \n",
    "    &\\ + (1)(2)\\left(\\frac{1}{8}\\right) + (2)(2)\\left(\\frac{1}{8}\\right) \\\\ \n",
    "    &\\ + (1)(3)\\left(\\frac{1}{8}\\right) \\\\ \n",
    "    &= \\frac{17}{8} = 2.125 \n",
    "    \\end{align*}$\n",
    "\n",
    "2. Next, if we define  $g(x)=x$ , and compute the expected value of  $X$:\n",
    "$\\begin{align*} \n",
    "    \\text{E}[X] = \\mathop{\\sum\\sum}_{(x,y)}x\\cdot p(x,y) &= (0)\\left(\\frac{1}{8}\\right) \\\\ \n",
    "    &\\ + (1)\\left(\\frac{1}{8}\\right) + (2)\\left(\\frac{2}{8}\\right) + (3)\\left(\\frac{1}{8}\\right) \\\\ \n",
    "    &\\ + (1)\\left(\\frac{1}{8}\\right) + (2)\\left(\\frac{1}{8}\\right) \\\\ \n",
    "    &\\ + (1)\\left(\\frac{1}{8}\\right)\\\\ \n",
    "    &= \\frac{12}{8} = 1.5 \n",
    "    \\end{align*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-franchise",
   "metadata": {},
   "source": [
    "## Conditional expectation of joint distribution\n",
    "\n",
    "Refs: [1](https://web.stanford.edu/class/archive/cs/cs109/cs109.1196/lectures/13%20-%20ConditionalJoints.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-manufacturer",
   "metadata": {},
   "source": [
    "## Subscript notation in expectations\n",
    "\n",
    "When many random variables are involved, and there is no subscript in the 𝐸 symbol, the expected value is taken with respect to their joint distribution:\n",
    "\n",
    "$E[h(X,Y)] = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty h(x,y) f_{XY}(x,y) \\, dx \\, dy$\n",
    "\n",
    "When a subscript is present, it tells us on which variable we should condition.\n",
    "\n",
    "$E_X[h(X,Y)] = E[h(X,Y)\\mid X] = \\int_{-\\infty}^\\infty h(x,y) f_{h(X,Y)\\mid X}(h(x,y)\\mid x)\\,dy$\n",
    "\n",
    "\n",
    "Refs: [1](https://stats.stackexchange.com/questions/72613/subscript-notation-in-expectations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-belize",
   "metadata": {},
   "source": [
    "## Take the expectation with respect to a probability measure\n",
    "\n",
    "In neural network architecture, the posterior probability of classes $\\mathbf{y}=y_1,y_2,...,y_K]$ given an input feature vector $\\mathbf{x}$ is $p(\\mathbf{y}|\\mathbf{x};\\mathbf{w})$ where $\\mathbf{w}$ are the parameters of the network. Note that $\\mathbf{y}$ is in one-hot encoding.\n",
    "\n",
    "\n",
    "This posterior probability is estimated using maximum likelihood estimation, and therefore the objective is to maximize $E_{p(\\mathbf{x},\\mathbf{y})}[log(p(\\mathbf{y}|\\mathbf{x};\\mathbf{w}))]$\n",
    "\n",
    "\n",
    "\n",
    "Let $f$ be a function and $\\mu$ be a probability measure. A notation $\\mathbb E_\\mu[f]$ means \n",
    "\n",
    "$\\mathbb E_\\mu[f]=\\int_\\mu f=\\int f(x)d(\\mu(x))$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$\\mathbb{E}_{\\mathbf{x} \\sim p(\\mathbf{x}|\\theta)}[X].$\n",
    "\n",
    "\n",
    "Refs: [1](https://www.youtube.com/watch?v=9zKuYvjFFS8&ab_channel=ArxivInsights), [2](https://www.youtube.com/watch?v=2pEkWk-LHmU&ab_channel=JordanBoyd-GraberJordanBoyd-Graber)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-biography",
   "metadata": {},
   "source": [
    "## Expectation with respect to a probability distribution\n",
    "\n",
    "$\\mathbb{E}[X] = \\int_x x \\cdot p(x) \\ dx$\n",
    "\n",
    "$\\mathbb{E}[g(X)]=\\int_x g(x) \\cdot p(x) \\ dx$\n",
    "\n",
    "\n",
    "$\\mathbb{E}_{p(\\mathbf{x};\\mathbf{\\theta})}[f(\\mathbf{x};\\mathbf{\\phi})] = \\int p(\\mathbf{x};\\mathbf{\\theta}) f(\\mathbf{x};\\mathbf{\\phi}) d\\mathbf{x}$\n",
    "\n",
    "$\\mathbb{E}_{\\mathbf{x}}[f(\\mathbf{x};\\mathbf{\\phi})]$\n",
    "\n",
    "$\\mathbf{x} \\sim p(\\mathbf{x};\\mathbf{\\theta})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-machinery",
   "metadata": {},
   "source": [
    "## Marginal distribution and Expected Value\n",
    "\n",
    "${\\displaystyle p_{X}(x_{i})=\\sum _{j}p(x_{i},y_{j})},$ and ${\\displaystyle \\ p_{Y}(y_{j})=\\sum _{i}p(x_{i},y_{j})}$\n",
    "\n",
    "A marginal probability can always be written as an expected value:\n",
    "\n",
    "${\\displaystyle p_{X}(x)=\\int _{y}p_{X\\mid Y}(x\\mid y)\\,p_{Y}(y)\\,\\mathrm {d} y=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)]\\;.}$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
