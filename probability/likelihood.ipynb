{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "executive-simulation",
   "metadata": {},
   "source": [
    "## Likelihood\n",
    "Now if you take a random sample (an observation) from the above graph, let say at $x=-2$, then the $y=0.6$ is the likelihood that this observation generated from the this graph ($\\mu=4$ and $\\sigma=2$). The value $y=0.6$ is relatively small, which make sense, because if take a random sample from a gaussian distribution the chance that we get closer to the mean is bigger than the chance of being away from that.\n",
    "\n",
    "$Likelihood(\\mu=4,\\sigma=2|Observation=-2)$\n",
    "\n",
    "Refs: [1](https://www.youtube.com/watch?v=pYxNSUDSFH4&t=182s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-current",
   "metadata": {},
   "source": [
    "<img src='images/likelihood.png'>\n",
    "\n",
    "The red ares=$P(5<x<10|\\mu=4,\\sigma=2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-collectible",
   "metadata": {},
   "source": [
    "## Log Likelihood\n",
    "Since we assume the obeservations are independent of each other and for independent probabilites we have:\n",
    "\n",
    "$P(x_1,x_2|\\theta)=P(x_1|\\theta).P(x_2|\\theta)$\n",
    "\n",
    "$x_i\\perp x_j \\text{indipendent}$ \n",
    "\n",
    "Therefore for likelihood we would also have:\n",
    "$L(distribution|observeation1,observeation2)=L(distribution|observeation1)L(distribution|observeation2)$\n",
    "\n",
    "Since Likelihood values are small and multiplying them will make them smaller which might may round to zero in  computation, we use the **log** function. The **log** function will also truns multipication into summation and power into multipication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-presentation",
   "metadata": {},
   "source": [
    "# Likelihood ratio\n",
    "We usually don't use likelihood function but we compare them :\n",
    "$L(\\theta1|x)>L(\\theta2|x)?$\n",
    "\n",
    "Since **log** function is a monotonically increasig function, when the likelihood increase/ decrease, the log will also increase/ decrease, so we compare log of likelihood \n",
    "# Odds ratio\n",
    "Odds provide a measure of the likelihood of a particular outcome. The odds of rolling a 6 is 1:5, The odds of rolling either a 5 or 6 is 2:4.\n",
    "\n",
    "\n",
    "$odds=\\frac{P(event)}{1-P(event)}$\n",
    "# Log odds\n",
    "\n",
    "The logit function or the log-odds is the logarithm of the odds. If $p$ is a probability, \n",
    "\n",
    "${\\displaystyle \\operatorname {logit} (p)=\\log \\left({\\frac {p}{1-p}}\\right)=\\log(p)-\\log(1-p)=-\\log \\left({\\frac {1}{p}}-1\\right)\\,.}$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
