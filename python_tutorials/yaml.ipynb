{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6021d4dd-aa2e-4d00-a785-e455d3693dc0",
   "metadata": {},
   "source": [
    "## Create/ Write a YAML\n",
    "\n",
    "Here’s how to create the file:\n",
    "\n",
    "```yaml\n",
    "model:\n",
    "  name: resnet18\n",
    "  weights: pretrained\n",
    "\n",
    "train:\n",
    "  batch_size: 32\n",
    "  epochs: 10\n",
    "```\n",
    "\n",
    "To save this YAML in Python:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf2077e-d673-4ba1-aafc-bdc892555721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data = {\n",
    "    'model': {'name': 'resnet18', 'weights': 'pretrained'},\n",
    "    'train': {'batch_size': 32, 'epochs': 10}\n",
    "}\n",
    "\n",
    "with open('data/config.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181610ae-9493-4ec7-a26b-58e8490b08e3",
   "metadata": {},
   "source": [
    "## Read a YAML\n",
    "To read a YAML file directly into a Python object without manual iteration (i.e., without looping through keys/values), you can use the `yaml.safe_load()` function from the PyYAML library. This function automatically parses the YAML content and returns a native Python object — typically a dictionary, list, or nested combination — depending on the YAML structure.\n",
    "\n",
    "**Example**\n",
    "\n",
    "`config.yaml`:\n",
    "\n",
    "```yaml\n",
    "model:\n",
    "  name: resnet18\n",
    "  weights: pretrained\n",
    "train:\n",
    "  batch_size: 32\n",
    "  epochs: 10\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273b2a63-c30a-4acb-a5f5-1f619af13a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'name': 'resnet18', 'weights': 'pretrained'}, 'train': {'batch_size': 32, 'epochs': 10}}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"data/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Now `config` is a native Python object, like a dict or list\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf75f1-f46b-4581-b091-bb7f0123693e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  **Define a Typed Class Using `dataclasses`**\n",
    "\n",
    "You can map the YAML content directly into a Python dataclass for structured access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18df4771-91cf-4086-ab52-fa3dcbee9ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import yaml\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    name: str\n",
    "    weights: str\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    batch_size: int\n",
    "    epochs: int\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    model: ModelConfig\n",
    "    train: TrainConfig\n",
    "\n",
    "\n",
    "\n",
    "def dict_to_dataclass(d: dict) -> Config:\n",
    "    return Config(\n",
    "        model=ModelConfig(**d['model']),\n",
    "        train=TrainConfig(**d['train'])\n",
    "    )\n",
    "\n",
    "with open(\"data/config.yaml\", \"r\") as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "config = dict_to_dataclass(data)\n",
    "\n",
    "# Now you can access like an object:\n",
    "print(config.model.name)        # resnet18\n",
    "print(config.train.batch_size)  # 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccf0eb-83ed-4242-84db-0073124acedb",
   "metadata": {},
   "source": [
    "Here's how you can load a YAML file directly into a `pydantic` model — it's very clean, type-safe, and supports validation.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Define `pydantic` Models**\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class ModelConfig(BaseModel):\n",
    "    name: str\n",
    "    weights: Literal[\"pretrained\", \"none\"]\n",
    "\n",
    "class TrainConfig(BaseModel):\n",
    "    batch_size: int\n",
    "    epochs: int\n",
    "\n",
    "class Config(BaseModel):\n",
    "    model: ModelConfig\n",
    "    train: TrainConfig\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  **2. Create YAML File (`config.yaml`)**\n",
    "\n",
    "You can write this manually or with Python as shown earlier:\n",
    "\n",
    "```yaml\n",
    "model:\n",
    "  name: resnet18\n",
    "  weights: pretrained\n",
    "\n",
    "train:\n",
    "  batch_size: 32\n",
    "  epochs: 10\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  **3. Load YAML into `pydantic` Model**\n",
    "\n",
    "```python\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    raw_config = yaml.safe_load(f)\n",
    "\n",
    "config = Config(**raw_config)\n",
    "\n",
    "# Access as object with validation\n",
    "print(config.model.name)        # resnet18\n",
    "print(config.train.batch_size)  # 32\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Optional: YAML Dump from `pydantic` Model\n",
    "\n",
    "```python\n",
    "with open(\"config_out.yaml\", \"w\") as f:\n",
    "    yaml.dump(config.dict(), f)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "This approach is ideal for structured, validated configuration — perfect for machine learning pipelines, apps, and experiment management."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
